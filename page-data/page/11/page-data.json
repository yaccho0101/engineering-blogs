{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/11","result":{"data":{"allPost":{"edges":[{"node":{"ID":4390,"Title":"Adopting dbt as the Data Transformation Tool at Instacart","Description":"","PublishedAt":"2023-08-17 23:50:21+00:00","OriginURL":"https://tech.instacart.com/adopting-dbt-as-the-data-transformation-tool-at-instacart-36c74bc407df?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":4391,"Title":"AVA Discovery View: Surfacing Authentic Moments","Description":"","PublishedAt":"2023-08-17 22:07:14+00:00","OriginURL":"https://netflixtechblog.com/ava-discovery-view-surfacing-authentic-moments-b8cd145491cc?source=rss----2615bd06b42e---4","SourceName":"Netflix"}},{"node":{"ID":4388,"Title":"mTLS: When certificate authentication is done wrong","Description":"<p>In this post, we'll deep dive into some interesting attacks on mTLS authentication. We'll have a look at implementation vulnerabilities and how developers can make their mTLS systems vulnerable to user impersonation, privilege escalation, and information leakages.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://github.blog/2023-08-17-mtls-when-certificate-authentication-is-done-wrong/\">mTLS: When certificate authentication is done wrong</a> appeared first on <a rel=\"nofollow\" href=\"https://github.blog\">The GitHub Blog</a>.</p>\n","PublishedAt":"2023-08-17 21:22:26+00:00","OriginURL":"https://github.blog/2023-08-17-mtls-when-certificate-authentication-is-done-wrong/","SourceName":"GitHub"}},{"node":{"ID":4386,"Title":"New – Amazon EC2 Hpc7a Instances Powered by 4th Gen AMD EPYC Processors Optimized for High Performance Computing","Description":"In January 2022, we launched Amazon EC2 Hpc6a instances for customers to efficiently run their compute-bound high performance computing (HPC) workloads on AWS with up to 65 percent better price performance over comparable x86-based compute-optimized instances. As their jobs grow more complex, customers have asked for more cores with more compute performance and more memory […]","PublishedAt":"2023-08-17 19:55:06+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-amazon-ec2-hpc7a-instances-powered-by-4th-gen-amd-epyc-processors-optimized-for-high-performance-computing/","SourceName":"AWS"}},{"node":{"ID":4384,"Title":"CDK for Terraform 0.18 reduces synthesization time","Description":"The newest CDKTF release cuts synthesization times for TypeScript, Python, and Java, drastically improving the user experience.","PublishedAt":"2023-08-17 14:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/cdk-for-terraform-0-18-reduces-synthesization-time","SourceName":"HashiCorp"}},{"node":{"ID":4382,"Title":"How to Ensure Supply Chain Security for AI Applications","Description":"<p>Machine Learning (ML) is at the heart of the boom in AI Applications, revolutionizing various domains. From powering intelligent Large Language Model (LLM) based chatbots like ChatGPT and Bard, to enabling text-to-AI image generators like Stable Diffusion, ML continues to drive innovation. Its transformative impact advances multiple fields from genetics to medicine to finance. Without [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/how-to-ensure-supply-chain-security-for-ai-applications/\">How to Ensure Supply Chain Security for AI Applications</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2023-08-17 13:20:29+00:00","OriginURL":"https://blog.cloudera.com/how-to-ensure-supply-chain-security-for-ai-applications/","SourceName":"Cloudera"}},{"node":{"ID":4383,"Title":"Elastic Stack 8.9.1 released ","Description":"","PublishedAt":"2023-08-17 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-stack-8-9-1-released","SourceName":"Elastic"}},{"node":{"ID":4385,"Title":"Changes to Datadog Cloud Security Management","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/cloud-security-management-changes/CSM-product-split-announcement_230815.png\" width=\"100%\"/>In order to better meet organizations&rsquo; specific requirements for securing their environments, we are making changes to our Cloud Security Management product. On August 1, Datadog introduced new offerings in Cloud Security Management: CSM Pro and CSM Enterprise. Alongside Datadog Cloud Workload Security, these distinct packages provide customers with security capabilities tailored to their particular use cases and needs.CSM Pro provides continuous security scanning of your cloud and container environments for misconfigurations and resource vulnerabilities.","PublishedAt":"2023-08-17 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/cloud-security-management-changes/","SourceName":"Datadog"}},{"node":{"ID":4387,"Title":"Easily install the Datadog Agent using AWS Systems Manager","Description":"<img class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/datadog-agent-aws-ssm/hero.png\" width=\"100%\"/>AWS Systems Manager (SSM), an end-to-end management solution for AWS resources, provides a marketplace of pre-packaged software scripts for SSM-managed Windows and Linux instances, enabling AWS users to automatically install custom software on large groups of instances.Datadog now offers documents that enable easy, one-click installation of the latest version of our Agent for both Linux and Windows through the AWS SSM marketplace, allowing joint Datadog and AWS users to install the Agent without having to configure the Agent YAML file.","PublishedAt":"2023-08-17 00:00:00+00:00","OriginURL":"https://www.datadoghq.com/blog/datadog-agent-aws-ssm/","SourceName":"Datadog"}},{"node":{"ID":4379,"Title":"New Accreditations for Cloudera Partners","Description":"<p>Cloudera Partner Network Introduces New Sales, Technical and Industry Accreditations</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/new-accreditations-for-cloudera-partners/\">New Accreditations for Cloudera Partners</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2023-08-16 20:30:32+00:00","OriginURL":"https://blog.cloudera.com/new-accreditations-for-cloudera-partners/","SourceName":"Cloudera"}},{"node":{"ID":4380,"Title":"Blog: Kubernetes 1.28: Non-Graceful Node Shutdown Moves to GA","Description":"<p><strong>Authors:</strong> Xing Yang (VMware) and Ashutosh Kumar (Elastic)</p>\n<p>The Kubernetes Non-Graceful Node Shutdown feature is now GA in Kubernetes v1.28.\nIt was introduced as\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/2268-non-graceful-shutdown\">alpha</a>\nin Kubernetes v1.24, and promoted to\n<a href=\"https://kubernetes.io/blog/2022/12/16/kubernetes-1-26-non-graceful-node-shutdown-beta/\">beta</a>\nin Kubernetes v1.26.\nThis feature allows stateful workloads to restart on a different node if the\noriginal node is shutdown unexpectedly or ends up in a non-recoverable state\nsuch as the hardware failure or unresponsive OS.</p>\n<h2 id=\"what-is-a-non-graceful-node-shutdown\">What is a Non-Graceful Node Shutdown</h2>\n<p>In a Kubernetes cluster, a node can be shutdown in a planned graceful way or\nunexpectedly because of reasons such as power outage or something else external.\nA node shutdown could lead to workload failure if the node is not drained\nbefore the shutdown. A node shutdown can be either graceful or non-graceful.</p>\n<p>The <a href=\"https://kubernetes.io/blog/2021/04/21/graceful-node-shutdown-beta/\">Graceful Node Shutdown</a>\nfeature allows Kubelet to detect a node shutdown event, properly terminate the pods,\nand release resources, before the actual shutdown.</p>\n<p>When a node is shutdown but not detected by Kubelet's Node Shutdown Manager,\nthis becomes a non-graceful node shutdown.\nNon-graceful node shutdown is usually not a problem for stateless apps, however,\nit is a problem for stateful apps.\nThe stateful application cannot function properly if the pods are stuck on the\nshutdown node and are not restarting on a running node.</p>\n<p>In the case of a non-graceful node shutdown, you can manually add an <code>out-of-service</code> taint on the Node.</p>\n<pre tabindex=\"0\"><code>kubectl taint nodes &lt;node-name&gt; node.kubernetes.io/out-of-service=nodeshutdown:NoExecute\n</code></pre><p>This taint triggers pods on the node to be forcefully deleted if there are no\nmatching tolerations on the pods. Persistent volumes attached to the shutdown node\nwill be detached, and new pods will be created successfully on a different running\nnode.</p>\n<p><strong>Note:</strong> Before applying the out-of-service taint, you must verify that a node is\nalready in shutdown or power-off state (not in the middle of restarting).</p>\n<p>Once all the workload pods that are linked to the out-of-service node are moved to\na new running node, and the shutdown node has been recovered, you should remove that\ntaint on the affected node after the node is recovered.</p>\n<h2 id=\"what-s-new-in-stable\">What’s new in stable</h2>\n<p>With the promotion of the Non-Graceful Node Shutdown feature to stable, the\nfeature gate <code>NodeOutOfServiceVolumeDetach</code> is locked to true on\n<code>kube-controller-manager</code> and cannot be disabled.</p>\n<p>Metrics <code>force_delete_pods_total</code> and <code>force_delete_pod_errors_total</code> in the\nPod GC Controller are enhanced to account for all forceful pods deletion.\nA reason is added to the metric to indicate whether the pod is forcefully deleted\nbecause it is terminated, orphaned, terminating with the <code>out-of-service</code> taint,\nor terminating and unscheduled.</p>\n<p>A &quot;reason&quot; is also added to the metric <code>attachdetach_controller_forced_detaches</code>\nin the Attach Detach Controller to indicate whether the force detach is caused by\nthe <code>out-of-service</code> taint or a timeout.</p>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>This feature requires a user to manually add a taint to the node to trigger\nworkloads failover and remove the taint after the node is recovered.\nIn the future, we plan to find ways to automatically detect and fence nodes\nthat are shutdown/failed and automatically failover workloads to another node.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Check out additional documentation on this feature\n<a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#non-graceful-node-shutdown\">here</a>.</p>\n<h2 id=\"how-to-get-involved\">How to get involved?</h2>\n<p>We offer a huge thank you to all the contributors who helped with design,\nimplementation, and review of this feature and helped move it from alpha, beta, to stable:</p>\n<ul>\n<li>Michelle Au (<a href=\"https://github.com/msau42\">msau42</a>)</li>\n<li>Derek Carr (<a href=\"https://github.com/derekwaynecarr\">derekwaynecarr</a>)</li>\n<li>Danielle Endocrimes (<a href=\"https://github.com/endocrimes\">endocrimes</a>)</li>\n<li>Baofa Fan (<a href=\"https://github.com/carlory\">carlory</a>)</li>\n<li>Tim Hockin (<a href=\"https://github.com/thockin\">thockin</a>)</li>\n<li>Ashutosh Kumar (<a href=\"https://github.com/sonasingh46\">sonasingh46</a>)</li>\n<li>Hemant Kumar (<a href=\"https://github.com/gnufied\">gnufied</a>)</li>\n<li>Yuiko Mouri (<a href=\"https://github.com/YuikoTakada\">YuikoTakada</a>)</li>\n<li>Mrunal Patel (<a href=\"https://github.com/mrunalp\">mrunalp</a>)</li>\n<li>David Porter (<a href=\"https://github.com/bobbypage\">bobbypage</a>)</li>\n<li>Yassine Tijani (<a href=\"https://github.com/yastij\">yastij</a>)</li>\n<li>Jing Xu (<a href=\"https://github.com/jingxu97\">jingxu97</a>)</li>\n<li>Xing Yang (<a href=\"https://github.com/xing-yang\">xing-yang</a>)</li>\n</ul>\n<p>This feature is a collaboration between SIG Storage and SIG Node.\nFor those interested in getting involved with the design and development of any\npart of the Kubernetes Storage system, join the Kubernetes Storage Special\nInterest Group (SIG).\nFor those interested in getting involved with the design and development of the\ncomponents that support the controlled interactions between pods and host\nresources, join the Kubernetes Node SIG.</p>","PublishedAt":"2023-08-16 18:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/08/16/kubernetes-1-28-non-graceful-node-shutdown-ga/","SourceName":"Kubernetes"}},{"node":{"ID":4381,"Title":"Curbing Connection Churn in Zuul","Description":"","PublishedAt":"2023-08-16 17:55:48+00:00","OriginURL":"https://netflixtechblog.com/curbing-connection-churn-in-zuul-2feb273a3598?source=rss----2615bd06b42e---4","SourceName":"Netflix"}},{"node":{"ID":4377,"Title":"Join AWS Hybrid Cloud & Edge Day to Learn How to Deploy Your Applications in the Everywhere Cloud","Description":"In his keynote of AWS re:Invent 2021, Dr. Werner Vogels shared the insight of how “the everywhere cloud” is bringing AWS to new locales through AWS hardware and services and spotlighted it as one of his tech predictions for 2022 and beyond in his blog post. “What we will see in 2022, and even more […]","PublishedAt":"2023-08-16 16:47:44+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/join-aws-hybrid-cloud-edge-day-to-learn-how-to-deploy-your-applications-in-the-everywhere-cloud/","SourceName":"AWS"}},{"node":{"ID":4378,"Title":"The Next Era of Data at Instacart","Description":"","PublishedAt":"2023-08-16 16:14:54+00:00","OriginURL":"https://tech.instacart.com/the-next-era-of-data-at-instacart-e081d8dfa162?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":4375,"Title":"Introducing Cloudflare's 2023 phishing threats report","Description":"The 2023 Phishing Threats Report analyzes millions of malicious emails, brand impersonation examples, identity deception, and other key attack trends based on email security data from a 12-month period","PublishedAt":"2023-08-16 09:13:17+00:00","OriginURL":"http://blog.cloudflare.com/2023-phishing-report/","SourceName":"Cloudflare"}},{"node":{"ID":4393,"Title":"Making event-driven development predictable with Discover","Description":"<p>SPONSORED BY DISCOVER FINANCIAL SERVICES On this sponsored episode of the podcast, Ben and Ryan chat with Paul Manning and Emanuele Pugliese of Discover Financial about the tech that goes into payments and the way they approach developer experience and architecture. They talk about domain-driven design, event-driven architecture, Kafka Streams, and how they leverage all…</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2023/08/16/making-event-driven-development-predictable-with-discover/\">Making event-driven development predictable with Discover</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2023-08-16 04:40:00+00:00","OriginURL":"https://stackoverflow.blog/2023/08/16/making-event-driven-development-predictable-with-discover/","SourceName":"Stack Overflow"}},{"node":{"ID":4376,"Title":"Optimizing cloud resources and cost with APM metadata in Elastic Observability","Description":"","PublishedAt":"2023-08-16 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/optimize-cloud-resources-cost-apm-metadata-elastic-observability","SourceName":"Elastic"}},{"node":{"ID":4457,"Title":"Searching by music: Leveraging vector search for audio information retrieval","Description":"","PublishedAt":"2023-08-16 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/searching-by-music-leveraging-vector-search-audio-information-retrieval","SourceName":"Elastic"}},{"node":{"ID":4374,"Title":"New – Amazon EC2 M7a General Purpose Instances Powered by 4th Gen AMD EPYC Processors","Description":"In November 2021, we launched Amazon EC2 M6a instances, powered by 3rd Gen AMD EPYC (Milan) processors, running at frequencies up to 3.6 GHz, which offer you up to 35 percent improvement in price performance compared to M5a instances. Many customers who run workloads that are dependent on x86 instructions, such as SAP, are looking […]","PublishedAt":"2023-08-15 22:11:37+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/new-amazon-ec2-m7a-general-purpose-instances-powered-by-4th-gen-amd-epyc-processors/","SourceName":"AWS"}},{"node":{"ID":4372,"Title":"Blog: pkgs.k8s.io: Introducing Kubernetes Community-Owned Package Repositories","Description":"<p><strong>Author</strong>: Marko Mudrinić (Kubermatic)</p>\n<p>On behalf of Kubernetes SIG Release, I am very excited to introduce the\nKubernetes community-owned software\nrepositories for Debian and RPM packages: <code>pkgs.k8s.io</code>! The new package\nrepositories are replacement for the Google-hosted package repositories\n(<code>apt.kubernetes.io</code> and <code>yum.kubernetes.io</code>) that we've been using since\nKubernetes v1.5.</p>\n<p>This blog post contains information about these new package repositories,\nwhat does it mean to you as an end user, and how to migrate to the new\nrepositories.</p>\n<h2 id=\"what-you-need-to-know-about-the-new-package-repositories\">What you need to know about the new package repositories?</h2>\n<ul>\n<li>This is an <strong>opt-in change</strong>; you're required to manually migrate from the\nGoogle-hosted repository to the Kubernetes community-owned repositories.\nSee <a href=\"#how-to-migrate\">how to migrate</a> later in this announcement for migration information\nand instructions.</li>\n<li>Access to the Google-hosted repository will remain intact for the foreseeable\nfuture. However, the Kubernetes project plans to stop publishing packages to\nthe Google-hosted repository in the future. The project strongly recommends\nmigrating to the Kubernetes package repositories going forward.</li>\n<li>The Kubernetes package repositories contain packages beginning with those\nKubernetes versions that were still under support when the community took\nover the package builds. This means that anything before v1.24.0 will only be\navailable in the Google-hosted repository.</li>\n<li>There's a dedicated package repository for each Kubernetes minor version.\nWhen upgrading to a different minor release, you must bear in mind that\nthe package repository details also change.</li>\n</ul>\n<h2 id=\"why-are-we-introducing-new-package-repositories\">Why are we introducing new package repositories?</h2>\n<p>As the Kubernetes project is growing, we want to ensure the best possible\nexperience for the end users. The Google-hosted repository has been serving\nus well for many years, but we started facing some problems that require\nsignificant changes to how we publish packages. Another goal that we have is to\nuse community-owned infrastructure for all critical components and that\nincludes package repositories.</p>\n<p>Publishing packages to the Google-hosted repository is a manual process that\ncan be done only by a team of Google employees called\n<a href=\"https://kubernetes.io/releases/release-managers/#build-admins\">Google Build Admins</a>.\n<a href=\"https://kubernetes.io/releases/release-managers/#release-managers\">The Kubernetes Release Managers team</a>\nis a very diverse team especially in terms of timezones that we work in.\nGiven this constraint, we have to do very careful planning for every release to\nensure that we have both Release Manager and Google Build Admin available to\ncarry out the release.</p>\n<p>Another problem is that we only have a single package repository. Because of\nthis, we were not able to publish packages for prerelease versions (alpha,\nbeta, and rc). This made testing Kubernetes prereleases harder for anyone who\nis interested to do so. The feedback that we receive from people testing these\nreleases is critical to ensure the best quality of releases, so we want to make\ntesting these releases as easy as possible. On top of that, having only one\nrepository limited us when it comes to publishing dependencies like <code>cri-tools</code>\nand <code>kubernetes-cni</code>.</p>\n<p>Regardless of all these issues, we're very thankful to Google and Google Build\nAdmins for their involvement, support, and help all these years!</p>\n<h2 id=\"how-the-new-package-repositories-work\">How the new package repositories work?</h2>\n<p>The new package repositories are hosted at <code>pkgs.k8s.io</code> for both Debian and\nRPM packages. At this time, this domain points to a CloudFront CDN backed by S3\nbucket that contains repositories and packages. However, we plan on onboarding\nadditional mirrors in the future, giving possibility for other companies to\nhelp us with serving packages.</p>\n<p>Packages are built and published via the <a href=\"http://openbuildservice.org\">OpenBuildService (OBS) platform</a>.\nAfter a long period of evaluating different solutions, we made a decision to\nuse OpenBuildService as a platform to manage our repositories and packages.\nFirst of all, OpenBuildService is an open source platform used by a large\nnumber of open source projects and companies, like openSUSE, VideoLAN,\nDell, Intel, and more. OpenBuildService has many features making it very\nflexible and easy to integrate with our existing release tooling. It also\nallows us to build packages in a similar way as for the Google-hosted\nrepository making the migration process as seamless as possible.</p>\n<p>SUSE sponsors the Kubernetes project with access to their reference\nOpenBuildService setup (<a href=\"http://build.opensuse.org\"><code>build.opensuse.org</code></a>) and\nwith technical support to integrate OBS with our release processes.</p>\n<p>We use SUSE's OBS instance for building and publishing packages. Upon building\na new release, our tooling automatically pushes needed artifacts and\npackage specifications to <code>build.opensuse.org</code>. That will trigger the build\nprocess that's going to build packages for all supported architectures (AMD64,\nARM64, PPC64LE, S390X). At the end, generated packages will be automatically\npushed to our community-owned S3 bucket making them available to all users.</p>\n<p>We want to take this opportunity to thank SUSE for allowing us to use\n<code>build.opensuse.org</code> and their generous support to make this integration\npossible!</p>\n<h2 id=\"what-are-significant-differences-between-the-google-hosted-and-kubernetes-package-repositories\">What are significant differences between the Google-hosted and Kubernetes package repositories?</h2>\n<p>There are three significant differences that you should be aware of:</p>\n<ul>\n<li>There's a dedicated package repository for each Kubernetes minor release.\nFor example, repository called <code>core:/stable:/v1.28</code> only hosts packages for\nstable Kubernetes v1.28 releases. This means you can install v1.28.0 from\nthis repository, but you can't install v1.27.0 or any other minor release\nother than v1.28. Upon upgrading to another minor version, you have to add a\nnew repository and optionally remove the old one</li>\n<li>There's a difference in what <code>cri-tools</code> and <code>kubernetes-cni</code> package\nversions are available in each Kubernetes repository\n<ul>\n<li>These two packages are dependencies for <code>kubelet</code> and <code>kubeadm</code></li>\n<li>Kubernetes repositories for v1.24 to v1.27 have same versions of these\npackages as the Google-hosted repository</li>\n<li>Kubernetes repositories for v1.28 and onwards are going to have published\nonly versions that are used by that Kubernetes minor release\n<ul>\n<li>Speaking of v1.28, only kubernetes-cni 1.2.0 and cri-tols v1.28 are going\nto be available in the repository for Kubernetes v1.28</li>\n<li>Similar for v1.29, we only plan on publishing cri-tools v1.29 and\nwhatever kubernetes-cni version is going to be used by Kubernetes v1.29</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>The revision part of the package version (the <code>-00</code> part in <code>1.28.0-00</code>) is\nnow autogenerated by the OpenBuildService platform and has a different format.\nThe revision is now in the format of <code>-x.y</code>, e.g. <code>1.28.0-1.1</code></li>\n</ul>\n<h2 id=\"does-this-in-any-way-affect-existing-google-hosted-repositories\">Does this in any way affect existing Google-hosted repositories?</h2>\n<p>The Google-hosted repository and all packages published to it will continue\nworking in the same way as before. There are no changes in how we build and\npublish packages to the Google-hosted repository, all newly-introduced changes\nare only affecting packages publish to the community-owned repositories.</p>\n<p>However, as mentioned at the beginning of this blog post, we plan to stop\npublishing packages to the Google-hosted repository in the future.</p>\n<h2 id=\"how-to-migrate\">How to migrate to the Kubernetes community-owned repositories?</h2>\n<h3 id=\"how-to-migrate-deb\">Debian, Ubuntu, and operating systems using <code>apt</code>/<code>apt-get</code></h3>\n<ol>\n<li>\n<p>Replace the <code>apt</code> repository definition so that <code>apt</code> points to the new\nrepository instead of the Google-hosted repository. Make sure to replace the\nKubernetes minor version in the command below with the minor version\nthat you're currently using:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#a2f\">echo</span> <span style=\"color:#b44\">&#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /&#34;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list\n</span></span></code></pre></div></li>\n<li>\n<p>Download the public signing key for the Kubernetes package repositories.\nThe same signing key is used for all repositories, so you can disregard the\nversion in the URL:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n</span></span></code></pre></div></li>\n<li>\n<p>Update the <code>apt</code> package index:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>sudo apt-get update\n</span></span></code></pre></div></li>\n</ol>\n<h3 id=\"how-to-migrate-rpm\">CentOS, Fedora, RHEL, and operating systems using <code>rpm</code>/<code>dnf</code></h3>\n<ol>\n<li>\n<p>Replace the <code>yum</code> repository definition so that <code>yum</code> points to the new\nrepository instead of the Google-hosted repository. Make sure to replace the\nKubernetes minor version in the command below with the minor version\nthat you're currently using:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">[kubernetes]\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">name=Kubernetes\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">baseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">enabled=1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">gpgcheck=1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">gpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div></li>\n</ol>\n<h2 id=\"can-i-rollback-to-the-google-hosted-repository-after-migrating-to-the-kubernetes-repositories\">Can I rollback to the Google-hosted repository after migrating to the Kubernetes repositories?</h2>\n<p>In general, yes. Just do the same steps as when migrating, but use parameters\nfor the Google-hosted repository. You can find those parameters in a document\nlike <a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm\">&quot;Installing kubeadm&quot;</a>.</p>\n<h2 id=\"why-isn-t-there-a-stable-list-of-domains-ips-why-can-t-i-restrict-package-downloads\">Why isn’t there a stable list of domains/IPs? Why can’t I restrict package downloads?</h2>\n<p>Our plan for <code>pkgs.k8s.io</code> is to make it work as a redirector to a set of\nbackends (package mirrors) based on user's location. The nature of this change\nmeans that a user downloading a package could be redirected to any mirror at\nany time. Given the architecture and our plans to onboard additional mirrors in\nthe near future, we can't provide a list of IP addresses or domains that you\ncan add to an allow list.</p>\n<p>Restrictive control mechanisms like man-in-the-middle proxies or network\npolicies that restrict access to a specific list of IPs/domains will break with\nthis change. For these scenarios, we encourage you to mirror the release\npackages to a local package repository that you have strict control over.</p>\n<h2 id=\"what-should-i-do-if-i-detect-some-abnormality-with-the-new-repositories\">What should I do if I detect some abnormality with the new repositories?</h2>\n<p>If you encounter any issue with new Kubernetes package repositories, please\nfile an issue in the\n<a href=\"https://github.com/kubernetes/release/issues/new/choose\"><code>kubernetes/release</code> repository</a>.</p>","PublishedAt":"2023-08-15 20:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/08/15/pkgs-k8s-io-introduction/","SourceName":"Kubernetes"}},{"node":{"ID":4370,"Title":"Supercharging ML/AI Foundations at Instacart","Description":"","PublishedAt":"2023-08-15 18:51:20+00:00","OriginURL":"https://tech.instacart.com/supercharging-ml-ai-foundations-at-instacart-d48214a2b511?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":4367,"Title":"Introducing Immortal Objects for Python","Description":"<p>Instagram has introduced Immortal Objects – PEP-683 – to Python. Now, objects can bypass reference count checks and live throughout the entire execution of the runtime, unlocking exciting avenues for true parallelism. At Meta, we use Python (Django) for our frontend server within Instagram. To handle parallelism, we rely on a multi-process architecture along with [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2023/08/15/developer-tools/immortal-objects-for-python-instagram-meta/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2023/08/15/developer-tools/immortal-objects-for-python-instagram-meta/\">Introducing Immortal Objects for Python</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n","PublishedAt":"2023-08-15 16:00:31+00:00","OriginURL":"https://engineering.fb.com/2023/08/15/developer-tools/immortal-objects-for-python-instagram-meta/","SourceName":"Facebook"}},{"node":{"ID":4368,"Title":"New Terraform integrations with ServiceNow, GitHub, Confluent, VMware, Cisco, and more","Description":"New Terraform Cloud and community integration partners provide more options to automate and secure cloud infrastructure management.","PublishedAt":"2023-08-15 16:00:00+00:00","OriginURL":"https://www.hashicorp.com/blog/new-terraform-integrations-with-servicenow-github-confluent-vmware-cisco-and-more","SourceName":"HashiCorp"}},{"node":{"ID":4365,"Title":"Get to know the Elastic Community series: Meet Manuel Alba","Description":"","PublishedAt":"2023-08-15 13:00:00+00:00","OriginURL":"https://www.elastic.co/blog/get-to-know-the-elastic-community-series-meet-manuel-alba","SourceName":"Elastic"}},{"node":{"ID":4373,"Title":"Blog: Kubernetes v1.28: Planternetes","Description":"<p><strong>Authors</strong>: <a href=\"https://github.com/kubernetes/sig-release/blob/master/releases/release-1.28/release-team.md\">Kubernetes v1.28 Release Team</a></p>\n<p>Announcing the release of Kubernetes v1.28 Planternetes, the second release of 2023!</p>\n<p>This release consists of 45 enhancements. Of those enhancements, 19 are entering Alpha, 14 have graduated to Beta, and 12 have graduated to Stable.</p>\n<h2 id=\"release-theme-and-logo\">Release Theme And Logo</h2>\n<p><strong>Kubernetes v1.28: <em>Planternetes</em></strong></p>\n<p>The theme for Kubernetes v1.28 is <em>Planternetes</em>.</p>\n<figure class=\"release-logo\">\n<img src=\"https://kubernetes.io/images/blog/2023-08-15-kubernetes-1.28-blog/kubernetes-1.28.png\"\nalt=\"Kubernetes 1.28 Planternetes logo\"/>\n</figure>\n<p>Each Kubernetes release is the culmination of the hard work of thousands of individuals from our community. The people behind this release come from a wide range of backgrounds, some of us industry veterans, parents, others students and newcomers to open-source. We combine our unique experience to create a collective artifact with global impact.</p>\n<p>Much like a garden, our release has ever-changing growth, challenges and opportunities. This theme celebrates the meticulous care, intention and efforts to get the release to where we are today. Harmoniously together, we grow better.</p>\n<h1 id=\"what-s-new-major-themes\">What's New (Major Themes)</h1>\n<h2 id=\"changes-to-supported-skew-between-control-plane-and-node-versions\">Changes to supported skew between control plane and node versions</h2>\n<p>This enables testing and expanding the supported skew between core node and control plane components by one version from n-2 to n-3, so that node components (kubelet and kube-proxy) for the oldest supported minor version work with control plane components (kube-apiserver, kube-scheduler, kube-controller-manager, cloud-controller-manager) for the newest supported minor version.</p>\n<p>This is valuable for end users as control plane upgrade will be a little faster than node upgrade, which are almost always going to be the longer with running workloads.</p>\n<p>The Kubernetes yearly support period already makes annual upgrades possible. Users can upgrade to the latest patch versions to pick up security fixes and do 3 sequential minor version upgrades once a year to &quot;catch up&quot; to the latest supported minor version.</p>\n<p>However, since the tested/supported skew between nodes and control planes is currently limited to 2 versions, a 3-version upgrade would have to update nodes twice to stay within the supported skew.</p>\n<h2 id=\"generally-available-recovery-from-non-graceful-node-shutdown\">Generally available: recovery from non-graceful node shutdown</h2>\n<p>If a node shuts down down unexpectedly or ends up in a non-recoverable state (perhaps due to hardware failure or unresponsive OS), Kubernetes allows you to clean up afterwards and allow stateful workloads to restart on a different node. For Kubernetes v1.28, that's now a stable feature.</p>\n<p>This allows stateful workloads to failover to a different node successfully after the original node is shut down or in a non-recoverable state, such as the hardware failure or broken OS.</p>\n<p>Versions of Kubernetes earlier than v1.20 lacked handling for node shutdown on Linux, the kubelet integrates with systemd\nand implements graceful node shutdown (beta, and enabled by default). However, even an intentional\nshutdown might not get handled well that could be because:</p>\n<ul>\n<li>the node runs Windows</li>\n<li>the node runs Linux, but uses a different <code>init</code> (not <code>systemd</code>)</li>\n<li>the shutdown does not trigger the system inhibitor locks mechanism</li>\n<li>because of a node-level configuration error\n(such as not setting appropriate values for <code>shutdownGracePeriod</code> and <code>shutdownGracePeriodCriticalPods</code>).</li>\n</ul>\n<p>When a node shutdowns or fails, and that shutdown was not detected by the kubelet, the pods that are part\nof a StatefulSet will be stuck in terminating status on the shutdown node. If the stopped node restarts, the\nkubelet on that node can clean up (<code>DELETE</code>) the Pods that the Kubernetes API still sees as bound to that node.\nHowever, if the node stays stopped - or if the kubelet isn't able to start after a reboot - then Kubernetes may\nnot be able to create replacement Pods. When the kubelet on the shut-down node is not available to delete\nthe old pods, an associated StatefulSet cannot create a new pod (which would have the same name).</p>\n<p>There's also a problem with storage. If there are volumes used by the pods, existing VolumeAttachments will\nnot be disassociated from the original - and now shut down - node so the PersistentVolumes used by these\npods cannot be attached to a different, healthy node. As a result, an application running on an\naffected StatefulSet may not be able to function properly. If the original, shut down node does come up, then\ntheir pods will be deleted by its kubelet and new pods can be created on a different running node.\nIf the original node does not come up (common with an <a href=\"https://glossary.cncf.io/immutable-infrastructure/\">immutable infrastructure</a> design), those pods would be stuck in a <code>Terminating</code> status on the shut-down node forever.</p>\n<p>For more information on how to trigger cleanup after a non-graceful node shutdown,\nread <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#non-graceful-node-shutdown\">non-graceful node shutdown</a>.</p>\n<h2 id=\"improvements-to-customresourcedefinition-validation-rules\">Improvements to CustomResourceDefinition validation rules</h2>\n<p>The <a href=\"https://github.com/google/cel-go\">Common Expression Language (CEL)</a> can be used to validate\n<a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resources</a>. The primary goal is to allow the majority of the validation use cases that might once have needed you, as a CustomResourceDefinition (CRD) author, to design and implement a webhook. Instead, and as a beta feature, you can add <em>validation expressions</em> directly into the schema of a CRD.</p>\n<p>CRDs need direct support for non-trivial validation. While admission webhooks do support CRDs validation, they significantly complicate the development and operability of CRDs.</p>\n<p>In 1.28, two optional fields <code>reason</code> and <code>fieldPath</code> were added to allow user to specify the failure reason and fieldPath when validation failed.</p>\n<p>For more information, read <a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#validation-rules\">validation rules</a> in the CRD documentation.</p>\n<h2 id=\"validatingadmissionpolicies-graduate-to-beta\">ValidatingAdmissionPolicies graduate to beta</h2>\n<p>Common Expression language for admission control is customizable, in-process validation of requests to the Kubernetes API server as an alternative to validating admission webhooks.</p>\n<p>This builds on the capabilities of the CRD Validation Rules feature that graduated to beta in 1.25 but with a focus on the policy enforcement capabilities of validating admission control.</p>\n<p>This will lower the infrastructure barrier to enforcing customizable policies as well as providing primitives that help the community establish and adhere to the best practices of both K8s and its extensions.</p>\n<p>To use <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/validating-admission-policy/\">ValidatingAdmissionPolicies</a>, you need to enable both the <code>admissionregistration.k8s.io/v1beta1</code> API group and the <code>ValidatingAdmissionPolicy</code> feature gate in your cluster's control plane.</p>\n<h2 id=\"match-conditions-for-admission-webhooks\">Match conditions for admission webhooks</h2>\n<p>Kubernetes v1.27 lets you specify <em>match conditions</em> for admission webhooks,\nwhich lets you narrow the scope of when Kubernetes makes a remote HTTP call at admission time.\nThe <code>matchCondition</code> field for ValidatingWebhookConfiguration and MutatingWebhookConfiguration\nis a CEL expression that must evaluate to true for the admission request to be sent to the webhook.</p>\n<p>In Kubernetes v1.28, that field moved to beta, and it's enabled by default.</p>\n<p>To learn more, see <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#matching-requests-matchconditions\"><code>matchConditions</code></a> in the Kubernetes documentation.</p>\n<h2 id=\"beta-support-for-enabling-swap-space-on-linux\">Beta support for enabling swap space on Linux</h2>\n<p>This adds swap support to nodes in a controlled, predictable manner so that Kubernetes users can perform testing and provide data to continue building cluster capabilities on top of swap.</p>\n<p>There are two distinct types of users for swap, who may overlap:</p>\n<ul>\n<li>\n<p>Node administrators, who may want swap available for node-level performance tuning and stability/reducing noisy neighbor issues.</p>\n</li>\n<li>\n<p>Application developers, who have written applications that would benefit from using swap memory.</p>\n</li>\n</ul>\n<h2 id=\"mixed-version-proxy\">Mixed version proxy (alpha)</h2>\n<p>When a cluster has multiple API servers at mixed versions (such as during an upgrade/downgrade or when runtime-config changes and a rollout happens), not every apiserver can serve every resource at every version.</p>\n<p>For Kubernetes v1.28, you can enable the <em>mixed version proxy</em> within the API server's aggregation layer.\nThe mixed version proxy finds requests that the local API server doesn't recognize but another API server\ninside the control plan is able to support. Having found a suitable peer, the aggregation layer proxies\nthe request to a compatible API server; this is transparent from the client's perspective.</p>\n<p>When an upgrade or downgrade is performed on a cluster, for some period of time the API servers\nwithin the control plane may be at differing versions; when that happens, different subsets of the\nAPI servers are able to serve different sets of built-in resources (different groups, versions, and resources\nare all possible). This new alpha mechanism lets you hide that skew from clients.</p>\n<h2 id=\"source-code-reorganization-for-control-plane-components\">Source code reorganization for control plane components</h2>\n<p>Kubernetes contributors have begun to reorganize the code for the kube-apiserver to build on a new staging repository that consumes <a href=\"https://github.com/kubernetes/apiserver\">k/apiserver</a> but has a bigger, carefully chosen subset of the functionality of kube-apiserver such that it is reusable.</p>\n<p>This is a gradual reorganization; eventually there will be a new git repository with generic functionality abstracted from Kubernetes' API server.</p>\n<h2 id=\"cdi-device-plugin\">Support for CDI injection into containers (alpha)</h2>\n<p>CDI provides a standardized way of injecting complex devices into a container (i.e. devices that logically require more than just a single /dev node to be injected for them to work). This new feature enables plugin developers to utilize the CDIDevices field added to the CRI in 1.27 to pass CDI devices directly to CDI enabled runtimes (of which containerd and crio-o are in recent releases).</p>\n<h2 id=\"sidecar-init-containers\">API awareness of sidecar containers (alpha)</h2>\n<p>Kubernetes 1.28 introduces an alpha <code>restartPolicy</code> field for <a href=\"https://github.com/kubernetes/website/blob/main/content/en/docs/concepts/workloads/pods/init-containers.md\">init containers</a>,\nand uses that to indicate when an init container is also a <em>sidecar container</em>. The will start init containers with <code>restartPolicy: Always</code> in the order they are defined, along with other init containers. Instead of waiting for that sidecar container to complete before starting the main container(s) for the Pod, the kubelet only waits for\nthe sidecar init container to have started.</p>\n<p>The condition for startup completion will be that the startup probe succeeded (or if no startup probe is defined) and postStart handler is completed. This condition is represented with the field Started of ContainerStatus type. See the section &quot;Pod startup completed condition&quot; for considerations on picking this signal.</p>\n<p>For init containers, you can either omit the <code>restartPolicy</code> field, or set it to <code>Always</code>. Omitting the field\nmeans that you want a true init container that runs to completion before application startup.</p>\n<p>Sidecar containers do not block Pod completion: if all regular containers are complete, sidecar\ncontainers in that Pod will be terminated.</p>\n<p>For sidecar containers, the restart behavior is more complex than for init containers. In a Pod with\n<code>restartPolicy</code> set to <code>Never</code>, a sidecar container that fails during Pod startup will <strong>not</strong> be restarted\nand the whole Pod is treated as having failed. If the Pod's <code>restartPolicy</code> is <code>Always</code> or <code>OnFailure</code>,\na sidecar that fails to start will be retried.</p>\n<p>Once the sidecar container has started (process running, <code>postStart</code> was successful, and\nany configured startup probe is passing), and then there's a failure, that sidecar container will be\nrestarted even when the Pod's overall <code>restartPolicy</code> is <code>Never</code> or <code>OnFailure</code>.\nFurthermore, sidecar containers will be restarted (on failure or on normal exit)\n<em>even during Pod termination</em>.</p>\n<p>To learn more, read <a href=\"https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#api-for-sidecar-containers\">API for sidecar containers</a>.</p>\n<h2 id=\"automatic-retroactive-assignment-of-a-default-storageclass-graduates-to-stable\">Automatic, retroactive assignment of a default StorageClass graduates to stable</h2>\n<p>Kubernetes automatically sets a <code>storageClassName</code> for a PersistentVolumeClaim (PVC) if you don't provide\na value. The control plane also sets a StorageClass for any existing PVC that doesn't have a <code>storageClassName</code>\ndefined.\nPrevious versions of Kubernetes also had this behavior; for Kubernetes v1.28 is is automatic and always\nactive; the feature has graduated to stable (general availability).</p>\n<p>To learn more, read about <a href=\"https://kubernetes.io/docs/concepts/storage/storage-classes/\">StorageClass</a> in the Kubernetes\ndocumentation.</p>\n<h2 id=\"pod-replacement-policy\">Pod replacement policy for Jobs (alpha)</h2>\n<p>Kubernetes 1.28 adds a new field for the Job API that allows you to specify if you want the control\nplane to make new Pods as soon as the previous Pods begin termination (existing behavior),\nor only once the existing pods are fully terminated (new, optional behavior).</p>\n<p>Many common machine learning frameworks, such as Tensorflow and JAX, require unique pods per index.\nWith the older behaviour, if a pod that belongs to an <code>Indexed</code> Job enters a terminating state (due to preemption, eviction or other external factors), a replacement pod is created but then immediately fails to start due\nto the clash with the old pod that has not yet shut down.</p>\n<p>Having a replacement Pod appear before the previous one fully terminates can also cause problems\nin clusters with scarce resources or with tight budgets. These resources can be difficult to obtain so pods may only be able to find nodes once the existing pods have been terminated. If cluster autoscaler is enabled, early creation of replacement Pods might produce undesired scale-ups.</p>\n<p>To learn more, read <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#delayed-creation-of-replacement-pods\">Delayed creation of replacement pods</a>\nin the Job documentation.</p>\n<h2 id=\"job-per-index-retry-backoff\">Job retry backoff limit, per index (alpha)</h2>\n<p>This extends the Job API to support indexed jobs where the backoff limit is per index, and the Job can continue execution despite some of its indexes failing.</p>\n<p>Currently, the indexes of an indexed job share a single backoff limit. When the job reaches this shared backoff limit, the job controller marks the entire job as failed, and the resources are cleaned up, including indexes that have yet to run to completion.</p>\n<p>As a result, the existing implementation did not cover the situation where the workload is truly\n<a href=\"https://en.wikipedia.org/wiki/Embarrassingly_parallel\">embarrassingly parallel</a>: each index is\nfully independent of other indexes.</p>\n<p>For instance, if indexed jobs were used as the basis for a suite of long-running integration tests, then each test run would only be able to find a single test failure.</p>\n<p>For more information, read <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/job/#handling-pod-and-container-failures\">Handling Pod and container failures</a> in the Kubernetes documentation.</p>\n<h2 id=\"cri-container-and-pod-statistics-without-cadvisor\">CRI container and pod statistics without cAdvisor</h2>\n<p>This encompasses two related pieces of work (changes to the kubelet's <code>/metrics/cadvisor</code> endpoint and improvements to the replacement <em>summary</em> API).</p>\n<p>There are two main APIs that consumers use to gather stats about running containers and pods: summary API and <code>/metrics/cadvisor</code>. The Kubelet is responsible for implementing the summary API, and cadvisor is responsible for fulfilling <code>/metrics/cadvisor</code>.</p>\n<p>This enhances CRI implementations to be able to fulfill all the stats needs of Kubernetes. At a high level, there are two pieces of this:</p>\n<ul>\n<li>\n<p>It enhances the CRI API with enough metrics to supplement the pod and container fields in the summary API directly from CRI.</p>\n</li>\n<li>\n<p>It enhances the CRI implementations to broadcast the required metrics to fulfill the pod and container fields in the <code>/metrics/cadvisor</code> endpoint.</p>\n</li>\n</ul>\n<h2 id=\"feature-graduations-and-deprecations-in-kubernetes-v1-28\">Feature graduations and deprecations in Kubernetes v1.28</h2>\n<h3 id=\"graduations-to-stable\">Graduations to stable</h3>\n<p>This release includes a total of 12 enhancements promoted to Stable:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1440\"><code>kubectl events</code></a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3333\">Retroactive default StorageClass assignment</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2268\">Non-graceful node shutdown</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/606\">Support 3rd party device monitoring plugins</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3325\">Auth API to get self-user attributes</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1669\">Proxy Terminating Endpoints</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2595\">Expanded DNS Configuration</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3178\">Cleaning up IPTables Chain Ownership</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3453\">Minimizing iptables-restore input size</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3743\">Graduate the kubelet pod resources endpoint to GA</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2403\">Extend podresources API to report allocatable resources</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/3685\">Move EndpointSlice Reconciler into Staging</a></li>\n</ul>\n<h3 id=\"deprecations-and-removals\">Deprecations and removals</h3>\n<p>Removals:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1488\">Removal of CSI Migration for GCE PD</a></li>\n</ul>\n<p>Deprecations:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/kubernetes/pull/118303\">Ceph RBD in-tree plugin</a></li>\n<li><a href=\"https://github.com/kubernetes/kubernetes/pull/118143\">Ceph FS in-tree plugin</a></li>\n</ul>\n<h2 id=\"release-notes\">Release Notes</h2>\n<p>The complete details of the Kubernetes v1.28 release are available in our <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.28.md\">release notes</a>.</p>\n<h2 id=\"availability\">Availability</h2>\n<p>Kubernetes v1.28 is available for download on <a href=\"https://github.com/kubernetes/kubernetes/releases/tag/v1.28.0\">GitHub</a>. To get started with Kubernetes, you can run local Kubernetes clusters using <a href=\"https://minikube.sigs.k8s.io/docs/\">minikube</a>, <a href=\"https://kind.sigs.k8s.io/\">kind</a>, etc. You can also easily install v1.28 using <a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\">kubeadm</a>.</p>\n<h2 id=\"release-team\">Release Team</h2>\n<p>Kubernetes is only possible with the support, commitment, and hard work of its community. Each release team is comprised of dedicated community volunteers who work together to build the many pieces that make up the Kubernetes releases you rely on. This requires the specialized skills of people from all corners of our community, from the code itself to its documentation and project management.</p>\n<p>We would like to thank the entire release team for the hours spent hard at work to ensure we deliver a solid Kubernetes v1.28 release for our community.</p>\n<p>Special thanks to our release lead, Grace Nguyen, for guiding us through a smooth and successful release cycle.</p>\n<h2 id=\"ecosystem-updates\">Ecosystem Updates</h2>\n<ul>\n<li>KubeCon + CloudNativeCon China 2023 will take place in Shanghai, China, from 26 – 28 September 2023! You can find more information about the conference and registration on the <a href=\"https://www.lfasiallc.com/kubecon-cloudnativecon-open-source-summit-china/\">event site</a>.</li>\n<li>KubeCon + CloudNativeCon North America 2023 will take place in Chicago, Illinois, The United States of America, from 6 – 9 November 2023! You can find more information about the conference and registration on the <a href=\"https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/\">event site</a>.</li>\n</ul>\n<h2 id=\"project-velocity\">Project Velocity</h2>\n<p>The <a href=\"https://k8s.devstats.cncf.io/d/12/dashboards?orgId=1&amp;refresh=15m\">CNCF K8s DevStats</a> project aggregates a number of interesting data points related to the velocity of Kubernetes and various sub-projects. This includes everything from individual contributions to the number of companies that are contributing and is an illustration of the depth and breadth of effort that goes into evolving this ecosystem.</p>\n<p>In the v1.28 release cycle, which <a href=\"https://github.com/kubernetes/sig-release/tree/master/releases/release-1.28\">ran for 14 weeks</a> (May 15 to August 15), we saw contributions from <a href=\"https://k8s.devstats.cncf.io/d/9/companies-table?orgId=1&amp;var-period_name=v1.27.0%20-%20now&amp;var-metric=contributions\">911 companies</a> and <a href=\"https://k8s.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&amp;var-period_name=v1.27.0%20-%20now&amp;var-metric=contributions&amp;var-repogroup_name=Kubernetes&amp;var-repo_name=kubernetes%2Fkubernetes&amp;var-country_name=All&amp;var-companies=All\">1440 individuals</a>.</p>\n<h2 id=\"upcoming-release-webinar\">Upcoming Release Webinar</h2>\n<p>Join members of the Kubernetes v1.28 release team on Friday, September 14, 2023, at 10 a.m. PDT to learn about the major features of this release, as well as deprecations and removals to help plan for upgrades. For more information and registration, visit the <a href=\"https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-live-webinar-kubernetes-v128-release/\">event page</a> on the CNCF Online Programs site.</p>\n<h2 id=\"get-involved\">Get Involved</h2>\n<p>The simplest way to get involved with Kubernetes is by joining one of the many <a href=\"https://github.com/kubernetes/community/blob/master/sig-list.md\">Special Interest Groups</a> (SIGs) that align with your interests.</p>\n<p>Have something you’d like to broadcast to the Kubernetes community? Share your voice at our weekly <a href=\"https://github.com/kubernetes/community/tree/master/communication\">community meeting</a>, and through the channels below:</p>\n<ul>\n<li>\n<p>Find out more about contributing to Kubernetes at the <a href=\"https://www.kubernetes.dev/\">Kubernetes Contributors website</a>.</p>\n</li>\n<li>\n<p>Follow us on Twitter <a href=\"https://twitter.com/kubernetesio\">@Kubernetesio</a> for the latest updates.</p>\n</li>\n<li>\n<p>Join the community discussion on <a href=\"https://discuss.kubernetes.io/\">Discuss</a>.</p>\n</li>\n<li>\n<p>Join the community on <a href=\"https://communityinviter.com/apps/kubernetes/community\">Slack</a>.</p>\n</li>\n<li>\n<p>Post questions (or answer questions) on <a href=\"https://serverfault.com/questions/tagged/kubernetes\">Server Fault</a>.</p>\n</li>\n<li>\n<p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform\">Share</a> your Kubernetes story.</p>\n</li>\n<li>\n<p>Read more about what’s happening with Kubernetes on the <a href=\"https://kubernetes.io/blog/\">blog</a>.</p>\n</li>\n<li>\n<p>Learn more about the <a href=\"https://github.com/kubernetes/sig-release/tree/master/release-team\">Kubernetes Release Team</a>.</p>\n</li>\n</ul>","PublishedAt":"2023-08-15 12:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2023/08/15/kubernetes-v1-28-release/","SourceName":"Kubernetes"}},{"node":{"ID":4394,"Title":"Want better answers from your data? Ask better questions (Ep. 599)","Description":"<p>Tim Tutt, CEO and cofounder of Night Shift Development, tells the home team about his work in deploying large-scale search and discovery analytics, why he’s working to help nontechnical users understand and utilize their business data, and how GenAI is teaching people to ask better questions.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://stackoverflow.blog/2023/08/15/want-better-answers-from-your-data-ask-better-questions/\">Want better answers from your data? Ask better questions (Ep. 599)</a> appeared first on <a rel=\"nofollow\" href=\"https://stackoverflow.blog\">Stack Overflow Blog</a>.</p>\n","PublishedAt":"2023-08-15 04:40:00+00:00","OriginURL":"https://stackoverflow.blog/2023/08/15/want-better-answers-from-your-data-ask-better-questions/","SourceName":"Stack Overflow"}},{"node":{"ID":4366,"Title":"Managing your applications on Amazon ECS EC2-based clusters with Elastic Observability","Description":"","PublishedAt":"2023-08-15 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/manage-applications-amazon-ecs-ec2-based-clusters-elastic-observability","SourceName":"Elastic"}},{"node":{"ID":4369,"Title":"Someone Like Me: Wes Mason navigates his recent ADHD diagnosis and offers tips for coping","Description":"","PublishedAt":"2023-08-15 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/culture-wes-anderson-adhd-tips-for-coping","SourceName":"Elastic"}},{"node":{"ID":4371,"Title":"Why cybersecurity is a perfect storm for the public sector","Description":"","PublishedAt":"2023-08-15 00:00:00+00:00","OriginURL":"https://www.elastic.co/blog/cybersecurity-perfect-storm-public-sector","SourceName":"Elastic"}},{"node":{"ID":4363,"Title":"AWS Weekly Roundup – Amazon MWAA, EMR Studio, Generative AI, and More – August 14, 2023","Description":"While I enjoyed a few days off in California to get a dose of vitamin sea, a lot has happened in the AWS universe. Let’s take a look together! Last Week’s Launches Here are some launches that got my attention: Amazon MWAA now supports Apache Airflow version 2.6 – Amazon Managed Workflows for Apache Airflow […]","PublishedAt":"2023-08-14 17:22:05+00:00","OriginURL":"https://aws.amazon.com/blogs/aws/aws-weekly-roundup-amazon-mwaa-emr-studio-generative-ai-and-more-august-14-2023/","SourceName":"AWS"}}]}},"pageContext":{"limit":30,"skip":300,"numPages":158,"currentPage":11}},"staticQueryHashes":["3649515864"]}