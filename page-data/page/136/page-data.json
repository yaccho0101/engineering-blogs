{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/136","result":{"data":{"allPost":{"edges":[{"node":{"ID":247,"Title":"Driving Industry Transformation Through the Use of Data","Description":"<p>Use cases showing how your data strategy can create massive business impact</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/driving-industry-transformation-through-the-use-of-data/\">Driving Industry Transformation Through the Use of Data</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-09 13:59:31+00:00","OriginURL":"https://blog.cloudera.com/driving-industry-transformation-through-the-use-of-data/","SourceName":"Cloudera"}},{"node":{"ID":1242,"Title":"Blog: Kubernetes 1.23: Pod Security Graduates to Beta","Description":"<p><strong>Authors:</strong> Jim Angel (Google), Lachlan Evenson (Microsoft)</p>\n<p>With the release of Kubernetes v1.23, <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security admission</a> has now entered beta. Pod Security is a <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/\">built-in</a> admission controller that evaluates pod specifications against a predefined set of <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/\">Pod Security Standards</a> and determines whether to <code>admit</code> or <code>deny</code> the pod from running.</p>\n<p>Pod Security is the successor to <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-policy/\">PodSecurityPolicy</a> which was deprecated in the v1.21 release, and will be removed in Kubernetes v1.25. In this article, we cover the key concepts of Pod Security along with how to use it. We hope that cluster administrators and developers alike will use this new mechanism to enforce secure defaults for their workloads.</p>\n<h2 id=\"why-pod-security\">Why Pod Security</h2>\n<p>The overall aim of Pod Security is to let you isolate workloads. You can run a cluster that runs different workloads and, without adding extra third-party tooling, implement controls that require Pods for a workload to restrict their own privileges to a defined bounding set.</p>\n<p>Pod Security overcomes key shortcomings of Kubernetes' existing, but deprecated, PodSecurityPolicy (PSP) mechanism:</p>\n<ul>\n<li>Policy authorization model — challenging to deploy with controllers.</li>\n<li>Risks around switching — a lack of dry-run/audit capabilities made it hard to enable PodSecurityPolicy.</li>\n<li>Inconsistent and Unbounded API — the large configuration surface and evolving constraints led to a complex and confusing API.</li>\n</ul>\n<p>The shortcomings of PSP made it very difficult to use which led the community to reevaluate whether or not a better implementation could achieve the same goals. One of those goals was to provide an out-of-the-box solution to apply security best practices. Pod Security ships with predefined Pod Security levels that a cluster administrator can configure to meet the desired security posture.</p>\n<p>It's important to note that Pod Security doesn't have complete feature parity with the deprecated PodSecurityPolicy. Specifically, it doesn't have the ability to mutate or change Kubernetes resources to auto-remediate a policy violation on behalf of the user. Additionally, it doesn't provide fine-grained control over each allowed field and value within a pod specification or any other Kubernetes resource that you may wish to evaluate. If you need more fine-grained policy control then take a look at these <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/#faq\">other</a> projects which support such use cases.</p>\n<p>Pod Security also adheres to Kubernetes best practices of declarative object management by denying resources that violate the policy. This requires resources to be updated in source repositories, and tooling to be updated prior to being deployed to Kubernetes.</p>\n<h2 id=\"how-does-pod-security-work\">How Does Pod Security Work?</h2>\n<p>Pod Security is a built-in <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/\">admission controller</a> starting with Kubernetes v1.22, but can also be run as a standalone <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/#webhook\">webhook</a>. Admission controllers function by intercepting requests in the Kubernetes API server prior to persistence to storage. They can either <code>admit</code> or <code>deny</code> a request. In the case of Pod Security, pod specifications will be evaluated against a configured policy in the form of a Pod Security Standard. This means that security sensitive fields in a pod specification will only be allowed to have <a href=\"h/docs/concepts/security/pod-security-standards/#profile-details\">specific</a> values.</p>\n<h2 id=\"configuring-pod-security\">Configuring Pod Security</h2>\n<h3 id=\"pod-security-standards\">Pod Security Standards</h3>\n<p>In order to use Pod Security we first need to understand <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/\">Pod Security Standards</a>. These standards define three different policy levels that range from permissive to restrictive. These levels are as follows:</p>\n<ul>\n<li><code>privileged</code> — open and unrestricted</li>\n<li><code>baseline</code> — Covers known privilege escalations while minimizing restrictions</li>\n<li><code>restricted</code> — Highly restricted, hardening against known and unknown privilege escalations. May cause compatibility issues</li>\n</ul>\n<p>Each of these policy levels define which fields are restricted within a pod specification and the allowed values. Some of the fields restricted by these policies include:</p>\n<ul>\n<li><code>spec.securityContext.sysctls</code></li>\n<li><code>spec.hostNetwork</code></li>\n<li><code>spec.volumes[*].hostPath</code></li>\n<li><code>spec.containers[*].securityContext.privileged</code></li>\n</ul>\n<p>Policy levels are applied via labels on Namespace resources, which allows for granular per-namespace policy selection. The AdmissionConfiguration in the API server can also be configured to set cluster-wide default levels and exemptions.</p>\n<h3 id=\"policy-modes\">Policy modes</h3>\n<p>Policies are applied in a specific mode. Multiple modes (with different policy levels) can be set on the same namespace. Here is a list of modes:</p>\n<ul>\n<li><code>enforce</code> — Any Pods that violate the policy will be rejected</li>\n<li><code>audit</code> — Violations will be recorded as an annotation in the audit logs, but don't affect whether the pod is allowed.</li>\n<li><code>warn</code> — Violations will send a warning message back to the user, but don't affect whether the pod is allowed.</li>\n</ul>\n<p>In addition to modes you can also pin the policy to a specific version (for example v1.22). Pinning to a specific version allows the behavior to remain consistent if the policy definition changes in future Kubernetes releases.</p>\n<h2 id=\"hands-on-demo\">Hands on demo</h2>\n<h3 id=\"prerequisites\">Prerequisites</h3>\n<ul>\n<li><a href=\"https://kind.sigs.k8s.io/docs/user/quick-start/#installation\">KinD</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/tools/\">kubectl</a></li>\n<li><a href=\"https://docs.docker.com/get-docker/\">Docker</a> or <a href=\"https://podman.io/getting-started/installation\">Podman</a> container runtime &amp; CLI</li>\n</ul>\n<h3 id=\"deploy-a-kind-cluster\">Deploy a kind cluster</h3>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kind create cluster --image kindest/node:v1.23.0\n</span></span></code></pre></div><p>It might take a while to start and once it's started it might take a minute or so before the node becomes ready.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl cluster-info --context kind-kind\n</span></span></code></pre></div><p>Wait for the node STATUS to become ready.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl get nodes\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>NAME STATUS ROLES AGE VERSION\nkind-control-plane Ready control-plane,master 54m v1.23.0\n</code></pre><h3 id=\"confirm-pod-security-is-enabled\">Confirm Pod Security is enabled</h3>\n<p>The best way to <a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#which-plugins-are-enabled-by-default\">confirm the API's default enabled plugins</a> is to check the Kubernetes API container's help arguments.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl -n kube-system <span style=\"color:#a2f\">exec</span> kube-apiserver-kind-control-plane -it -- kube-apiserver -h | grep <span style=\"color:#b44\">&#34;default enabled ones&#34;</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>...\n--enable-admission-plugins strings\nadmission plugins that should be enabled in addition\nto default enabled ones (NamespaceLifecycle, LimitRanger,\nServiceAccount, TaintNodesByCondition, PodSecurity, Priority,\nDefaultTolerationSeconds, DefaultStorageClass,\nStorageObjectInUseProtection, PersistentVolumeClaimResize,\nRuntimeClass, CertificateApproval, CertificateSigning,\nCertificateSubjectRestriction, DefaultIngressClass,\nMutatingAdmissionWebhook, ValidatingAdmissionWebhook,\nResourceQuota).\n...\n</code></pre><p><code>PodSecurity</code> is listed in the group of default enabled admission plugins.</p>\n<p>If using a cloud provider, or if you don't have access to the API server, the best way to check would be to run a quick end-to-end test:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl create namespace verify-pod-security\n</span></span><span style=\"display:flex;\"><span>kubectl label namespace verify-pod-security pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>restricted\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># The following command does NOT create a workload (--dry-run=server)</span>\n</span></span><span style=\"display:flex;\"><span>kubectl -n verify-pod-security run <span style=\"color:#a2f\">test</span> --dry-run<span style=\"color:#666\">=</span>server --image<span style=\"color:#666\">=</span>busybox --privileged\n</span></span><span style=\"display:flex;\"><span>kubectl delete namespace verify-pod-security\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Error from server (Forbidden): pods &#34;test&#34; is forbidden: violates PodSecurity &#34;restricted:latest&#34;: privileged (container &#34;test&#34; must not set securityContext.privileged=true), allowPrivilegeEscalation != false (container &#34;test&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &#34;test&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;test&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;test&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\n</code></pre><h3 id=\"configure-pod-security\">Configure Pod Security</h3>\n<p>Policies are applied to a namespace via labels. These labels are as follows:</p>\n<ul>\n<li><code>pod-security.kubernetes.io/&lt;MODE&gt;: &lt;LEVEL&gt;</code> (required to enable pod security)</li>\n<li><code>pod-security.kubernetes.io/&lt;MODE&gt;-version: &lt;VERSION&gt;</code> (<em>optional</em>, defaults to latest)</li>\n</ul>\n<p>A specific version can be supplied for each enforcement mode. The version pins the policy to the version that was shipped as part of the Kubernetes release. Pinning to a specific Kubernetes version allows for deterministic policy behavior while allowing flexibility for future updates to Pod Security Standards. The possible &lt;MODE(S)&gt; are <code>enforce</code>, <code>audit</code> and <code>warn</code>.</p>\n<h3 id=\"when-to-use-warn\">When to use <code>warn</code>?</h3>\n<p>The typical uses for <code>warn</code> are to get ready for a future change where you want to enforce a different policy. The most two common cases would be:</p>\n<ul>\n<li><code>warn</code> at the same level but a different version (e.g. pin <code>enforce</code> to <em>restricted+v1.23</em> and <code>warn</code> at <em>restricted+latest</em>)</li>\n<li><code>warn</code> at a stricter level (e.g. <code>enforce</code> baseline, <code>warn</code> restricted)</li>\n</ul>\n<p>It's not recommended to use <code>warn</code> for the exact same level+version of the policy as <code>enforce</code>. In the admission sequence, if <code>enforce</code> fails, the entire sequence fails before evaluating the <code>warn</code>.</p>\n<p>First, create a namespace called <code>verify-pod-security</code> if not created earlier. For the demo, <code>--overwrite</code> is used when labeling to allow repurposing a single namespace for multiple examples.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl create namespace verify-pod-security\n</span></span></code></pre></div><h3 id=\"deploy-demo-workloads\">Deploy demo workloads</h3>\n<p>Each workload represents a higher level of security that would not pass the profile that comes after it.</p>\n<p>For the following examples, use the <code>busybox</code> container runs a <code>sleep</code> command for 1 million seconds (≅11 days) or until deleted. Pod Security is not interested in which container image you chose, but rather the Pod level settings and their implications for security.</p>\n<h3 id=\"privileged-level-and-workload\">Privileged level and workload</h3>\n<p>For the privileged pod, use the <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/#privileged\">privileged policy</a>. This allows the process inside a container to gain new processes (also known as &quot;privilege escalation&quot;) and can be dangerous if untrusted.</p>\n<p>First, let's apply a restricted Pod Security level for a test.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># enforces a &#34;restricted&#34; security policy and audits on restricted</span>\n</span></span><span style=\"display:flex;\"><span>kubectl label --overwrite ns verify-pod-security <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>restricted <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/audit<span style=\"color:#666\">=</span>restricted\n</span></span></code></pre></div><p>Next, try to deploy a privileged workload in the namespace.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-privileged\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Error from server (Forbidden): error when creating &#34;STDIN&#34;: pods &#34;busybox-privileged&#34; is forbidden: violates PodSecurity &#34;restricted:latest&#34;: allowPrivilegeEscalation != false (container &#34;busybox&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &#34;busybox&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;busybox&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;busybox&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\n</code></pre><p>Now let's apply the privileged Pod Security level and try again.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># enforces a &#34;privileged&#34; security policy and warns / audits on baseline</span>\n</span></span><span style=\"display:flex;\"><span>kubectl label --overwrite ns verify-pod-security <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>privileged <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/warn<span style=\"color:#666\">=</span>baseline <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/audit<span style=\"color:#666\">=</span>baseline\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-privileged\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>pod/busybox-privileged created\n</code></pre><p>We can run <code>kubectl -n verify-pod-security get pods</code> to verify it is running. Clean up with:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl -n verify-pod-security delete pod busybox-privileged\n</span></span></code></pre></div><h3 id=\"baseline-level-and-workload\">Baseline level and workload</h3>\n<p>The <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/#baseline\">baseline policy</a> demonstrates sensible defaults while preventing common container exploits.</p>\n<p>Let's revert back to a restricted Pod Security level for a quick test.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># enforces a &#34;restricted&#34; security policy and audits on restricted</span>\n</span></span><span style=\"display:flex;\"><span>kubectl label --overwrite ns verify-pod-security <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>restricted <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/audit<span style=\"color:#666\">=</span>restricted\n</span></span></code></pre></div><p>Apply the workload.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-baseline\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: false\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> capabilities:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> add:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - NET_BIND_SERVICE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - CHOWN\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Error from server (Forbidden): error when creating &#34;STDIN&#34;: pods &#34;busybox-baseline&#34; is forbidden: violates PodSecurity &#34;restricted:latest&#34;: unrestricted capabilities (container &#34;busybox&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]; container &#34;busybox&#34; must not include &#34;CHOWN&#34; in securityContext.capabilities.add), runAsNonRoot != true (pod or container &#34;busybox&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;busybox&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\n</code></pre><p>Let's apply the baseline Pod Security level and try again.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># enforces a &#34;baseline&#34; security policy and warns / audits on restricted</span>\n</span></span><span style=\"display:flex;\"><span>kubectl label --overwrite ns verify-pod-security <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>baseline <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/warn<span style=\"color:#666\">=</span>restricted <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/audit<span style=\"color:#666\">=</span>restricted\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-baseline\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: false\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> capabilities:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> add:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - NET_BIND_SERVICE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - CHOWN\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to the following. Note that the warnings match the error message from the test above, but the pod is still successfully created.</p>\n<pre tabindex=\"0\"><code>Warning: would violate PodSecurity &#34;restricted:latest&#34;: unrestricted capabilities (container &#34;busybox&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]; container &#34;busybox&#34; must not include &#34;CHOWN&#34; in securityContext.capabilities.add), runAsNonRoot != true (pod or container &#34;busybox&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;busybox&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\npod/busybox-baseline created\n</code></pre><p>Remember, we set the <code>verify-pod-security</code> namespace to <code>warn</code> based on the restricted profile. We can run <code>kubectl -n verify-pod-security get pods</code> to verify it is running. Clean up with:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl -n verify-pod-security delete pod busybox-baseline\n</span></span></code></pre></div><h3 id=\"restricted-level-and-workload\">Restricted level and workload</h3>\n<p>The <a href=\"https://kubernetes.io/docs/concepts/security/pod-security-standards/#restricted\">restricted policy</a> requires rejection of all privileged parameters. It is the most secure with a trade-off for complexity.\nThe restricted policy allows containers to add the <code>NET_BIND_SERVICE</code> capability only.</p>\n<p>While we've already tested restricted as a blocking function, let's try to get something running that meets all the criteria.</p>\n<p>First we need to reapply the restricted profile, for the last time.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># enforces a &#34;restricted&#34; security policy and audits on restricted</span>\n</span></span><span style=\"display:flex;\"><span>kubectl label --overwrite ns verify-pod-security <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/enforce<span style=\"color:#666\">=</span>restricted <span style=\"color:#b62;font-weight:bold\">\\\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b62;font-weight:bold\"></span> pod-security.kubernetes.io/audit<span style=\"color:#666\">=</span>restricted\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-restricted\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: false\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> capabilities:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> add:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - NET_BIND_SERVICE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Error from server (Forbidden): error when creating &#34;STDIN&#34;: pods &#34;busybox-restricted&#34; is forbidden: violates PodSecurity &#34;restricted:latest&#34;: unrestricted capabilities (container &#34;busybox&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;busybox&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;busybox&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\n</code></pre><p>This is because the restricted profile explicitly requires that certain values are set to the most secure parameters.</p>\n<p>By requiring explicit values, manifests become more declarative and your entire security model can shift left. With the <code>restricted</code> level of enforcement, a company could audit their cluster's compliance based on permitted manifests.</p>\n<p>Let's fix each warning resulting in the following file:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-restricted\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> seccompProfile:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> type: RuntimeDefault\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> runAsNonRoot: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: false\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> capabilities:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> drop:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - ALL\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> add:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - NET_BIND_SERVICE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>pod/busybox-restricted created\n</code></pre><p>Run <code>kubectl -n verify-pod-security get pods</code> to verify it is running. The output is similar to this:</p>\n<pre tabindex=\"0\"><code>NAME READY STATUS RESTARTS AGE\nbusybox-restricted 0/1 CreateContainerConfigError 0 2m26s\n</code></pre><p>Let's figure out why the container is not starting with <code>kubectl -n verify-pod-security describe pod busybox-restricted</code>. The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Events:\nType Reason Age From Message\n---- ------ ---- ---- -------\nWarning Failed 2m29s (x8 over 3m55s) kubelet Error: container has runAsNonRoot and image will run as root (pod: &#34;busybox-restricted_verify-pod-security(a4c6a62d-2166-41a9-b288-20df17cf5c90)&#34;, container: busybox)\n</code></pre><p>To solve this, set the effective UID (<code>runAsUser</code>) to a non-zero (root) value or use the <code>nobody</code> UID (65534).</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># delete the original pod</span>\n</span></span><span style=\"display:flex;\"><span>kubectl -n verify-pod-security delete pod busybox-restricted\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># create the pod again with new runAsUser</span>\n</span></span><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n verify-pod-security apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-restricted\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> runAsUser: 65534\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> seccompProfile:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> type: RuntimeDefault\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> runAsNonRoot: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: false\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> capabilities:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> drop:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - ALL\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> add:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - NET_BIND_SERVICE\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>Run <code>kubectl -n verify-pod-security get pods</code> to verify it is running. The output is similar to this:</p>\n<pre tabindex=\"0\"><code>NAME READY STATUS RESTARTS AGE\nbusybox-restricted 1/1 Running 0 25s\n</code></pre><p>Clean up the demo (restricted pod and namespace) with:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl delete namespace verify-pod-security\n</span></span></code></pre></div><p>At this point, if you wanted to dive deeper into linux permissions or what is permitted for a certain container, exec into the control plane and play around with <code>containerd</code> and <code>crictl inspect</code>.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># if using docker, shell into the control plane</span>\n</span></span><span style=\"display:flex;\"><span>docker <span style=\"color:#a2f\">exec</span> -it kind-control-plane bash\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># list running containers</span>\n</span></span><span style=\"display:flex;\"><span>crictl ps\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># inspect each one by container ID</span>\n</span></span><span style=\"display:flex;\"><span>crictl inspect &lt;CONTAINER ID&gt;\n</span></span></code></pre></div><h3 id=\"applying-a-cluster-wide-policy\">Applying a cluster-wide policy</h3>\n<p>In addition to applying labels to namespaces to configure policy you can also configure cluster-wide policies and exemptions using the AdmissionConfiguration resource.</p>\n<p>Using this resource, policy definitions are applied cluster-wide by default and any policy that is applied via namespace labels will take precedence.</p>\n<p>There is no runtime configurable API for the <code>AdmissionConfiguration</code> configuration file so a cluster administrator would need to specify a path to the file below via the <code>--admission-control-config-file</code> flag on the API server.</p>\n<p>In the following resource we are enforcing the baseline policy and warning and auditing the baseline policy. We are also making the kube-system namespace exempt from this policy.</p>\n<p>It's not recommended to alter control plane / clusters after install, so let's build a new cluster with a default policy on all namespaces.</p>\n<p>First, delete the current cluster.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kind delete cluster\n</span></span></code></pre></div><p>Create a Pod Security configuration that <code>enforce</code> and <code>audit</code> baseline policies while using a restricted profile to <code>warn</code> the end user.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF &gt; pod-security.yaml\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: apiserver.config.k8s.io/v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: AdmissionConfiguration\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">plugins:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">- name: PodSecurity\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> configuration:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> apiVersion: pod-security.admission.config.k8s.io/v1beta1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> kind: PodSecurityConfiguration\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> defaults:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> enforce: &#34;baseline&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> enforce-version: &#34;latest&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> audit: &#34;baseline&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> audit-version: &#34;latest&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> warn: &#34;restricted&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> warn-version: &#34;latest&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> exemptions:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # Array of authenticated usernames to exempt.\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> usernames: []\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # Array of runtime class names to exempt.\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> runtimeClasses: []\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # Array of namespaces to exempt.\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> namespaces: [kube-system]\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>For additional options, check out the official <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-admission-controller/#configure-the-admission-controller\"><em>standards admission controller</em></a> docs.</p>\n<p>We now have a default baseline policy. Next pass it to the kind configuration to enable the <code>--admission-control-config-file</code> API server argument and pass the policy file. To pass a file to a kind cluster, use a configuration file to pass additional setup instructions. Kind uses <code>kubeadm</code> to provision the cluster and the configuration file has the ability to pass <code>kubeadmConfigPatches</code> for further customization. In our case, the local file is mounted into the control plane node as <code>/etc/kubernetes/policies/pod-security.yaml</code> which is then mounted into the <code>apiServer</code> container. We also pass the <code>--admission-control-config-file</code> argument pointing to the policy's location.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF &gt; kind-config.yaml\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Cluster\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: kind.x-k8s.io/v1alpha4\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">nodes:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">- role: control-plane\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> kubeadmConfigPatches:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - |\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> kind: ClusterConfiguration\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> apiServer:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # enable admission-control-config flag on the API server\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> extraArgs:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> admission-control-config-file: /etc/kubernetes/policies/pod-security.yaml\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # mount new file / directories on the control plane\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> extraVolumes:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: policies\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> hostPath: /etc/kubernetes/policies\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> mountPath: /etc/kubernetes/policies\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> readOnly: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> pathType: &#34;DirectoryOrCreate&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> # mount the local file on the control plane\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> extraMounts:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - hostPath: ./pod-security.yaml\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containerPath: /etc/kubernetes/policies/pod-security.yaml\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> readOnly: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>Create a new cluster using the kind configuration file defined above.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kind create cluster --image kindest/node:v1.23.0 --config kind-config.yaml\n</span></span></code></pre></div><p>Let's look at the default namespace.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl describe namespace default\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Name: default\nLabels: kubernetes.io/metadata.name=default\nAnnotations: &lt;none&gt;\nStatus: Active\nNo resource quota.\nNo LimitRange resource.\n</code></pre><p>Let's create a new namespace and see if the labels apply there.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl create namespace test-defaults\n</span></span><span style=\"display:flex;\"><span>kubectl describe namespace test-defaults\n</span></span></code></pre></div><p>Same.</p>\n<pre tabindex=\"0\"><code>Name: test-defaults\nLabels: kubernetes.io/metadata.name=test-defaults\nAnnotations: &lt;none&gt;\nStatus: Active\nNo resource quota.\nNo LimitRange resource.\n</code></pre><p>Can a privileged workload be deployed?</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n test-defaults apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-privileged\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> securityContext:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> allowPrivilegeEscalation: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>Hmm... yep. The default <code>warn</code> level is working at least.</p>\n<pre tabindex=\"0\"><code>Warning: would violate PodSecurity &#34;restricted:latest&#34;: allowPrivilegeEscalation != false (container &#34;busybox&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container &#34;busybox&#34; must set securityContext.capabilities.drop=[&#34;ALL&#34;]), runAsNonRoot != true (pod or container &#34;busybox&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container &#34;busybox&#34; must set securityContext.seccompProfile.type to &#34;RuntimeDefault&#34; or &#34;Localhost&#34;)\npod/busybox-privileged created\n</code></pre><p>Let's delete the pod with <code>kubectl -n test-defaults delete pod/busybox-privileged</code>.</p>\n<p>Is my config even working?</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># if using docker, shell into the control plane</span>\n</span></span><span style=\"display:flex;\"><span>docker <span style=\"color:#a2f\">exec</span> -it kind-control-plane bash\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># cat out the file we mounted</span>\n</span></span><span style=\"display:flex;\"><span>cat /etc/kubernetes/policies/pod-security.yaml\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># check the api server logs</span>\n</span></span><span style=\"display:flex;\"><span>cat /var/log/containers/kube-apiserver*.log\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># check the api server config</span>\n</span></span><span style=\"display:flex;\"><span>cat /etc/kubernetes/manifests/kube-apiserver.yaml\n</span></span></code></pre></div><p><strong>UPDATE:</strong> The baseline policy permits <code>allowPrivilegeEscalation</code>. While I cannot see the Pod Security default levels of enforcement, they are there. Let's try to provide a manifest that violates the baseline by requesting hostNetwork access.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># delete the original pod</span>\n</span></span><span style=\"display:flex;\"><span>kubectl -n test-defaults delete pod busybox-privileged\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span>cat <span style=\"color:#b44\">&lt;&lt;EOF | kubectl -n test-defaults apply -f -\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">apiVersion: v1\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">kind: Pod\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">metadata:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> name: busybox-privileged\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">spec:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> containers:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - name: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> image: busybox\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> args:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - sleep\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> - &#34;1000000&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\"> hostNetwork: true\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#b44\">EOF</span>\n</span></span></code></pre></div><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code>Error from server (Forbidden): error when creating &#34;STDIN&#34;: pods &#34;busybox-privileged&#34; is forbidden: violates PodSecurity &#34;baseline:latest&#34;: host namespaces (hostNetwork=true)\n</code></pre><h4 id=\"it-worked\">Yes!!! It worked! 🎉🎉🎉</h4>\n<p>I later found out, another way to check if things are operating as intended is to check the raw API server metrics endpoint.</p>\n<p>Run the following command:</p>\n<pre tabindex=\"0\"><code>kubectl get --raw /metrics | grep pod_security_evaluations_total\n</code></pre><p>The output is similar to this:</p>\n<pre tabindex=\"0\"><code># HELP pod_security_evaluations_total [ALPHA] Number of policy evaluations that occurred, not counting ignored or exempt requests.\n# TYPE pod_security_evaluations_total counter\npod_security_evaluations_total{decision=&#34;allow&#34;,mode=&#34;enforce&#34;,policy_level=&#34;baseline&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 2\npod_security_evaluations_total{decision=&#34;allow&#34;,mode=&#34;enforce&#34;,policy_level=&#34;privileged&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 0\npod_security_evaluations_total{decision=&#34;allow&#34;,mode=&#34;enforce&#34;,policy_level=&#34;privileged&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;update&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 0\npod_security_evaluations_total{decision=&#34;deny&#34;,mode=&#34;audit&#34;,policy_level=&#34;baseline&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 1\npod_security_evaluations_total{decision=&#34;deny&#34;,mode=&#34;enforce&#34;,policy_level=&#34;baseline&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 1\npod_security_evaluations_total{decision=&#34;deny&#34;,mode=&#34;warn&#34;,policy_level=&#34;restricted&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;controller&#34;,subresource=&#34;&#34;} 2\npod_security_evaluations_total{decision=&#34;deny&#34;,mode=&#34;warn&#34;,policy_level=&#34;restricted&#34;,policy_version=&#34;latest&#34;,request_operation=&#34;create&#34;,resource=&#34;pod&#34;,subresource=&#34;&#34;} 2\n</code></pre><p>A monitoring tool could ingest these metrics too for reporting, assessments, or measuring trends.</p>\n<h2 id=\"clean-up\">Clean up</h2>\n<p>When finished, delete the kind cluster.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kind delete cluster\n</span></span></code></pre></div><h2 id=\"auditing\">Auditing</h2>\n<p>Auditing is another way to track what policies are being enforced in your cluster. To set up auditing with kind, review the official docs for <a href=\"https://kind.sigs.k8s.io/docs/user/auditing/\">enabling auditing</a>. As of <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.11.md#sig-auth\">version 1.11</a>, Kubernetes audit logs include two annotations that indicate whether or not a request was authorized (<code>authorization.k8s.io/decision</code>) and the reason for the decision (<code>authorization.k8s.io/reason</code>). Audit events can be streamed to a webhook for monitoring, tracking, or alerting.</p>\n<p>The audit events look similar to the following:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span>{<span style=\"color:#b44\">&#34;authorization.k8s.io/decision&#34;</span>:<span style=\"color:#b44\">&#34;allow&#34;</span>,<span style=\"color:#b44\">&#34;authorization.k8s.io/reason&#34;</span>:<span style=\"color:#b44\">&#34;&#34;</span>,<span style=\"color:#b44\">&#34;pod-security.kubernetes.io/audit&#34;</span>:<span style=\"color:#b44\">&#34;allowPrivilegeEscalation != false (container \\&#34;busybox\\&#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \\&#34;busybox\\&#34; must set securityContext.capabilities.drop=[\\&#34;ALL\\&#34;]), runAsNonRoot != true (pod or container \\&#34;busybox\\&#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \\&#34;busybox\\&#34; must set securityContext.seccompProfile.type to \\&#34;RuntimeDefault\\&#34; or \\&#34;Localhost\\&#34;)&#34;</span>}}<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Auditing is also a good first step in evaluating your cluster's current compliance with Pod Security. The Kubernetes Enhancement Proposal (KEP) hints at a future where <code>baseline</code> <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-auth/2579-psp-replacement/README.md#rollout-of-baseline-by-default-for-unlabeled-namespaces\">could be the default for unlabeled namespaces</a>.</p>\n<p>Example <code>audit-policy.yaml</code> configuration tuned for Pod Security events:</p>\n<pre tabindex=\"0\"><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: RequestResponse\nresources:\n- group: &#34;&#34; # core API group\nresources: [&#34;pods&#34;, &#34;pods/ephemeralcontainers&#34;, &#34;podtemplates&#34;, &#34;replicationcontrollers&#34;]\n- group: &#34;apps&#34;\nresources: [&#34;daemonsets&#34;, &#34;deployments&#34;, &#34;replicasets&#34;, &#34;statefulsets&#34;]\n- group: &#34;batch&#34;\nresources: [&#34;cronjobs&#34;, &#34;jobs&#34;]\nverbs: [&#34;create&#34;, &#34;update&#34;]\nomitStages:\n- &#34;RequestReceived&#34;\n- &#34;ResponseStarted&#34;\n- &#34;Panic&#34;\n</code></pre><p>Once auditing is enabled, look at the configured local file if using <code>--audit-log-path</code> or the destination of a webhook if using <code>--audit-webhook-config-file</code>.</p>\n<p>If using a file (<code>--audit-log-path</code>), run <code>cat /PATH/TO/API/AUDIT.log | grep &quot;is forbidden:&quot;</code> to see all rejected workloads audited.</p>\n<h2 id=\"psp-migrations\">PSP migrations</h2>\n<p>If you're already using PSP, SIG Auth has created a guide and <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/\">published the steps to migrate off of PSP</a>.</p>\n<p>To summarize the process:</p>\n<ul>\n<li>Update all existing PSPs to be non-mutating</li>\n<li>Apply Pod Security policies in <code>warn</code> or <code>audit</code> mode</li>\n<li>Upgrade Pod Security policies to <code>enforce</code> mode</li>\n<li>Remove <code>PodSecurityPolicy</code> from <code>--enable-admission-plugins</code></li>\n</ul>\n<p>Listed as &quot;optional future extensions&quot; and currently out of scope, SIG Auth has kicked around the idea of providing a tool to assist with migrations. More <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-auth/2579-psp-replacement/README.md#automated-psp-migration-tooling\">details in the KEP</a>.</p>\n<h2 id=\"wrap-up\">Wrap up</h2>\n<p>Pod Security is a promising new feature that provides an out-of-the-box way to allow users to improve the security posture of their workloads. Like any new enhancement that has matured to beta, we ask that you try it out, provide feedback, or share your experience via either raising a Github issue or joining SIG Auth community meetings. It's our hope that Pod Security will be deployed on every cluster in our ongoing pursuit as a community to make Kubernetes security a priority.</p>\n<p>For a step by step guide on how to enable &quot;baseline&quot; Pod Security Standards with Pod Security Admission feature please refer to these dedicated <a href=\"https://kubernetes.io/docs/tutorials/security/\">tutorials</a> that cover the configuration needed at cluster level and namespace level.</p>\n<h2 id=\"additional-resources\">Additional resources</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Official Pod Security Docs</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-namespace-labels/\">Enforce Pod Security Standards with Namespace Labels</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-admission-controller/\">Enforce Pod Security Standards by Configuring the Built-in Admission Controller</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-auth/2579-psp-replacement/README.md\">Official Kubernetes Enhancement Proposal</a> (KEP)</li>\n<li><a href=\"https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/\">PodSecurityPolicy Deprecation: Past, Present, and Future</a></li>\n<li><a href=\"https://medium.com/@LachlanEvenson/hands-on-with-kubernetes-pod-security-admission-b6cac495cd11\">Hands on with Kubernetes Pod Security</a></li>\n</ul>","PublishedAt":"2021-12-09 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/09/pod-security-admission-beta/","SourceName":"Kubernetes"}},{"node":{"ID":248,"Title":"Delivering High Performance for Cloudera Data Platform Operational Database (HBase) When Using S3","Description":"<p>CDP Operational Database allows developers to use Amazon Simple Storage Service (S3) as its main persistence layer for saving table data.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/delivering-high-performance-for-cloudera-data-platform-operational-database-hbase-when-using-s3/\">Delivering High Performance for Cloudera Data Platform Operational Database (HBase) When Using S3</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-08 15:50:17+00:00","OriginURL":"https://blog.cloudera.com/delivering-high-performance-for-cloudera-data-platform-operational-database-hbase-when-using-s3/","SourceName":"Cloudera"}},{"node":{"ID":249,"Title":"The Best Time to Kickstart Your Data Strategy Was Yesterday, the Next Best Time Is Now","Description":"<p>Delays in implementing a data strategy mean less time for the organization to harness critical business insights. Results from our global study of business and  IT decision makers show that organizations which had data strategies in place earlier also reaped the benefits sooner.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/the-best-time-to-kickstart-your-data-strategy-was-yesterday-the-next-best-time-is-now/\">The Best Time to Kickstart Your Data Strategy Was Yesterday, the Next Best Time Is Now</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-08 14:00:10+00:00","OriginURL":"https://blog.cloudera.com/the-best-time-to-kickstart-your-data-strategy-was-yesterday-the-next-best-time-is-now/","SourceName":"Cloudera"}},{"node":{"ID":1121,"Title":"Test Automation Policy in Merpay Frontend","Description":"<p>This is a post for the Day 8th of Merpay Advent Calendar 2021 written by @tanakaworld from the Merpay Frontend team. Introduction Merpay, a financial service, has been constantly working on quality. The Frontend team started automating Regression Testing two years ago and Integration Testing this year. In this article, I would like to look [&hellip;]</p>\n","PublishedAt":"2021-12-08 09:00:35+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211208-test-automation-policy-in-merpay-frontend/","SourceName":"Mercari"}},{"node":{"ID":467,"Title":"What does it take to be a good product analyst? (No, it’s not a data science degree.)","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/12/20211124_BlogHero_ProductAnalyst-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Good product teams know their users inside and out. They understand how they use their product, how long they stay, why they drop off, which cohorts will monetize, and where they should place their big bets.&#160; They get to know all of this by using data as a strategic asset—because good product teams are made</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/what-does-it-take-to-be-a-good-product-analyst-no-its-not-a-data-science-degree/\">What does it take to be a good product analyst? (No, it’s not a data science degree.)</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-12-08 06:29:00+00:00","OriginURL":"https://mixpanel.com/blog/what-does-it-take-to-be-a-good-product-analyst-no-its-not-a-data-science-degree/","SourceName":"Mixpanel"}},{"node":{"ID":1243,"Title":"Blog: Kubernetes 1.23: Dual-stack IPv4/IPv6 Networking Reaches GA","Description":"<p><strong>Author:</strong> Bridget Kromhout (Microsoft)</p>\n<p>&quot;When will Kubernetes have IPv6?&quot; This question has been asked with increasing frequency ever since alpha support for IPv6 was first added in k8s v1.9. While Kubernetes has supported IPv6-only clusters since v1.18, migration from IPv4 to IPv6 was not yet possible at that point. At long last, <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-network/563-dual-stack/\">dual-stack IPv4/IPv6 networking</a> has reached general availability (GA) in Kubernetes v1.23.</p>\n<p>What does dual-stack networking mean for you? Let’s take a look…</p>\n<h2 id=\"service-api-updates\">Service API updates</h2>\n<p><a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Services</a> were single-stack before 1.20, so using both IP families meant creating one Service per IP family. The user experience was simplified in 1.20, when Services were re-implemented to allow both IP families, meaning a single Service can handle both IPv4 and IPv6 workloads. Dual-stack load balancing is possible between services running any combination of IPv4 and IPv6.</p>\n<p>The Service API now has new fields to support dual-stack, replacing the single ipFamily field.</p>\n<ul>\n<li>You can select your choice of IP family by setting <code>ipFamilyPolicy</code> to one of three options: SingleStack, PreferDualStack, or RequireDualStack. A service can be changed between single-stack and dual-stack (within some limits).</li>\n<li>Setting <code>ipFamilies</code> to a list of families assigned allows you to set the order of families used.</li>\n<li><code>clusterIPs</code> is inclusive of the previous <code>clusterIP</code> but allows for multiple entries, so it’s no longer necessary to run duplicate services, one in each of the two IP families. Instead, you can assign cluster IP addresses in both IP families.</li>\n</ul>\n<p>Note that Pods are also dual-stack. For a given pod, there is no possibility of setting multiple IP addresses in the same family.</p>\n<h2 id=\"default-behavior-remains-single-stack\">Default behavior remains single-stack</h2>\n<p>Starting in 1.20 with the re-implementation of dual-stack services as alpha, the underlying networking for Kubernetes has included dual-stack whether or not a cluster was configured with the feature flag to enable dual-stack.</p>\n<p>Kubernetes 1.23 removed that feature flag as part of graduating the feature to stable. Dual-stack networking is always available if you want to configure it. You can set your cluster network to operate as single-stack IPv4, as single-stack IPv6, or as dual-stack IPv4/IPv6.</p>\n<p>While Services are set according to what you configure, Pods default to whatever the CNI plugin sets. If your CNI plugin assigns single-stack IPs, you will have single-stack unless <code>ipFamilyPolicy</code> specifies PreferDualStack or RequireDualStack. If your CNI plugin assigns dual-stack IPs, <code>pod.status.PodIPs</code> defaults to dual-stack.</p>\n<p>Even though dual-stack is possible, it is not mandatory to use it. Examples in the documentation show the variety possible in <a href=\"https://kubernetes.io/docs/concepts/services-networking/dual-stack/#dual-stack-service-configuration-scenarios\">dual-stack service configurations</a>.</p>\n<h2 id=\"try-dual-stack-right-now\">Try dual-stack right now</h2>\n<p>While upstream Kubernetes now supports <a href=\"https://kubernetes.io/docs/concepts/services-networking/dual-stack/\">dual-stack networking</a> as a GA or stable feature, each provider’s support of dual-stack Kubernetes may vary. Nodes need to be provisioned with routable IPv4/IPv6 network interfaces. Pods need to be dual-stack. The <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/\">network plugin</a> is what assigns the IP addresses to the Pods, so it's the network plugin being used for the cluster that needs to support dual-stack. Some Container Network Interface (CNI) plugins support dual-stack, as does kubenet.</p>\n<p>Ecosystem support of dual-stack is increasing; you can create <a href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/dual-stack-support/\">dual-stack clusters with kubeadm</a>, try a <a href=\"https://kind.sigs.k8s.io/docs/user/configuration/#ip-family\">dual-stack cluster locally with KIND</a>, and deploy dual-stack clusters in cloud providers (after checking docs for CNI or kubenet availability).</p>\n<h2 id=\"get-involved-with-sig-network\">Get involved with SIG Network</h2>\n<p>SIG-Network wants to learn from community experiences with dual-stack networking to find out more about evolving needs and your use cases. The <a href=\"https://www.youtube.com/watch?v=uZ0WLxpmBbY&amp;list=PLj6h78yzYM2Nd1U4RMhv7v88fdiFqeYAP&amp;index=4\">SIG-network update video from KubeCon NA 2021</a> summarizes the SIG’s recent updates, including dual-stack going to stable in 1.23.</p>\n<p>The current SIG-Network <a href=\"https://github.com/orgs/kubernetes/projects/10\">KEPs</a> and <a href=\"https://github.com/kubernetes/kubernetes/issues?q=is%3Aopen+is%3Aissue+label%3Asig%2Fnetwork\">issues</a> on GitHub illustrate the SIG’s areas of emphasis. The <a href=\"https://github.com/kubernetes/enhancements/issues/2438\">dual-stack API server</a> is one place to consider contributing.</p>\n<p><a href=\"https://github.com/kubernetes/community/tree/master/sig-network#meetings\">SIG-Network meetings</a> are a friendly, welcoming venue for you to connect with the community and share your ideas. Looking forward to hearing from you!</p>\n<h2 id=\"acknowledgments\">Acknowledgments</h2>\n<p>The dual-stack networking feature represents the work of many Kubernetes contributors. Thanks to all who contributed code, experience reports, documentation, code reviews, and everything in between. Bridget Kromhout details this community effort in <a href=\"https://containerjournal.com/features/dual-stack-networking-in-kubernetes/\">Dual-Stack Networking in Kubernetes</a>. KubeCon keynotes by Tim Hockin &amp; Khaled (Kal) Henidak in 2019 (<a href=\"https://www.youtube.com/watch?v=o-oMegdZcg4\">The Long Road to IPv4/IPv6 Dual-stack Kubernetes</a>) and by Lachlan Evenson in 2021 (<a href=\"https://www.youtube.com/watch?v=lVrt8F2B9CM\">And Here We Go: Dual-stack Networking in Kubernetes</a>) talk about the dual-stack journey, spanning five years and a great many lines of code.</p>","PublishedAt":"2021-12-08 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/08/dual-stack-networking-ga/","SourceName":"Kubernetes"}},{"node":{"ID":1122,"Title":"Assisting Customer Support Agents by Providing Suggestions for Reply Templates","Description":"<p>This post is for Day 07 of Mercari Advent Calendar 2021, brought to you by @primaprashant from the Mercari AI-CRE team. Mercari has customer support offices in Tokyo, Sendai, and Fukuoka. We have dedicated agents to provide support and help customers resolve issues they encounter. Quick resolution of customer issues is essential for providing a [&hellip;]</p>\n","PublishedAt":"2021-12-07 09:00:45+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211206-assisting-customer-support-agents-by-providing-suggestions-for-reply-templates/","SourceName":"Mercari"}},{"node":{"ID":1244,"Title":"Blog: Kubernetes 1.23: The Next Frontier","Description":"<p><strong>Authors:</strong> <a href=\"https://github.com/kubernetes/sig-release/blob/master/releases/release-1.23/release-team.md\">Kubernetes 1.23 Release Team</a></p>\n<p>We’re pleased to announce the release of Kubernetes 1.23, the last release of 2021!</p>\n<p>This release consists of 47 enhancements: 11 enhancements have graduated to stable, 17 enhancements are moving to beta, and 19 enhancements are entering alpha. Also, 1 feature has been deprecated.</p>\n<h2 id=\"major-themes\">Major Themes</h2>\n<h3 id=\"deprecation-of-flexvolume\">Deprecation of FlexVolume</h3>\n<p>FlexVolume is deprecated. The out-of-tree CSI driver is the recommended way to write volume drivers in Kubernetes. See <a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/volume-plugin-faq.md#kubernetes-volume-plugin-faq-for-storage-vendors\">this doc</a> for more information. Maintainers of FlexVolume drivers should implement a CSI driver and move users of FlexVolume to CSI. Users of FlexVolume should move their workloads to the CSI driver.</p>\n<h3 id=\"deprecation-of-klog-specific-flags\">Deprecation of klog specific flags</h3>\n<p>To simplify the code base, several <a href=\"https://kubernetes.io/docs/concepts/cluster-administration/system-logs/#klog\">logging flags were marked as deprecated</a> in Kubernetes 1.23. The code which implements them will be removed in a future release, so users of those need to start replacing the deprecated flags with some alternative solutions.</p>\n<h3 id=\"software-supply-chain-slsa-level-1-compliance-in-the-kubernetes-release-process\">Software Supply Chain SLSA Level 1 Compliance in the Kubernetes Release Process</h3>\n<p>Kubernetes releases now generate provenance attestation files describing the staging and release phases of the release process. Artifacts are now verified as they are handed over from one phase to the next. This final piece completes the work needed to comply with Level 1 of the <a href=\"https://slsa.dev/\">SLSA security framework</a> (Supply-chain Levels for Software Artifacts).</p>\n<h3 id=\"ipv4-ipv6-dual-stack-networking-graduates-to-ga\">IPv4/IPv6 Dual-stack Networking graduates to GA</h3>\n<p><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-network/563-dual-stack\">IPv4/IPv6 dual-stack networking</a> graduates to GA. Since 1.21, Kubernetes clusters have been enabled to support dual-stack networking by default. In 1.23, the <code>IPv6DualStack</code> feature gate is removed. The use of dual-stack networking is not mandatory. Although clusters are enabled to support dual-stack networking, Pods and Services continue to default to single-stack. To use dual-stack networking Kubernetes nodes must have routable IPv4/IPv6 network interfaces, a dual-stack capable CNI network plugin must be used, Pods must be configured to be dual-stack and Services must have their <code>.spec.ipFamilyPolicy</code> field set to either <code>PreferDualStack</code> or <code>RequireDualStack</code>.</p>\n<h3 id=\"horizontalpodautoscaler-v2-graduates-to-ga\">HorizontalPodAutoscaler v2 graduates to GA</h3>\n<p>The HorizontalPodAutscaler <code>autoscaling/v2</code> stable API moved to GA in 1.23. The HorizontalPodAutoscaler <code>autoscaling/v2beta2</code> API has been deprecated.</p>\n<h3 id=\"generic-ephemeral-volume-feature-graduates-to-ga\">Generic Ephemeral Volume feature graduates to GA</h3>\n<p>The generic ephemeral volume feature moved to GA in 1.23. This feature allows any existing storage driver that supports dynamic provisioning to be used as an ephemeral volume with the volume’s lifecycle bound to the Pod. All StorageClass parameters for volume provisioning and all features supported with PersistentVolumeClaims are supported.</p>\n<h3 id=\"skip-volume-ownership-change-graduates-to-ga\">Skip Volume Ownership change graduates to GA</h3>\n<p>The feature to configure volume permission and ownership change policy for Pods moved to GA in 1.23. This allows users to skip recursive permission changes on mount and speeds up the pod start up time.</p>\n<h3 id=\"allow-csi-drivers-to-opt-in-to-volume-ownership-and-permission-change-graduates-to-ga\">Allow CSI drivers to opt-in to volume ownership and permission change graduates to GA</h3>\n<p>The feature to allow CSI Drivers to declare support for fsGroup based permissions graduates to GA in 1.23.</p>\n<h3 id=\"podsecurity-graduates-to-beta\">PodSecurity graduates to Beta</h3>\n<p><a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">PodSecurity</a> moves to Beta. <code>PodSecurity</code> replaces the deprecated <code>PodSecurityPolicy</code> admission controller. <code>PodSecurity</code> is an admission controller that enforces Pod Security Standards on Pods in a Namespace based on specific namespace labels that set the enforcement level. In 1.23, the <code>PodSecurity</code> feature gate is enabled by default.</p>\n<h3 id=\"container-runtime-interface-cri-v1-is-default\">Container Runtime Interface (CRI) v1 is default</h3>\n<p>The Kubelet now supports the CRI <code>v1</code> API, which is now the project-wide default.\nIf a container runtime does not support the <code>v1</code> API, Kubernetes will fall back to the <code>v1alpha2</code> implementation. There is no intermediate action required by end-users, because <code>v1</code> and <code>v1alpha2</code> do not differ in their implementation. It is likely that <code>v1alpha2</code> will be removed in one of the future Kubernetes releases to be able to develop <code>v1</code>.</p>\n<h3 id=\"structured-logging-graduate-to-beta\">Structured logging graduate to Beta</h3>\n<p>Structured logging reached its Beta milestone. Most log messages from kubelet and kube-scheduler have been converted. Users are encouraged to try out JSON output or parsing of the structured text format and provide feedback on possible solutions for the open issues, such as handling of multi-line strings in log values.</p>\n<h3 id=\"simplified-multi-point-plugin-configuration-for-scheduler\">Simplified Multi-point plugin configuration for scheduler</h3>\n<p>The kube-scheduler is adding a new, simplified config field for Plugins to allow multiple extension points to be enabled in one spot. The new <code>multiPoint</code> plugin field is intended to simplify most scheduler setups for administrators. Plugins that are enabled via <code>multiPoint</code> will automatically be registered for each individual extension point that they implement. For example, a plugin that implements Score and Filter extensions can be simultaneously enabled for both. This means entire plugins can be enabled and disabled without having to manually edit individual extension point settings. These extension points can now be abstracted away due to their irrelevance for most users.</p>\n<h3 id=\"csi-migration-updates\">CSI Migration updates</h3>\n<p>CSI Migration enables the replacement of existing in-tree storage plugins such as <code>kubernetes.io/gce-pd</code> or <code>kubernetes.io/aws-ebs</code> with a corresponding CSI driver.\nIf CSI Migration is working properly, Kubernetes end users shouldn’t notice a difference.\nAfter migration, Kubernetes users may continue to rely on all the functionality of in-tree storage plugins using the existing interface.</p>\n<ul>\n<li>CSI Migration feature is turned on by default but stays in Beta for GCE PD, AWS EBS, and Azure Disk in 1.23.</li>\n<li>CSI Migration is introduced as an Alpha feature for Ceph RBD and Portworx in 1.23.</li>\n</ul>\n<h3 id=\"expression-language-validation-for-crd-is-alpha\">Expression language validation for CRD is alpha</h3>\n<p>Expression language validation for CRD is in alpha starting in 1.23. If the <code>CustomResourceValidationExpressions</code> feature gate is enabled, custom resources will be validated by validation rules using the <a href=\"https://github.com/google/cel-spec\">Common Expression Language (CEL)</a>.</p>\n<h3 id=\"server-side-field-validation-is-alpha\">Server Side Field Validation is Alpha</h3>\n<p>If the <code>ServerSideFieldValidation</code> feature gate is enabled starting 1.23, users will receive warnings from the server when they send Kubernetes objects in the request that contain unknown or duplicate fields. Previously unknown fields and all but the last duplicate fields would be dropped by the server.</p>\n<p>With the feature gate enabled, we also introduce the <code>fieldValidation</code> query parameter so that users can specify the desired behavior of the server on a per request basis. Valid values for the <code>fieldValidation</code> query parameter are:</p>\n<ul>\n<li>Ignore (default when feature gate is disabled, same as pre-1.23 behavior of dropping/ignoring unkonwn fields)</li>\n<li>Warn (default when feature gate is enabled).</li>\n<li>Strict (this will fail the request with an Invalid Request error)</li>\n</ul>\n<h3 id=\"openapi-v3-is-alpha\">OpenAPI v3 is Alpha</h3>\n<p>If the <code>OpenAPIV3</code> feature gate is enabled starting 1.23, users will be able to request the OpenAPI v3.0 spec for all Kubernetes types. OpenAPI v3 aims to be fully transparent and includes support for a set of fields that are dropped when publishing OpenAPI v2: <code>default</code>, <code>nullable</code>, <code>oneOf</code>, <code>anyOf</code>. A separate spec is published per Kubernetes group version (at the <code>$cluster/openapi/v3/apis/&lt;group&gt;/&lt;version&gt;</code> endpoint) for improved performance and discovery, for all group versions can be found at the <code>$cluster/openapi/v3</code> path.</p>\n<h2 id=\"other-updates\">Other Updates</h2>\n<h3 id=\"graduated-to-stable\">Graduated to Stable</h3>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/563\">IPv4/IPv6 Dual-Stack Support</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/695\">Skip Volume Ownership Change</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/592\">TTL After Finished Controller</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1682\">Config FSGroup Policy in CSI Driver object</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1698\">Generic Ephemeral Inline Volumes</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1933\">Defend Against Logging Secrets via Static Analysis</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2365\">Namespace Scoped Ingress Class Parameters</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2420\">Reducing Kubernetes Build Maintenance</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/2702\">Graduate HPA API to GA</a></li>\n</ul>\n<h3 id=\"major-changes\">Major Changes</h3>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/1040\">Priority and Fairness for API Server Requests</a></li>\n</ul>\n<h3 id=\"release-notes\">Release Notes</h3>\n<p>Check out the full details of the Kubernetes 1.23 release in our <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md\">release notes</a>.</p>\n<h3 id=\"availability\">Availability</h3>\n<p>Kubernetes 1.23 is available for download on <a href=\"https://github.com/kubernetes/kubernetes/releases/tag/v1.23.0\">GitHub</a>. To get started with Kubernetes, check out these <a href=\"https://kubernetes.io/docs/tutorials/\">interactive tutorials</a> or run local Kubernetes clusters using Docker container “nodes” with <a href=\"https://kind.sigs.k8s.io/\">kind</a>. You can also easily install 1.23 using <a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\">kubeadm</a>.</p>\n<h3 id=\"release-team\">Release Team</h3>\n<p>This release was made possible by a very dedicated group of individuals, who came together as a team to deliver technical content, documentation, code, and a host of other components that go into every Kubernetes release.</p>\n<p>A huge thank you to the release lead Rey Lejano for leading us through a successful release cycle, and to everyone else on the release team for supporting each other, and working so hard to deliver the 1.23 release for the community.</p>\n<h3 id=\"release-theme-and-logo\">Release Theme and Logo</h3>\n<p><strong>Kubernetes 1.23: The Next Frontier</strong></p>\n<figure class=\"release-logo\">\n<img src=\"https://kubernetes.io/images/blog/2021-12-07-kubernetes-release-1.23/kubernetes-1.23.png\"/>\n</figure>\n<p>&quot;The Next Frontier&quot; theme represents the new and graduated enhancements in 1.23, Kubernetes' history of Star Trek references, and the growth of community members in the release team.</p>\n<p>Kubernetes has a history of Star Trek references. The original codename for Kubernetes within Google is Project 7, a reference to Seven of Nine from Star Trek Voyager. And of course Borg was the name for the predecessor to Kubernetes. &quot;The Next Frontier&quot; theme continues the Star Trek references. &quot;The Next Frontier&quot; is a fusion of two Star Trek titles, Star Trek V: The Final Frontier and Star Trek the Next Generation.</p>\n<p>&quot;The Next Frontier&quot; represents a line in the SIG Release charter, &quot;Ensure there is a consistent group of community members in place to support the release process across time.&quot; With each release team, we grow the community with new release team members and for many it's their first contribution in their open source frontier.</p>\n<p>Reference: <a href=\"https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/\">https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/</a>\nReference: <a href=\"https://github.com/kubernetes/community/blob/master/sig-release/charter.md\">https://github.com/kubernetes/community/blob/master/sig-release/charter.md</a></p>\n<p>The Kubernetes 1.23 release logo continues with the theme's Star Trek reference. Every star is a helm from the Kubernetes logo. The ship represents the collective teamwork of the release team.</p>\n<p>Rey Lejano designed the logo.</p>\n<h3 id=\"user-highlights\">User Highlights</h3>\n<ul>\n<li><a href=\"https://www.cncf.io/announcements/2021/09/22/cncf-end-user-technology-radar-provides-insights-into-devsecops/\">Findings of the latest CNCF End User Technology Radar</a> were themed around DevSecOps. Check out the <a href=\"https://radar.cncf.io/\">Radar Page</a> for the full details and findings.</li>\n<li>Learn about how <a href=\"https://www.cncf.io/case-studies/aegon-life-india/\">end user Aegon Life India migrated core processes from its traditional monolith to a microservice-based architecture</a> in its effort to transform into a leading digital service company.</li>\n<li>Utilizing multiple cloud native projects, <a href=\"https://www.cncf.io/case-studies/seagate/\">Seagate engineered edgerX to run Real-time Analytics at the Edge</a>.</li>\n<li>Check out how <a href=\"https://www.cncf.io/case-studies/zambon/\">Zambon worked with SparkFabrik to develop 16 websites, with cloud native technologies, to enable stakeholders to easily update content while maintaining a consistent brand identity</a>.</li>\n<li>Using Kubernetes, <a href=\"https://www.cncf.io/case-studies/influxdata/\">InfluxData was able to deliver on the promise of multi-cloud, multi-region service availability</a> by creating a true cloud abstraction layer that allows for the seamless delivery of InfluxDB as a single application to multiple global clusters across three major cloud providers.</li>\n</ul>\n<h3 id=\"ecosystem-updates\">Ecosystem Updates</h3>\n<ul>\n<li><a href=\"https://www.cncf.io/events/kubecon-cloudnativecon-north-america-2021/\">KubeCon + CloudNativeCon NA 2021</a> was held in October 2021, both online and in person. All talks are <a href=\"https://www.youtube.com/playlist?list=PLj6h78yzYM2Nd1U4RMhv7v88fdiFqeYAP\">now available on-demand</a> for anyone that would like to catch up!</li>\n<li><a href=\"https://www.cncf.io/announcements/2021/11/18/kubernetes-and-cloud-native-essentials-training-and-kcna-certification-now-available/\">Kubernetes and Cloud Native Essentials Training and KCNA Certification are now generally available for enrollment and scheduling</a>. Additionally, a new online training course, <a href=\"https://www.cncf.io/announcements/2021/10/13/entry-level-kubernetes-certification-to-help-advance-cloud-careers/\">Kubernetes and Cloud Native Essentials (LFS250)</a>, has been released to both prepare individuals for entry-level cloud roles and to sit for the KCNA exam.</li>\n<li><a href=\"https://www.cncf.io/announcements/2021/10/13/inclusive-naming-initiative-announces-new-community-resources-for-a-more-inclusive-future/\">New resources are now available from the Inclusive Naming Initiative</a>, including an Inclusive Strategies for Open Source (LFC103) course, Language Evaluation Framework, and Implementation Path.</li>\n</ul>\n<h3 id=\"project-velocity\">Project Velocity</h3>\n<p>The <a href=\"https://k8s.devstats.cncf.io/d/12/dashboards?orgId=1&amp;refresh=15m\">CNCF K8s DevStats</a> project aggregates a number of interesting data points related to the velocity of Kubernetes and various sub-projects. This includes everything from individual contributions to the number of companies that are contributing, and is an illustration of the depth and breadth of effort that goes into evolving this ecosystem.</p>\n<p>In the v1.23 release cycle, which ran for 16 weeks (August 23 to December 7), we saw contributions from <a href=\"https://k8s.devstats.cncf.io/d/9/companies-table?orgId=1&amp;var-period_name=v1.22.0%20-%20now&amp;var-metric=contributions\">1032 companies</a> and <a href=\"https://k8s.devstats.cncf.io/d/66/developer-activity-counts-by-companies?orgId=1&amp;var-period_name=v1.22.0%20-%20now&amp;var-metric=contributions&amp;var-repogroup_name=Kubernetes&amp;var-country_name=All&amp;var-companies=All&amp;var-repo_name=kubernetes%2Fkubernetes\">1084 individuals</a>.</p>\n<h3 id=\"event-update\">Event Update</h3>\n<ul>\n<li><a href=\"https://www.lfasiallc.com/kubecon-cloudnativecon-open-source-summit-china/\">KubeCon + CloudNativeCon China 2021</a> is happening this month from December 9 - 11. After taking a break last year, the event will be virtual this year and includes 105 sessions. Check out the event schedule <a href=\"https://www.lfasiallc.com/kubecon-cloudnativecon-open-source-summit-china/program/schedule/\">here</a>.</li>\n<li>KubeCon + CloudNativeCon Europe 2022 will take place in Valencia, Spain, May 4 – 7, 2022! You can find more information about the conference and registration on the <a href=\"https://events.linuxfoundation.org/archive/2021/kubecon-cloudnativecon-europe/\">event site</a>.</li>\n<li>Kubernetes Community Days has upcoming events scheduled in Pakistan, Brazil, Chengdu, and in Australia.</li>\n</ul>\n<h3 id=\"upcoming-release-webinar\">Upcoming Release Webinar</h3>\n<p>Join members of the Kubernetes 1.23 release team on January 4, 2022 to learn about the major features of this release, as well as deprecations and removals to help plan for upgrades. For more information and registration, visit the <a href=\"https://community.cncf.io/e/mrey9h/\">event page</a> on the CNCF Online Programs site.</p>\n<h3 id=\"get-involved\">Get Involved</h3>\n<p>The simplest way to get involved with Kubernetes is by joining one of the many <a href=\"https://github.com/kubernetes/community/blob/master/sig-list.md\">Special Interest Groups</a> (SIGs) that align with your interests. Have something you’d like to broadcast to the Kubernetes community? Share your voice at our weekly <a href=\"https://github.com/kubernetes/community/tree/master/communication\">community meeting</a>, and through the channels below:</p>\n<ul>\n<li>Find out more about contributing to Kubernetes at the <a href=\"https://www.kubernetes.dev/\">Kubernetes Contributors</a> website</li>\n<li>Follow us on Twitter <a href=\"https://twitter.com/kubernetesio\">@Kubernetesio</a> for the latest updates</li>\n<li>Join the community discussion on <a href=\"https://discuss.kubernetes.io/\">Discuss</a></li>\n<li>Join the community on <a href=\"http://slack.k8s.io/\">Slack</a></li>\n<li>Post questions (or answer questions) on <a href=\"http://stackoverflow.com/questions/tagged/kubernetes\">Stack Overflow</a></li>\n<li>Share your Kubernetes <a href=\"https://docs.google.com/a/linuxfoundation.org/forms/d/e/1FAIpQLScuI7Ye3VQHQTwBASrgkjQDSS5TP0g3AXfFhwSM9YpHgxRKFA/viewform\">story</a></li>\n<li>Read more about what’s happening with Kubernetes on the <a href=\"https://kubernetes.io/blog/\">blog</a></li>\n<li>Learn more about the <a href=\"https://github.com/kubernetes/sig-release/tree/master/release-team\">Kubernetes Release Team</a></li>\n</ul>","PublishedAt":"2021-12-07 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/07/kubernetes-1-23-release-announcement/","SourceName":"Kubernetes"}},{"node":{"ID":468,"Title":"Ask an expert: Building a richer customer lifecycle with analytics-tailored user messaging","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/12/Ask-An-Expert_Josh.png\" class=\"type:primaryImage\" /></figure>\n<p>Good products get their messaging out to users on things like available features and how to access them. But the best products do this with a focus on relevancy, making sure to let the right users know about the right features for them. Joshua Hollander is a Client Success Leader at OneSignal, a user messaging</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/ask-an-expert-building-a-richer-customer-lifecycle-with-analytics-tailored-user-messaging/\">Ask an expert: Building a richer customer lifecycle with analytics-tailored user messaging</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-12-06 18:02:00+00:00","OriginURL":"https://mixpanel.com/blog/ask-an-expert-building-a-richer-customer-lifecycle-with-analytics-tailored-user-messaging/","SourceName":"Mixpanel"}},{"node":{"ID":1123,"Title":"Interviewing and Onboarding at Mercari From Overseas With an 8 hour Time Difference","Description":"<p>This post is for Day 4 of Mercari Advent Calendar 2021, brought to you by @aymeric from the Mercari Listing Quality team. This is the story of how my interview process and ensuing onboarding at Mercari went, all the way from Europe, with an 8 hours time difference with Japan. It will not go into [&hellip;]</p>\n","PublishedAt":"2021-12-04 10:00:03+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211204-interviewing-and-onboarding-at-mercari-from-overseas-with-an-8-hour-time-difference/","SourceName":"Mercari"}},{"node":{"ID":432,"Title":"Better Practices for Git Version Control in Postman","Description":"","PublishedAt":"2021-12-03 17:42:14+00:00","OriginURL":"https://medium.com/better-practices/better-practices-for-git-version-control-in-postman-8476bd6fa51b?source=rss----410f2fbc015d---4","SourceName":"Postman"}},{"node":{"ID":1124,"Title":"Systems Thinking for Engineering","Description":"<p>Today&#8217;s post for Day 3 of the Mercari Advent Calendar 2021 is brought to you by Darren from the Mercari Data Team. I was recently asked to share my thoughts on what it means to be a &quot;distinguished engineer&quot; at Mercari, and my first thought was about systems. Below is an internal note that I [&hellip;]</p>\n","PublishedAt":"2021-12-03 10:00:02+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211203-use-systems-thinking-to-become-a-better-engineer/","SourceName":"Mercari"}},{"node":{"ID":1125,"Title":"CI/CD Metrics with GSM Framework","Description":"<p>This post is for Day 2 for Mercari Advent Calendar 2021, brought to you by Yuji Kazama from the Mercari platform group. Introduction Hello, I am the Engineering Manager of the CI/CD platform teams in Mercari. Our teams are responsible for providing CI/CD platforms for microservices and other client applications. In this article, I will [&hellip;]</p>\n","PublishedAt":"2021-12-02 06:00:37+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211130-ci-cd-metrics-with-gsm-framework/","SourceName":"Mercari"}},{"node":{"ID":433,"Title":"Dynamically create custom environments with code","Description":"","PublishedAt":"2021-12-01 23:56:24+00:00","OriginURL":"https://medium.com/better-practices/dynamically-create-custom-environments-with-code-c7b15c03f306?source=rss----410f2fbc015d---4","SourceName":"Postman"}},{"node":{"ID":530,"Title":"Nextdoor Notifications: How we use ML to keep neighbors informed","Description":"","PublishedAt":"2021-12-01 15:27:35+00:00","OriginURL":"https://engblog.nextdoor.com/nextdoor-notifications-how-we-use-ml-to-keep-neighbors-informed-57d8f707aab0?source=rss----5e54f11cdfdf---4","SourceName":"Nextdoor"}},{"node":{"ID":1126,"Title":"Why is metadata important?","Description":"<p>This post is for Day 01 of Mercari Advent Calendar 2021, brought to you by @gancim from the Mercari Metadata Ecosystem team. The Mercari marketplace app was born to create value in a global marketplace where anyone can buy &amp; sell. Thanks to the power of technology, we want people all around the world to [&hellip;]</p>\n","PublishedAt":"2021-12-01 14:00:38+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211201-why-is-metadata-important/","SourceName":"Mercari"}},{"node":{"ID":1245,"Title":"Blog: Contribution, containers and cricket: the Kubernetes 1.22 release interview","Description":"<p><strong>Author</strong>: Craig Box (Google)</p>\n<p>The Kubernetes release train rolls on, and we look ahead to the release of 1.23 next week. <a href=\"https://www.google.com/search?q=%22release+interview%22+site%3Akubernetes.io%2Fblog\">As is our tradition</a>, I'm pleased to bring you a look back at the process that brought us the previous version.</p>\n<p>The release team for 1.22 was led by <a href=\"https://twitter.com/coffeeartgirl\">Savitha Raghunathan</a>, who was, at the time, a Senior Platform Engineer at MathWorks. <a href=\"https://kubernetespodcast.com/episode/157-kubernetes-1.22/\">I spoke to Savitha</a> on the <a href=\"https://kubernetespodcast.com/\">Kubernetes Podcast from Google</a>, the weekly<super>*</super> show covering the Kubernetes and Cloud Native ecosystem.</p>\n<p>Our release conversations shine a light on the team that puts together each Kubernetes release. Make sure you <a href=\"https://kubernetespodcast.com/subscribe/\">subscribe, wherever you get your podcasts</a> so you catch the story of 1.23.</p>\n<p>And in case you're interested in why the show has been on a hiatus the last few weeks, all will be revealed in the next episode!</p>\n<p><em>This transcript has been lightly edited and condensed for clarity.</em></p>\n<hr>\n<p><strong>CRAIG BOX: Welcome to the show, Savitha.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Hey, Craig. Thanks for having me on the show. How are you today?</p>\n<p><strong>CRAIG BOX: I'm very well, thank you. I've interviewed a lot of people on the show, and you're actually the first person who's asked that of me.</strong></p>\n<p>SAVITHA RAGHUNATHAN: I'm glad. It's something that I always do. I just want to make sure the other person is good and happy.</p>\n<p><strong>CRAIG BOX: That's very kind of you. Thank you for kicking off on a wonderful foot there. I want to ask first of all — you grew up in Chennai. My association with Chennai is the <a href=\"https://en.wikipedia.org/wiki/Chennai_Super_Kings\">Super Kings cricket team</a>. Was cricket part of your upbringing?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yeah. Actually, a lot. My mom loves watching cricket. I have a younger brother, and when we were growing up, we used to play cricket on the terrace. Everyone surrounding me, my best friends — and even now, my partner — loves watching cricket, too. Cricket is a part of my life.</p>\n<p>I stopped watching it a while ago, but I still enjoy a good game.</p>\n<p><strong>CRAIG BOX: It's probably a bit harder in the US. Everything's in a different time zone. I find, with my cricket team being on the other side of the world, that it's a lot easier when they're playing near me, as opposed to trying to keep up with what they're doing when they're playing at 3:00 in the morning.</strong></p>\n<p>SAVITHA RAGHUNATHAN: That is actually one of the things that made me lose touch with cricket. I'm going to give you a piece of interesting information. I never supported Chennai Super Kings. I always supported <a href=\"https://en.wikipedia.org/wiki/Royal_Challengers_Bangalore\">Royal Challengers of Bangalore</a>.</p>\n<p>I once went to the stadium, and it was a match between the Chennai Super Kings and the RCB. I was the only one who was cheering whenever the RCB hit a 6, or when they were scoring. I got the stares of thousands of people looking at me. I'm like, &quot;what are you doing?&quot; My friends are like, &quot;you're going to get us killed! Just stop screaming!&quot;</p>\n<p><strong>CRAIG BOX: I hear you. As a New Zealander in the UK, there are a lot of international cricket matches I've been to where I am one of the few people dressed in the full beige kit. But I have to ask, why an affiliation with a different team?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I'm not sure. When the IPL came out, I really liked Virat Kohli. He was playing for RCB at that time, and I think pretty much that's it.</p>\n<p><strong>CRAIG BOX: Well, what I know about the Chennai Super Kings is that their coach is New Zealand's finest batsmen and <a href=\"https://www.youtube.com/watch?v=vSZAaUCAclw\">air conditioning salesman</a>, <a href=\"https://en.wikipedia.org/wiki/Stephen_Fleming\">Stephen Fleming</a>.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Oh, really?</p>\n<p><strong>CRAIG BOX: Yeah, he's a dead ringer for the guy who played the <a href=\"https://s1.reutersmedia.net/resources/r/?m=02&amp;d=20061130&amp;t=2&amp;i=153531&amp;w=&amp;fh=545px&amp;fw=&amp;ll=&amp;pl=&amp;sq=&amp;r=153531\">yellow Wiggle</a> back in the day.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Oh, interesting. I remember the name, but I cannot put the picture and the name together. I stopped watching cricket once I moved to the States. Then, all my focus was on studies and extracurriculars. I have always been an introvert. The campus — it was a new thing for me — they had international festivals.</p>\n<p>And every week, they'd have some kind of new thing going on, so I'd go check them out. I wouldn't participate, but I did go out and check them out. That was a big feat for me around that time because a lot of people — and still, even now, a lot of people — they kind of scare me. I don't know how to make a conversation with everyone.</p>\n<p>I'll just go and say, &quot;hi, how are you? OK, I'm good. I'm just going to move on&quot;. And I'll just go to the next person. And after two hours, I'm out of that place.</p>\n<p><strong>CRAIG BOX: Perhaps a pleasant side effect of the last 12 months — a lot fewer gatherings of people.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Could be that, but I'm so excited about KubeCon. But when I think about it, I'm like &quot;oh my God. There's going to be a lot of people. What am I going to do? I'm going to meet all my friends over there&quot;.</p>\n<p>Sometimes I have social anxiety like, what's going to happen?</p>\n<p><strong>CRAIG BOX: What's going to happen is you're going to ask them how they are at the beginning, and they're immediately going to be set at ease.</strong></p>\n<p>SAVITHA RAGHUNATHAN: <em>laughs</em> I hope so.</p>\n<p><strong>CRAIG BOX: Let's talk a little bit, then, about your transition from India to the US. You did your undergraduate degree in computer science at the SSN College of Engineering. How did you end up at Arizona State?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I always wanted to pursue higher studies when I was in India, and I didn't have the opportunity immediately. Once I graduated from my school there, I went and I worked for a couple of years. My aim was always to get out of there and come here, do my graduate studies.</p>\n<p>Eventually, I want to do a PhD. I have an idea of what I want to do. I always wanted to keep studying. If there's an option that I could just keep studying and not do work or anything of that sort, I'd just pick that other one — I'll just keep studying.</p>\n<p>But unfortunately, you need money and other things to live and sustain in this world. So I'm like, OK, I'll take a break from studies, and I will work for a while.</p>\n<p><strong>CRAIG BOX: The road to success is littered with dreams of PhDs. I have a lot of friends who thought that that was the path they were going to take, and they've had a beautiful career and probably aren't going to go back to study. Did you use the <a href=\"https://en.wikipedia.org/wiki/MATLAB\">Matlab</a> software at all while you were going through your schooling?</strong></p>\n<p>SAVITHA RAGHUNATHAN: No, unfortunately. That is a question that everyone asks. I have not used Matlab. I haven't used it even now. I don't use it for work. I didn't have any necessity for my school work. I didn't have anything to do with Matlab. I never analysed, or did data processing, or anything, with Matlab. So unfortunately, no.</p>\n<p>Everyone asks me like, you're working at <a href=\"https://en.wikipedia.org/wiki/MathWorks\">MathWorks</a>. Have you used Matlab? I'm like, no.</p>\n<p><strong>CRAIG BOX: Fair enough. Nor have I. But it's been around since the late 1970s, so I imagine there are a lot of people who will have come across it at some point. Do you work with a lot of people who have been working on it that whole time?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Kind of. Not all the time, but I get to meet some folks who work on the product itself. Most of my interactions are with the infrastructure team and platform engineering teams at MathWorks. One other interesting fact is that when I joined the company — MathWorks has an extensive internal curriculum for training and learning, which I really love. They have an &quot;Intro to Matlab&quot; course, and that's on my bucket of things to do.</p>\n<p>It was like 500 years ago. I added it, and I never got to it. I'm like, OK, maybe this year at least I want to get to it and I want to learn something new. My partner used Matlab extensively. He misses it right now at his current employer. And he's like, &quot;you have the entire licence! You have access to the entire suite and you haven't used it?&quot; I'm like, &quot;no!&quot;</p>\n<p><strong>CRAIG BOX: Well, I have bad news for the idea of you doing a PhD, I'm sorry.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Another thing is that none of my family knew about the company MathWorks and Matlab. The only person who knew was my younger brother. He was so proud. He was like, &quot;oh my God&quot;.</p>\n<p>When he was 12 years old, he started getting involved in robotics and all that stuff. That's how he got introduced to Matlab. He goes absolutely bananas for the swag. So all the t-shirts, all the hoodies — any swag that I get from MathWorks goes to him, without saying.</p>\n<p>Over the five, six years, the things that I've got — there was only one sweatshirt that I kept for myself. Everything else I've just given to him. And he cherishes it. He's the only one in my family who knew about Matlab and MathWorks.</p>\n<p>Now, everyone knows, because I'm working there. They were initially like, I don't even know that company name. Is it like Amazon? I'm like, no, we make software that can send people to the moon. And we also make software that can do amazing robotic surgeries and even make a car drive on its own. That's something that I take immense pride in.</p>\n<p>I know I don't directly work on the product, but I'm enabling the people who are creating the product. I'm really, really proud of that.</p>\n<p><strong>CRAIG BOX: I think Jeff Bezos is working on at least two out of three of those disciplines that you mentioned before, so it's maybe a little bit like Amazon. One thing I've always thought about Matlab is that, because it's called Matlab, it solves that whole problem where <a href=\"https://www.grammar.com/math_vs._maths\">Americans call it math, and the rest of the world call it maths</a>. Why do Americans think there's only one math?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Definitely. I had trouble — growing up in India, it's always British English. And I had so much trouble when I moved here. So many things changed.</p>\n<p>One of the things is maths. I always got used to writing maths, physics, and everything.</p>\n<p><strong>CRAIG BOX: They don't call it &quot;physic&quot; in the US, do they?</strong></p>\n<p>SAVITHA RAGHUNATHAN: No, no, they don't. Luckily, they don't. That still stays &quot;physics&quot;. But math — I had trouble. It's maths. Even when you do the full abbreviations like mathematics and you are still calling it math, I'm like, mm.</p>\n<p><strong>CRAIG BOX: They can do the computer science abbreviation thing and call it math-7-S or whatever the number of letters is.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Just like Kubernetes. K-8-s.</p>\n<p><strong>CRAIG BOX: Your path to Kubernetes is through MathWorks. They started out as a company making software which was distributed in a physical sense — boxed copies, if you will. I understand now there is a cloud version. Can I assume that that is where the two worlds intersect?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Kind of. I have interaction with the team that supports Matlab on the cloud, but I don't get to work with them on a day-to-day basis. They use Docker containers, and they are building the platform using Kubernetes. So yeah, a little bit of that.</p>\n<p><strong>CRAIG BOX: So what exactly is the platform that you are engineering day to day?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Providing Kubernetes as a platform, obviously — that goes without saying — to some of the internal development teams. In the future we might expand it to more teams within the company. That is a focus area right now, so that's what we are doing. In the process, we might even get to work with the people who are deploying Matlab on the cloud, which is exciting.</p>\n<p><strong>CRAIG BOX: Now, your path to contribution to Kubernetes, you've said before, was through <a href=\"https://github.com/kubernetes/website/pull/15588\">fixing a 404 error on the Kubernetes.io website</a>. Do you remember what the page was?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I do. I was going to something for work, and I came across this changelog. In Kubernetes there's a nice page — once you got to the release page, there would be a long list of changelogs.</p>\n<p>One of the things that I fixed was, the person who worked on the feature had changed their GitHub handle, and that wasn't reflected on this page. So that was my first. I got curious and clicked on the links. One of the links was the handle, and that went to a 404. And I was like &quot;Yeah, I'll just fix that. They have done all the hard work. They can get the credit that's due&quot;.</p>\n<p>It was easy. It wasn't overwhelming for me to pick it up as my first issue. Before that I logged on around Kubernetes for about six to eight months without doing anything because it was just a lot.</p>\n<p><strong>CRAIG BOX: One of the other things that you said about your initial contribution is that you had to learn how to use Git. As a very powerful tool, I find Git is a high barrier to entry for even contributing code to a project. When you want to contribute a blog post or documentation or a fix like you did before, I find it almost impossible to think how a new user would come along and do that. What was your process? Do you think that there's anything we can do to make that barrier lower for new contributors?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Of course. There are more and more tutorials available these days. There is a new contributor workshop. They actually have a <a href=\"https://www.kubernetes.dev/docs/guide/github-workflow/\">GitHub workflow section</a>, <a href=\"https://www.kubernetes.dev/docs/guide/pull-requests/\">how to do a pull request</a> and stuff like that. I know a couple of folks from SIG Docs that are working on which Git commands that you need, or how to get to writing something small and getting it committed. But more tutorials or more links to intro to Git would definitely help.</p>\n<p>The thing is also, someone like a documentation writer — they don't actually want to know the entirety of Git. Honestly, it's an ocean. I don't know how to do it. Most of the time, I still ask for help even though I work with Git on a day to day basis. There are several articles and a lot of help is available already within the community. Maybe we could just add a couple more to <a href=\"https://kubernetes.dev/\">kubernetes.dev</a>. That is an amazing site for all the new contributors and existing contributors who want to build code, who want to write documentation.</p>\n<p>We could just add a tutorial there like, &quot;hey, don't know Git, you are new to Git? You just need to know these main things&quot;.</p>\n<p><strong>CRAIG BOX: I find it a shame, to be honest, that people need to use Git for that, by comparison to Wikipedia where you can come along, and even though it might be written in Markdown or something like it, it seems like the barrier is a lot lower. Similar to you, I always have to look up anything more complicated than the five or six Git commands that I use on a day to day basis. Even to do simple things, I basically just go and follow a recipe which I find on the internet.</strong></p>\n<p>SAVITHA RAGHUNATHAN: This is how I got introduced to one of the amazing mentors in Kubernetes. Everyone knows him by his handle, Dims. It was my second PR to the Kubernetes website, and I made a mistake. I destroyed the Git history. I could not push my reviews and comments — I addressed them. I couldn't push them back.</p>\n<p>My immediate thought was to delete it and recreate, do another pull request. But then I was like, &quot;what happens to others who have already put effort into reviewing them?&quot; I asked for help, and Dims was there.</p>\n<p>I would say I just got lucky he was there. And he was like, &quot;OK, let me walk you through&quot;. We did troubleshooting through Slack messages. I copied and pasted all the errors. Every single command that he said, I copied and pasted. And then he was like, &quot;OK, run this one. Try this one. And do this one&quot;.</p>\n<p>Finally, I got it fixed. So you know what I did? I went and I stored the command history somewhere local for the next time when I run into this problem. Luckily, I haven't. But I find the contributors so helpful. They are busy. They have a lot of things to do, but they take moments to stop and help someone who's new.</p>\n<p>That is also another part of the reason why I stay — I want to contribute more. It's mainly the community. It's the Kubernetes community. I know you asked me about Git, and I just took the conversation to the Kubernetes community. That's how my brain works.</p>\n<p><strong>CRAIG BOX: A lot of people in the community do that and think that's fantastic, obviously, people like Dims who are just floating around on Slack and seem to have endless time. I don't know how they do it.</strong></p>\n<p>SAVITHA RAGHUNATHAN: I really want to know the secret for endless time. If I only had 48 hours in a day. I would sleep for 16 hours, and I would use the rest of the time for doing the things that I want.</p>\n<p><strong>CRAIG BOX: If I had a chance to sleep up to 48 hours a day, I think it'd be a lot more than 16.</strong></p>\n<p><strong>Now, one of the areas that you've been contributing to Kubernetes is in the release team. In 1.18, you were a shadow for the docs role. You led that role in 1.19. And you were a release lead shadow for versions 1,20 and 1.21 before finally leading this release, 1.22, which we will talk about soon.</strong></p>\n<p><strong>How did you get involved? And how did you decide which roles to take as you went through that process?</strong></p>\n<p>SAVITHA RAGHUNATHAN: That is a topic I love to talk about. This was fresh when I started learning about Kubernetes and using Kubernetes at work. And I got so much help from the community, I got interested in contributing back.</p>\n<p>At the first KubeCon that I attended in 2018, in Seattle, they had a speed mentoring session. Now they call it &quot;pod mentoring&quot;. I went to the session, and said, &quot;hey, I want to contribute. I don't know where to start&quot;. And I got a lot of information on how to get started.</p>\n<p>One of the places was SIG Release and the release team. I came back and diligently attended all the SIG Release meetings for four to six months. And in between, I applied to the Kubernetes release team — 1.14 and 1.15. I didn't get through. So I took a little bit of a break, and I focused on doing some documentation work. Then I applied for 1.18.</p>\n<p>Since I was already working on some kinds of — not like full fledged &quot;documentation&quot; documentation, I still don't write. I eventually want to write something really nice and full fledged documentation like other awesome folks.</p>\n<p><strong>CRAIG BOX: You'll need a lot more than 48 hours in your day to do that.</strong></p>\n<p>SAVITHA RAGHUNATHAN: <em>laughing</em> That's how I applied for the docs role, because I know a little bit about the website. I've done a few pull requests and commits. That's how I got started. I applied for that one role, and I got selected for the 1.18 team. That's how my journey just took off.</p>\n<p>And the next release, I was leading the documentation team. And as everyone knows, the pandemic hit. It was one of the longest releases. I could lean back on the community. I would just wait for the release team meetings.</p>\n<p>It was my way of coping with the pandemic. It took my mind off. It was actually more than a release team, they were people. They were all people first, and we took care of each other. So it felt good.</p>\n<p>And then, I became a release lead shadow for 1.20 and 1.21 because I wanted to know more. I wanted to learn more. I wasn't ready. I still don't feel ready, but I have led 1.22. So if I could do it, anyone could do it.</p>\n<p><strong>CRAIG BOX: How much of this work is day job?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I am lucky to be blessed with an awesome team. I do most of my work after work, but there have been times where I have to take meetings and attend to immediate urgent stuff. During the time of exception requests and stuff like that, I take a little bit of time from my work.</p>\n<p>My team has been wonderful: they support me in all possible ways, and the management as well. Other than the meetings, I don't do much of the work during the day job. It just takes my focus and attention away too much, and I end up having to spend a lot of time sitting in front of the computer, which I don't like.</p>\n<p>Before the pandemic I had a good work life balance. I'd just go to work at 7:00, 7:30, and I'd be back by 4 o'clock. I never touched my laptop ever again. I left all work behind when I came home. So right now, I'm still learning how to get through.</p>\n<p>I try to limit the amount of open source work that I do during work time. The release lead shadow and the release lead job — they require a lot of time, effort. So on average, I'd be spending two to three hours post work time on the release activities.</p>\n<p><strong>CRAIG BOX: Before the pandemic, everyone was worried that if we let people work from home, they wouldn't work enough. I think the opposite has actually happened, is that now we're worried that if we let people work from home, they will just get on the computer in the morning and you'll have to pry it out of their hands at midnight.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yeah, I think the productivity has increased at least twofold, I would say, for everyone, once they started working from home.</p>\n<p><strong>CRAIG BOX: But at the expense of work-life balance, though, because as you say, when you're sitting in the same chair in front of, perhaps, the same computer doing your MathWorks work and then your open source work, they kind of can blur into one perhaps?</strong></p>\n<p>SAVITHA RAGHUNATHAN: That is a challenge. I face it every day. But so many others are also facing it. I implemented a few little tricks to help me. When I used to come back home from work, the first thing I would do is remove my watch. That was an indication that OK, I'm done.</p>\n<p>That's the thing that I still do. I just remove my watch, and I just keep it right where my workstation is. And I just close the door so that I never look back. Even going past the room, I don't get a glimpse of my work office. I start implementing tiny little things like that to avoid burnout.</p>\n<p>I think I'm still facing a little bit of burnout. I don't know if I have fully recovered from it. I constantly feel like I need a vacation. And I could just take a vacation for like a month or two. If it's possible, I will just do it.</p>\n<p><strong>CRAIG BOX: I do hope that travel opens up for everyone as an opportunity because I know that, for a lot of people, it's not so much they've been working from home but they've been living at work. The idea of taking vacation effectively means, well, I've been stuck in the same place, if I've been under a lockdown. It's hard to justify that. It will be good as things improve worldwide for us to be able to start focusing more on mental health and perhaps getting away from the &quot;everything room,&quot; as I sometimes call it.</strong></p>\n<p>SAVITHA RAGHUNATHAN: I'm totally looking forward to it. I hope that travel opens up and I could go home and I could meet my siblings and my aunt and my parents.</p>\n<p><strong>CRAIG BOX: Catch a cricket match?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yeah. Probably yes, if I have company and if there is anything interesting happening around the time. I don't mind going back to the Chepauk Stadium and catching a match or two.</p>\n<p><strong>CRAIG BOX: Let's turn now to the recently released <a href=\"https://kubernetes.io/blog/2021/08/04/kubernetes-1-22-release-announcement/\">Kubernetes 1.22</a>. Congratulations on the launch.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Thank you.</p>\n<p><strong>CRAIG BOX: Each launch comes with a theme and a mascot or a logo. What is the theme for this release?</strong></p>\n<p>SAVITHA RAGHUNATHAN: The theme for the release is reaching new peaks. I am fascinated with a lot of space travel and chasing stars, the Milky Way. The best place to do that is over the top of a mountain. So that is the release logo, basically. It's a mountain — Mount Rainier. On top of that, there is a Kubernetes flag, and it's overlooking the Milky Way.</p>\n<p>It's also symbolic that with every release, that we are achieving something new, bigger, and better, and we are making the release awesome. So I just wanted to incorporate that into the team as to say, we are achieving new things with every release. That's the &quot;reaching new peaks&quot; theme.</p>\n<p><strong>CRAIG BOX: The last couple of releases have both been incrementally larger — as a result, perhaps, of the fact there are now only three releases per year rather than four. There were also changes to the process, where the work has been driven a lot more by the SIGs than by the release team having to go and ask the SIGs what was going on. What can you say about the size and scope of the 1.22 release?</strong></p>\n<p>SAVITHA RAGHUNATHAN: The 1.22 release is the largest release to date. We have 56 enhancements if I'm not wrong, and we have a good amount of features that's graduated as stable. You can now say that Kubernetes as a project has become more mature because you see new features coming in. At the same time, you see the features that weren't used getting deprecated — we have like three deprecations in this release.</p>\n<p>Aside from that fact, we also have a big team that's supporting one of the longest releases. This is the first official release cycle after the cadence KEP got approved. Officially, we are at four months, even though 1.19 was six months, and 1.21 was like 3 and 1/2 months, I think, this is the first one after the official KEP approval.</p>\n<p><strong>CRAIG BOX: What changes did you make to the process knowing that you had that extra month?</strong></p>\n<p>SAVITHA RAGHUNATHAN: One of the things the community had asked for is more time for development. We tried to incorporate that in the release schedule. We had about six weeks between the enhancements freeze and the code freeze. That's one.</p>\n<p>It might not be visible to everyone, but one of the things that I wanted to make sure of was the health of the team — since it was a long, long release, we had time to plan out, and not have everyone work during the weekends or during their evenings or time off. That actually helped everyone keep their sanity, and also in making good progress and delivering good results at the end of the release. That's one of the process improvements that I'd call out.</p>\n<p>We got better by making a post during the exception request process. Everyone works around the world. People from the UK start a little earlier than the people in the US East Coast. The West Coast starts three hours later than the East Coast. We used to make a post every Friday evening saying &quot;hey, we actually received this many requests. We have addressed a number of them. We are waiting on a couple, or whatever. All the release team members are done for the day. We will see you around on Monday. Have a good weekend.&quot; Something like that.</p>\n<p>We set the expectations from the community as well. We understand things are really important and urgent, but we are done. This gave everyone their time back. They don't have to worry over the weekend thinking like, hey, what's happening? What's happening in the release? They could spend time with their family, or they could do whatever they want to do, like go on a hike, or just sit and watch TV.</p>\n<p>There have been weekends that I just did that. I just binge-watched a series. That's what I did.</p>\n<p><strong>CRAIG BOX: Any recommendations?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I'm a big fan of Marvel, so I have watched the new <a href=\"https://en.wikipedia.org/wiki/Loki_(TV_series)\">Loki</a>, which I really love. Loki is one of my favourite characters in Marvel. And I also liked <a href=\"https://en.wikipedia.org/wiki/WandaVision\">WandaVision</a>. That was good, too.</p>\n<p><strong>CRAIG BOX: I've not seen Loki yet, but I've heard it described as the best series of Doctor Who in the last few years.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Really?</p>\n<p><strong>CRAIG BOX: There must be an element of time-travelling in there if that's how people are describing it.</strong></p>\n<p>SAVITHA RAGHUNATHAN: You should really go and watch it whenever you have time. It's really amazing. I might go back and watch it again because I might have missed bits and pieces. That always happens in Marvel movies and the episodes; you need to watch them a couple of times to catch, &quot;oh, this is how they relate&quot;.</p>\n<p><strong>CRAIG BOX: Yes, the mark of good media that you want to immediately go back and watch it again once you've seen it.</strong></p>\n<p><strong>Let's look now at some of the new features in Kubernetes 1.22. A couple of things that have graduated to general availability — server-side apply, external credential providers, a couple of new security features — the replacement for pod security policy has been announced, and seccomp is now available by default.</strong></p>\n<p><strong>Do you have any favourite features in 1.22 that you'd like to discuss?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I have a lot of them. All my favourite features are related to security. OK, one of them is not security, but a major theme of my favourite KEPs is security. I'll start with the <a href=\"https://github.com/kubernetes/enhancements/issues/2413\">default seccomp</a>. I think it will help make clusters secure by default, and may assist in preventing more vulnerabilities, which means less headaches for the cluster administrators.</p>\n<p>This is close to my heart because the base of the MathWorks platform is provisioning Kubernetes clusters. Knowing that they are secure by default will definitely provide me with some good sleep. And also, I'm paranoid about security most of the time. I'm super interested in making everything secure. It might get in the way of making the users of the platform angry because it's not usable in any way.</p>\n<p>My next one is <a href=\"https://github.com/kubernetes/enhancements/issues/2033\">rootless Kubelet</a>. That feature's going to enable the cluster admin, the platform developers to deploy Kubernetes components to run in a user namespace. And I think that is also a great addition.</p>\n<p>Like you mention, the most awaited drop in for the PSP replacement is here. It's <a href=\"https://github.com/kubernetes/enhancements/issues/2579\">pod admission control</a>. It lets cluster admins apply the pod security standards. And I think it's just not related to the cluster admins. I might have to go back and check on that. Anyone can probably use it — the developers and the admins alike.</p>\n<p>It also supports various modes, which is most welcome. There are times where you don't want to just cut the users off because they are trying to do something which is not securely correct. You just want to warn them, hey, this is what you are doing. This might just cause a security issue later, so you might want to correct it. But you just don't want to cut them off from using the platform, or them trying to attempt to do something — deploy their workload and get their day-to-day job done. That is something that I really like, that it also supports a warning mechanism.</p>\n<p>Another one which is not security is <a href=\"https://github.com/kubernetes/enhancements/issues/2400\">node swap support</a>. Kubernetes didn't have support for swap before, but it is taken into consideration now. This is an alpha feature. With this, you can take advantage of the swap, which is provisioned on the Linux VMs.</p>\n<p>Some of the workloads — when they are deployed, they might need a lot of swap for the start-up — example, like Node and Java applications, which I just took out of their KEP user stories. So if anyone's interested, they can go and look in the KEP. That's useful. And it also increases the node stability and whatnot. So I think it's going to be beneficial for a lot of folks.</p>\n<p>We know how Java and containers work. I think it has gotten better, but five years ago, it was so hard to get a Java application to fit in a small container. It always needed a lot of memory, swap, and everything to start up and run. I think this will help the users and help the admins and keep the cost low, and it will tie into so many other things as well. I'm excited about that feature.</p>\n<p>Another feature that I want to just call out — I don't use Windows that much, but I just want to give a shout out to the folks who are doing an amazing job bringing all the Kubernetes features to Windows as well, to give a seamless experience.</p>\n<p>One of the things is <a href=\"https://github.com/kubernetes/enhancements/issues/1981\">Windows privileged containers</a>. I think it went alpha this release. And that is a wonderful addition, if you ask me. It can take advantage of whatever that's happening on the Linux side. And they can also port it over and see, OK, I can now run Windows containers in a privileged mode.</p>\n<p>So whatever they are trying to achieve, they can do it. So that's a noteworthy mention. I need to give a shout out for the folks who work and make things happen in the Windows ecosystem as well.</p>\n<p><strong>CRAIG BOX: One of the things that's great about the release process is the continuity between groups and teams. There's always an emeritus advisor who was a lead from a previous release. One thing that I always ask when I do these interviews is, what is the advice that you give to the next person? When <a href=\"https://kubernetespodcast.com/episode/146-kubernetes-1.21/\">we talked to Nabarun for the 1.21 interview</a>, he said that his advice to you would be &quot;do, delegate, and defer&quot;. Figure out what you can do, figure out what you can ask other people to do, and figure out what doesn't need to be done. Were you able to take that advice on board?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yeah, you won't believe it. <a href=\"https://twitter.com/KubernetesPod/status/1423188323347177474/photo/3\">I have it right here stuck to my monitor.</a></p>\n<p><strong>CRAIG BOX: Next to your Git cheat sheet?</strong></p>\n<p>SAVITHA RAGHUNATHAN: <em>laughs</em> Absolutely. I just have it stuck there. I just took a look at it.</p>\n<p><strong>CRAIG BOX: Someone that you will have been able to delegate and defer to is Rey Lejano from Rancher Labs and SUSE, who is the release lead to be for 1.23.</strong></p>\n<p>SAVITHA RAGHUNATHAN: I want to tell Rey to beware of the team's mental health. Schedule in such a way that it avoids burnout. Check in, and make sure that everyone is doing good. If they need some kind of help, create a safe space where they can actually ask for help, if they want to step back, if they need someone to cover.</p>\n<p>I think that is most important. The releases are successful based on the thousands and thousands of contributors. But when it comes to a release team, you need to have a healthy team where people feel they are in a good place and they just want to make good contributions, which means they want to be heard. That's one thing that I want to tell Rey.</p>\n<p>Also collaborate and learn from each other. I constantly learn. I think the team was 39 folks, including me. Every day I learned something or the other, even starting from how to interact.</p>\n<p>Sometimes I have learned more leadership skills from my release lead shadows. They are awesome, and they are mature. I constantly learn from them, and I admire them a lot.</p>\n<p>It also helps to have good, strong individuals in the team who can step up and help when needed. For example, unfortunately, we lost one of our teammates after the start of the release cycle. That was tragic. His name was <a href=\"https://github.com/cncf/memorials/blob/main/peeyush-gupta.md\">Peeyush Gupta</a>. He was an awesome and wonderful human — very warm.</p>\n<p>I didn't get more of a chance to interact with him. I had exchanged a few Slack messages, but I got his warm personality. I just want to take a couple of seconds to remember him. He was awesome.</p>\n<p>After we lost him, we had this strong person from the team step up and lead the communications, who had never been a part of the release team before at all. He was a shadow for the first time. His name is Jesse Butler. So he stepped up, and he just took it away. He ran the comms show for 1.22.</p>\n<p>That's what the community is about. You take care of team members, and the team will take care of you. So that's one other thing that I want to let Rey know, and maybe whoever — I think it's applicable overall.</p>\n<p><strong>CRAIG BOX: There's a link to a <a href=\"https://milaap.org/fundraisers/support-peeyush-gupta-family-education\">family education fund for Peeyush Gupta</a>, which you can find in the show notes.</strong></p>\n<p><strong>Five releases in a row now you've been a member of the release team. Will you be putting your feet up now for 1.23?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I am going to take a break for a while. In the future, I want to be contributing, if not the release team, the SIG Release and the release management effort. But right now, I have been there for five releases. And I feel like, OK, I just need a little bit of fresh air.</p>\n<p>And also the pandemic and the burnout has caught up, so I'm going to take a break from certain contributions. You will see me in the future. I will be around, but I might not be actively participating in the release team activities. I will be around the community. Anyone can reach out to me. They all know my Slack, so they can just reach out to me via Slack or Twitter.</p>\n<p><strong>CRAIG BOX: Yes, your Twitter handle is CoffeeArtGirl. Does that mean that you'll be spending some time working on your lattes?</strong></p>\n<p>SAVITHA RAGHUNATHAN: I am very bad at making lattes. The coffee art means that I used to <a href=\"https://twitter.com/KubernetesPod/status/1423188323347177474/photo/1\">make art with coffee</a>. You get instant coffee powder and just mix it with water. You get the colours, very beautiful brown colours. I used to make art using that.</p>\n<p>And I love coffee. So I just combined all the words together. And I had to come up with it in a span of one hour or so because I was joining this 'meet our contributors' panel. And Paris asked me, &quot;do you have a Twitter handle?&quot; I was planning to create one, but I didn't have the time.</p>\n<p>I'm like, well, let me just think what I could just come up with real quick. So I just came up with that. So that's the story behind my Twitter handle. Everyone's interested in it. You are not the first person you have asked me or mentioned about it. So many others are like, why coffee art?</p>\n<p><strong>CRAIG BOX: And you are also interested in art with perhaps other materials?</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yes. My interests keep changing. I used to do pebble art. It's just collecting pebbles from wherever I go, and I used to paint on them. I used to use watercolour, but I want to come back to watercolour sometime.</p>\n<p>My recent interests are coloured pencils, which came back. When I was very young, I used to do a lot of coloured pencils. And then I switched to watercolours and oil painting. So I just go around in circles.</p>\n<p>One of the hobbies that I picked up during a pandemic is crochet. I made a scarf for Mother's Day. My mum and my dad were here last year. They got stuck because of the pandemic, and they couldn't go back home. So they stayed with me for 10 months. That is the jackpot that I had, that I got to spend so much time with my parents after I moved to the US.</p>\n<p><strong>CRAIG BOX: And they got rewarded with a scarf.</strong></p>\n<p>SAVITHA RAGHUNATHAN: Yeah.</p>\n<p><strong>CRAIG BOX: One to share between them.</strong></p>\n<p>SAVITHA RAGHUNATHAN: I started making a blanket for my dad. And it became so heavy, I might have to just pick up some lighter yarn. I still don't know the differences between different kinds of yarns, but I'm getting better.</p>\n<p>I started out because I wanted to make these little toys. They call them <a href=\"https://en.wikipedia.org/wiki/Amigurumi\">amigurumi</a> in the crochet world. I wanted to make them. That's why I started out. I'm trying. I made <a href=\"https://twitter.com/KubernetesPod/status/1423188323347177474/photo/2\">a little cat</a> which doesn't look like a cat, but it is a cat. I have to tell everyone that it's a cat so that they don't mock me later, but.</p>\n<p><strong>CRAIG BOX: It's an artistic interpretation of a cat.</strong></p>\n<p>SAVITHA RAGHUNATHAN: It definitely is!</p>\n<hr>\n<p><em><a href=\"https://twitter.com/coffeeartgirl\">Savitha Raghunathan</a>, now a Senior Software Engineer at Red Hat, served as the Kubernetes 1.22 release team lead.</em></p>\n<p><em>You can find the <a href=\"http://www.kubernetespodcast.com/\">Kubernetes Podcast from Google</a> at <a href=\"https://twitter.com/KubernetesPod\">@KubernetesPod</a> on Twitter, and you can <a href=\"https://kubernetespodcast.com/subscribe/\">subscribe</a> so you never miss an episode.</em></p>","PublishedAt":"2021-12-01 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/01/contribution-containers-and-cricket-the-kubernetes-1.22-release-interview/","SourceName":"Kubernetes"}},{"node":{"ID":1127,"Title":"Compiling for iOS on Apple M1","Description":"<p>Background At Mercari, we do our best to keep our tools and libraries up to date. This leads to a need to also upgrade our hardware. This year, many employees got their hands on a new M1 computer from Apple. This new computer is not an Intel based computer anymore but an arm64-based cpu. This [&hellip;]</p>\n","PublishedAt":"2021-11-30 12:00:19+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211129-compiling-for-ios-on-apple-m1/","SourceName":"Mercari"}},{"node":{"ID":469,"Title":"Re-build vs. buy—or how to turn a legacy tool into a new data stack","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/11/Blog-36-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Build vs. buy is one of those “evergreen” debates. When building a data stack and figuring out its respective components, it seems like it’ll never be out of style to ask: Wouldn’t it just be easier to buy? But there&#8217;s another, similar scenario that&#8217;s much less talked about even though it&#8217;s probably equally as important</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/re-build-vs-buy-or-how-to-turn-a-legacy-tool-into-a-data-stack/\">Re-build vs. buy—or how to turn a legacy tool into a new data stack</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-11-30 04:19:00+00:00","OriginURL":"https://mixpanel.com/blog/re-build-vs-buy-or-how-to-turn-a-legacy-tool-into-a-data-stack/","SourceName":"Mixpanel"}},{"node":{"ID":1246,"Title":"Blog: Quality-of-Service for Memory Resources","Description":"<p><strong>Authors:</strong> Tim Xu (Tencent Cloud)</p>\n<p>Kubernetes v1.22, released in August 2021, introduced a new alpha feature that improves how Linux nodes implement memory resource requests and limits.</p>\n<p>In prior releases, Kubernetes did not support memory quality guarantees.\nFor example, if you set container resources as follows:</p>\n<pre tabindex=\"0\"><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: example\nspec:\ncontainers:\n- name: nginx\nresources:\nrequests:\nmemory: &#34;64Mi&#34;\ncpu: &#34;250m&#34;\nlimits:\nmemory: &#34;64Mi&#34;\ncpu: &#34;500m&#34;\n</code></pre><p><code>spec.containers[].resources.requests</code>(e.g. cpu, memory) is designed for scheduling. When you create a Pod, the Kubernetes scheduler selects a node for the Pod to run on. Each node has a maximum capacity for each of the resource types: the amount of CPU and memory it can provide for Pods. The scheduler ensures that, for each resource type, the sum of the resource requests of the scheduled Containers is less than the capacity of the node.</p>\n<p><code>spec.containers[].resources.limits</code> is passed to the container runtime when the kubelet starts a container. CPU is considered a &quot;compressible&quot; resource. If your app starts hitting your CPU limits, Kubernetes starts throttling your container, giving your app potentially worse performance. However, it won’t be terminated. That is what &quot;compressible&quot; means.</p>\n<p>In cgroup v1, and prior to this feature, the container runtime never took into account and effectively ignored spec.containers[].resources.requests[&quot;memory&quot;]. This is unlike CPU, in which the container runtime consider both requests and limits. Furthermore, memory actually can't be compressed in cgroup v1. Because there is no way to throttle memory usage, if a container goes past its memory limit it will be terminated by the kernel with an OOM (Out of Memory) kill.</p>\n<p>Fortunately, cgroup v2 brings a new design and implementation to achieve full protection on memory. The new feature relies on cgroups v2 which most current operating system releases for Linux already provide. With this experimental feature, <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/\">quality-of-service for pods and containers</a> extends to cover not just CPU time but memory as well.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>Memory QoS uses the memory controller of cgroup v2 to guarantee memory resources in Kubernetes. Memory requests and limits of containers in pod are used to set specific interfaces <code>memory.min</code> and <code>memory.high</code> provided by the memory controller. When <code>memory.min</code> is set to memory requests, memory resources are reserved and never reclaimed by the kernel; this is how Memory QoS ensures the availability of memory for Kubernetes pods. And if memory limits are set in the container, this means that the system needs to limit container memory usage, Memory QoS uses <code>memory.high</code> to throttle workload approaching it's memory limit, ensuring that the system is not overwhelmed by instantaneous memory allocation.</p>\n<p><img src=\"./memory-qos-cal.svg\" alt=\"\"></p>\n<p>The following table details the specific functions of these two parameters and how they correspond to Kubernetes container resources.</p>\n<table>\n<tr>\n<th style=\"text-align:center\">File</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n<tr>\n<td>memory.min</td>\n<td><code>memory.min</code> specifies a minimum amount of memory the cgroup must always retain, i.e., memory that can never be reclaimed by the system. If the cgroup's memory usage reaches this low limit and can’t be increased, the system OOM killer will be invoked.\n<br>\n<br>\n<i>We map it to the container's memory request</i>\n</td>\n</tr>\n<tr>\n<td>memory.high</td>\n<td><code>memory.high</code> is the memory usage throttle limit. This is the main mechanism to control a cgroup's memory use. If a cgroup's memory use goes over the high boundary specified here, the cgroup’s processes are throttled and put under heavy reclaim pressure. The default is max, meaning there is no limit.\n<br>\n<br>\n<i>We use a formula to calculate <code>memory.high</code>, depending on container's memory limit or node allocatable memory (if container's memory limit is empty) and a throttling factor. Please refer to the KEP for more details on the formula.</i>\n</td>\n</tr>\n</table>\n<p>When container memory requests are made, kubelet passes <code>memory.min</code> to the back-end CRI runtime (possibly containerd, cri-o) via the <code>Unified</code> field in CRI during container creation. The <code>memory.min</code> in container level cgroup will be set to:</p>\n<p><img src=\"./container-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p>Since the <code>memory.min</code> interface requires that the ancestor cgroup directories are all set, the pod and node cgroup directories need to be set correctly.</p>\n<p><code>memory.min</code> in pod level cgroup:<br>\n<img src=\"./pod-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p><code>memory.min</code> in node level cgroup:<br>\n<img src=\"./node-memory-min.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> pod in one node, j: the j<sup>th</sup> container in one pod</sub></p>\n<p>Kubelet will manage the cgroup hierarchy of the pod level and node level cgroups directly using runc libcontainer library, while container cgroup limits are managed by the container runtime.</p>\n<p>For memory limits, in addition to the original way of limiting memory usage, Memory QoS adds an additional feature of throttling memory allocation. A throttling factor is introduced as a multiplier (default is 0.8). If the result of multiplying memory limits by the factor is greater than memory requests, kubelet will set <code>memory.high</code> to the value and use <code>Unified</code> via CRI. And if the container does not specify memory limits, kubelet will use node allocatable memory instead. The <code>memory.high</code> in container level cgroup is set to:</p>\n<p><img src=\"./container-memory-high.svg\" alt=\"\"><br>\n<sub>i: the i<sup>th</sup> container in one pod</sub></p>\n<p>This can can help improve stability when pod memory usage increases, ensuring that memory is throttled as it approaches the memory limit.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>Here are the prerequisites for enabling Memory QoS on your Linux node, some of these are related to <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2254-cgroup-v2\">Kubernetes support for cgroup v2</a>.</p>\n<ol>\n<li>Kubernetes since v1.22</li>\n<li><a href=\"https://github.com/opencontainers/runc\">runc</a> since v1.0.0-rc93; <a href=\"https://containerd.io/\">containerd</a> since 1.4; <a href=\"https://cri-o.io/\">cri-o</a> since 1.20</li>\n<li>Linux kernel minimum version: 4.15, recommended version: 5.2+</li>\n<li>Linux image with cgroupv2 enabled or enabling cgroupv2 unified_cgroup_hierarchy manually</li>\n</ol>\n<p>OCI runtimes such as runc and crun already support cgroups v2 <a href=\"https://github.com/opencontainers/runtime-spec/blob/master/config-linux.md#unified\"><code>Unified</code></a>, and Kubernetes CRI has also made the desired changes to support passing <a href=\"https://github.com/kubernetes/kubernetes/pull/102578\"><code>Unified</code></a>. However, CRI Runtime support is required as well. Memory QoS in Alpha phase is designed to support containerd and cri-o. Related PR <a href=\"https://github.com/containerd/containerd/pull/5627\">Feature: containerd-cri support LinuxContainerResources.Unified #5627</a> has been merged and will be released in containerd 1.6. CRI-O <a href=\"https://github.com/cri-o/cri-o/pull/5207\">implement kube alpha features for 1.22 #5207</a> is still in WIP.</p>\n<p>With those prerequisites met, you can enable the memory QoS feature gate (see <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/\">Set kubelet parameters via a config file</a>).</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>You can find more details as follows:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2570-memory-qos/#readme\">Support Memory QoS with cgroup v2</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2254-cgroup-v2/#readme\">cgroup v2</a></li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>You can reach SIG Node by several means:</p>\n<ul>\n<li>Slack: <a href=\"https://kubernetes.slack.com/messages/sig-node\">#sig-node</a></li>\n<li><a href=\"https://groups.google.com/forum/#!forum/kubernetes-sig-node\">Mailing list</a></li>\n<li><a href=\"https://github.com/kubernetes/community/labels/sig%2Fnode\">Open Community Issues/PRs</a></li>\n</ul>\n<p>You can also contact me directly:</p>\n<ul>\n<li>GitHub / Slack: @xiaoxubeii</li>\n<li>Email: <a href=\"mailto:xiaoxubeii@gmail.com\">xiaoxubeii@gmail.com</a></li>\n</ul>","PublishedAt":"2021-11-26 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/11/26/qos-memory-resources/","SourceName":"Kubernetes"}},{"node":{"ID":1128,"Title":"Mercari Advent Calendar 2021 is coming up!","Description":"<p>Hello! I’m @afroscript of the Mercari Engineering Office. We have our annual Advent Calendar event in December every year and we’ll be hosting it again this year! We have both Mercari and Merpay Advent Calendar at the same time. ▶ Merpay Advent Calendar 2021 is here What is the Advent Calendar? The original meaning of [&hellip;]</p>\n","PublishedAt":"2021-11-25 14:30:17+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211125-mercari-advent-calendar-2021/","SourceName":"Mercari"}},{"node":{"ID":1266,"Title":"How to switch between Java LTS versions 8, 11 and 17 on Mac","Description":"","PublishedAt":"2021-11-25 11:59:25+00:00","OriginURL":"https://medium.com/miro-engineering/how-to-switch-between-java-lts-versions-8-11-and-17-on-mac-cb6717d1272?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":146,"Title":"How Dropbox Replay keeps everyone in sync","Description":"","PublishedAt":"2021-11-23 14:00:00+00:00","OriginURL":"https://dropbox.tech/application/how-dropbox-replay-keeps-everyone-in-sync","SourceName":"Dropbox"}},{"node":{"ID":1267,"Title":"Agile Data Engineering at Miro","Description":"","PublishedAt":"2021-11-22 12:53:21+00:00","OriginURL":"https://medium.com/miro-engineering/agile-data-engineering-at-miro-ec2dcc8a3fcb?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":610,"Title":"trivago Tech Check-in: Meet Mohammad","Description":"","PublishedAt":"2021-11-22 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-11-22-trivagotechcheckinmeetmohammad/","SourceName":"Trivago"}},{"node":{"ID":1129,"Title":"Next Direction of Engineering Office","Description":"<p>Hello, everyone. I’m @hisahiko, Engineering Office Director. For this article, I wanted to write about the work we’re doing to prepare Mercari’s Engineering Division for the future. I also wrote an article about how the Engineering Office is working to strengthen our Engineering Div as part of the “Mercari Advent Calendar” project at the end [&hellip;]</p>\n","PublishedAt":"2021-11-21 13:12:56+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211115-next-direction-of-engineering-office/","SourceName":"Mercari"}},{"node":{"ID":764,"Title":"CRISP: Critical Path Analysis for Microservice Architectures","Description":"<p><span style=\"font-weight: 400;\">Uber’s backend is an exemplar of microservice architecture. Each microservice is a small, individually deployable program performing a specific business logic (operation). The microservice architecture is a type of distributed computing system, which is suitable for independent deployments and scaling </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/\">CRISP: Critical Path Analysis for Microservice Architectures</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-11-18 18:00:39+00:00","OriginURL":"https://eng.uber.com/crisp-critical-path-analysis-for-microservice-architectures/","SourceName":"Uber"}},{"node":{"ID":252,"Title":"Giphy SDK: Bridging Native SDKs in React Native","Description":"To make it easier for React Native developers to implement GIPHY and let their users share GIFs, Clips, and more, we released the GIPHY SDK for React Native a few months ago.","PublishedAt":"2021-11-17 15:06:46+00:00","OriginURL":"https://engineering.giphy.com/giphy-sdk-bridging-native-sdks-in-react-native/","SourceName":"GIPHY"}},{"node":{"ID":1268,"Title":"How we use Miro at Miro","Description":"","PublishedAt":"2021-11-16 05:31:07+00:00","OriginURL":"https://medium.com/miro-engineering/how-we-use-miro-at-miro-17f7f2c1b8a5?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}}]}},"pageContext":{"limit":30,"skip":4050,"numPages":158,"currentPage":136}},"staticQueryHashes":["3649515864"]}