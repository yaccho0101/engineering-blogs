{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/135","result":{"data":{"allPost":{"edges":[{"node":{"ID":464,"Title":"The ultimate guide to cohort analysis: How to reduce churn and strengthen your product","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2018/08/20211208_BlogHero_Cohorts-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Cohort analysis is one of the best ways product analytics can help you both acquire and retain customers.&#160; By digging into actual behavioral data overtime, instead of relying solely on interviews and feedback, you can get a crystal clear picture of a user journey—including where the value moments and roadblocks lay.&#160; With this level of</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/cohort-analysis/\">The ultimate guide to cohort analysis: How to reduce churn and strengthen your product</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-12-20 21:51:00+00:00","OriginURL":"https://mixpanel.com/blog/cohort-analysis/","SourceName":"Mixpanel"}},{"node":{"ID":82,"Title":"Felix, the “DevOps” between designers and developers","Description":"","PublishedAt":"2021-12-20 16:23:45+00:00","OriginURL":"https://medium.com/groupon-eng/felix-the-devops-between-designers-and-developers-c2976572e9f?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":240,"Title":"Recognizing Organizations Leading the Way in Data Security & Governance","Description":"<p>The importance of including centralized data management, security, and governance into data projects from the start</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/recognizing-organizations-leading-the-way-in-data-security-governance/\">Recognizing Organizations Leading the Way in Data Security &#038; Governance</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-20 13:55:36+00:00","OriginURL":"https://blog.cloudera.com/recognizing-organizations-leading-the-way-in-data-security-governance/","SourceName":"Cloudera"}},{"node":{"ID":1109,"Title":"Kubernetes based autoscaler for Cloud Spanner","Description":"<p>This article was published on day 22nd of Merpay Advent Calendar 2021, brought to you by @ravi from the Merpay SRE team. When it comes to DBaaS, all the cloud providers offer some solutions for meeting various kinds of user requirements. Google’s Cloud Spanner is one such solution from their list of available database options. [&hellip;]</p>\n","PublishedAt":"2021-12-20 10:00:23+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211222-kubernetes-based-spanner-autoscaler/","SourceName":"Mercari"}},{"node":{"ID":465,"Title":"Mixpanel Community: Top posts from 2021","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/12/MXP-Blog-TopPosts2021-1920x1080-1-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>As Community Manager at Mixpanel, I get to engage with Mixpanel users on a daily basis.&#160; Honestly, it’s the best. From in-the-weeds guidance on specific integrations to big picture best practices on product analytics, I love the kind of knowledge our members seek out—and what they share in return. If you didn’t know Mixpanel had</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/mixpanel-community-top-posts-from-2021/\">Mixpanel Community: Top posts from 2021</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-12-17 17:32:00+00:00","OriginURL":"https://mixpanel.com/blog/mixpanel-community-top-posts-from-2021/","SourceName":"Mixpanel"}},{"node":{"ID":241,"Title":"#ClouderaLife Spotlight: Manoj Shanmugasundaram – Principal Solutions Engineer","Description":"<p>Manoj Shanmugasundaram has been with Cloudera for 5 and a half years bringing his talents to our Solutions Engineering team.  As a Principal Solutions Engineer, he says his core responsibility is “to take Cloudera&#8217;s latest and greatest technology and meet a customer&#8217;s complex business requirements, across the data lifecycle, on any cloud or the datacenter.” [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/clouderalife-spotlight-manoj-shanmugasundaram-principal-solutions-engineer/\">#ClouderaLife Spotlight: Manoj Shanmugasundaram &#8211; Principal Solutions Engineer</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-17 14:06:27+00:00","OriginURL":"https://blog.cloudera.com/clouderalife-spotlight-manoj-shanmugasundaram-principal-solutions-engineer/","SourceName":"Cloudera"}},{"node":{"ID":609,"Title":"Presenting @trivago/prettier-plugin-sort-imports","Description":"I’m happy to share that trivago has released a Prettier plugin which sorts import declarations in TypeSCript and JavaScript modules for a given configured order. Throughout this article, I’ll explain to you the motivation behind this Prettier plugin and how it works in detail.","PublishedAt":"2021-12-17 00:00:00+00:00","OriginURL":"https://tech.trivago.com/post/2021-12-17-aprettierpluginthatsortsyourimports/","SourceName":"Trivago"}},{"node":{"ID":1238,"Title":"Blog: What's new in Security Profiles Operator v0.4.0","Description":"<p><strong>Authors:</strong> Jakub Hrozek, Juan Antonio Osorio, Paulo Gomes, Sascha Grunert</p>\n<hr>\n<p>The <a href=\"https://sigs.k8s.io/security-profiles-operator\">Security Profiles Operator (SPO)</a>\nis an out-of-tree Kubernetes enhancement to make the management of\n<a href=\"https://en.wikipedia.org/wiki/Seccomp\">seccomp</a>,\n<a href=\"https://en.wikipedia.org/wiki/Security-Enhanced_Linux\">SELinux</a> and\n<a href=\"https://en.wikipedia.org/wiki/AppArmor\">AppArmor</a> profiles easier and more\nconvenient. We're happy to announce that we recently <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/releases/tag/v0.4.0\">released\nv0.4.0</a>\nof the operator, which contains a ton of new features, fixes and usability\nimprovements.</p>\n<h2 id=\"what-s-new\">What's new</h2>\n<p>It has been a while since the last\n<a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/releases/tag/v0.3.0\">v0.3.0</a>\nrelease of the operator. We added new features, fine-tuned existing ones and\nreworked our documentation in 290 commits over the past half year.</p>\n<p>One of the highlights is that we're now able to record seccomp and SELinux\nprofiles using the operators <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#log-enricher-based-recording\">log enricher</a>.\nThis allows us to reduce the dependencies required for profile recording to have\n<a href=\"https://linux.die.net/man/8/auditd\">auditd</a> or\n<a href=\"https://en.wikipedia.org/wiki/Syslog\">syslog</a> (as fallback) running on the\nnodes. All profile recordings in the operator work in the same way by using the\n<code>ProfileRecording</code> CRD as well as their corresponding <a href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\">label\nselectors</a>. The log\nenricher itself can be also used to gather meaningful insights about seccomp and\nSELinux messages of a node. Checkout the <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#using-the-log-enricher\">official\ndocumentation</a>\nto learn more about it.</p>\n<h3 id=\"seccomp-related-improvements\">seccomp related improvements</h3>\n<p>Beside the log enricher based recording we now offer an alternative to record\nseccomp profiles by utilizing <a href=\"https://ebpf.io\">ebpf</a>. This optional feature can\nbe enabled by setting <code>enableBpfRecorder</code> to <code>true</code>. This results in running a\ndedicated container, which ships a custom bpf module on every node to collect\nthe syscalls for containers. It even supports older Kernel versions which do not\nexpose the <a href=\"https://www.kernel.org/doc/html/latest/bpf/btf.html\">BPF Type Format (BTF)</a> per\ndefault as well as the <code>amd64</code> and <code>arm64</code> architectures. Checkout\n<a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#ebpf-based-recording\">our documentation</a>\nto see it in action. By the way, we now add the seccomp profile architecture of\nthe recorder host to the recorded profile as well.</p>\n<p>We also graduated the seccomp profile API from <code>v1alpha1</code> to <code>v1beta1</code>. This\naligns with our overall goal to stabilize the CRD APIs over time. The only thing\nwhich has changed is that the seccomp profile type <code>Architectures</code> now points to\n<code>[]Arch</code> instead of <code>[]*Arch</code>.</p>\n<h3 id=\"selinux-enhancements\">SELinux enhancements</h3>\n<p>Managing SELinux policies (an equivalent to using <code>semodule</code> that\nyou would normally call on a single server) is not done by SPO\nitself, but by another container called selinuxd to provide better\nisolation. This release switched to using selinuxd containers from\na personal repository to images located under <a href=\"https://quay.io/organization/security-profiles-operator\">our team's quay.io\nrepository</a>.\nThe selinuxd repository has moved as well to <a href=\"https://github.com/containers/selinuxd\">the containers GitHub\norganization</a>.</p>\n<p>Please note that selinuxd links dynamically to <code>libsemanage</code> and mounts the\nSELinux directories from the nodes, which means that the selinuxd container\nmust be running the same distribution as the cluster nodes. SPO defaults\nto using CentOS-8 based containers, but we also build Fedora based ones.\nIf you are using another distribution and would like us to add support for\nit, please file <a href=\"https://github.com/containers/selinuxd/issues\">an issue against selinuxd</a>.</p>\n<h4 id=\"profile-recording\">Profile Recording</h4>\n<p>This release adds support for recording of SELinux profiles.\nThe recording itself is managed via an instance of a <code>ProfileRecording</code> Custom\nResource as seen in an\n<a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/main/examples/profilerecording-selinux-logs.yaml\">example</a>\nin our repository. From the user's point of view it works pretty much the same\nas recording of seccomp profiles.</p>\n<p>Under the hood, to know what the workload is doing SPO installs a special\npermissive policy called <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/main/deploy/base/profiles/selinuxrecording.cil\">selinuxrecording</a>\non startup which allows everything and logs all AVCs to <code>audit.log</code>.\nThese AVC messages are scraped by the log enricher component and when\nthe recorded workload exits, the policy is created.</p>\n<h4 id=\"selinuxprofile-crd-graduation\"><code>SELinuxProfile</code> CRD graduation</h4>\n<p>An <code>v1alpha2</code> version of the <code>SelinuxProfile</code> object has been introduced. This\nremoves the raw Common Intermediate Language (CIL) from the object itself and\ninstead adds a simple policy language to ease the writing and parsing\nexperience.</p>\n<p>Alongside, a <code>RawSelinuxProfile</code> object was also introduced. This contains a\nwrapped and raw representation of the policy. This was intended for folks to be\nable to take their existing policies into use as soon as possible. However, on\nvalidations are done here.</p>\n<h3 id=\"apparmor-support\">AppArmor support</h3>\n<p>This version introduces the initial support for AppArmor, allowing users to load and\nunload AppArmor profiles into cluster nodes by using the new <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/main/deploy/base/crds/apparmorprofile.yaml\">AppArmorProfile</a> CRD.</p>\n<p>To enable AppArmor support use the <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/main/examples/config.yaml#L10\">enableAppArmor feature gate</a> switch of your SPO configuration.\nThen use our <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/main/examples/apparmorprofile.yaml\">apparmor example</a> to deploy your first profile across your cluster.</p>\n<h3 id=\"metrics\">Metrics</h3>\n<p>The operator now exposes metrics, which are described in detail in\nour new <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#using-metrics\">metrics documentation</a>.\nWe decided to secure the metrics retrieval process by using\n<a href=\"https://github.com/brancz/kube-rbac-proxy\">kube-rbac-proxy</a>, while we ship an\nadditional <code>spo-metrics-client</code> cluster role (and binding) to retrieve the\nmetrics from within the cluster. If you're using\n<a href=\"https://www.redhat.com/en/technologies/cloud-computing/openshift\">OpenShift</a>,\nthen we provide an out of the box working\n<a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#automatic-servicemonitor-deployment\"><code>ServiceMonitor</code></a>\nto access the metrics.</p>\n<h4 id=\"debuggability-and-robustness\">Debuggability and robustness</h4>\n<p>Beside all those new features, we decided to restructure parts of the Security\nProfiles Operator internally to make it better to debug and more robust. For\nexample, we now maintain an internal <a href=\"https://grpc.io\">gRPC</a> API to communicate\nwithin the operator across different features. We also improved the performance\nof the log enricher, which now caches results for faster retrieval of the log\ndata. The operator can be put into a more <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#set-logging-verbosity\">verbose log mode</a>\nby setting <code>verbosity</code> from <code>0</code> to <code>1</code>.</p>\n<p>We also print the used <code>libseccomp</code> and <code>libbpf</code> versions on startup, as well as\nexpose CPU and memory profiling endpoints for each container via the\n<a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/71b3915/installation-usage.md#enable-cpu-and-memory-profiling\"><code>enableProfiling</code> option</a>.\nDedicated liveness and startup probes inside of the operator daemon will now\nadditionally improve the life cycle of the operator.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Thank you for reading this update. We're looking forward to future enhancements\nof the operator and would love to get your feedback about the latest release.\nFeel free to reach out to us via the Kubernetes slack\n<a href=\"https://kubernetes.slack.com/messages/security-profiles-operator\">#security-profiles-operator</a>\nfor any feedback or question.</p>","PublishedAt":"2021-12-17 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/17/security-profiles-operator/","SourceName":"Kubernetes"}},{"node":{"ID":763,"Title":"Cadence Multi-Tenant Task Processing","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Cadence is a multi-tenant orchestration framework that helps developers at Uber to write fault-tolerant, long-running applications, also known as workflows. It scales horizontally to handle millions of concurrent executions from various customers. It is currently used by hundreds of </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/cadence-multi-tenant-task-processing/\">Cadence Multi-Tenant Task Processing</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-12-16 17:30:14+00:00","OriginURL":"https://eng.uber.com/cadence-multi-tenant-task-processing/","SourceName":"Uber"}},{"node":{"ID":242,"Title":"How To Overcome Hybrid Cloud Migration Roadblocks","Description":"<p>Hybrid cloud data services and analytics is becoming a new enterprise standard as much of the global workforce has switched to a hybrid way of working. To implement hybrid data strategies, IT leaders need tactics to overcome internal and external hurdles.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/how-to-overcome-hybrid-cloud-migration-roadblocks/\">How To Overcome Hybrid Cloud Migration Roadblocks</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-16 14:24:34+00:00","OriginURL":"https://blog.cloudera.com/how-to-overcome-hybrid-cloud-migration-roadblocks/","SourceName":"Cloudera"}},{"node":{"ID":1110,"Title":"Mercari&#8217;s Opensource Supporter Project","Description":"<p>This is the 16th entry in Mercari Advent Calendar 2021, by @lestrrat from Engineering Office. In this Advent Calendar entry, I’d like to describe our activities to support FOSS projects and communities in a more direct manner, which is something we have been working on for the last few months. Without further ado, we are [&hellip;]</p>\n","PublishedAt":"2021-12-16 11:00:48+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/mercaris-opensource-supporter-project/","SourceName":"Mercari"}},{"node":{"ID":1239,"Title":"Blog: Kubernetes 1.23: StatefulSet PVC Auto-Deletion (alpha)","Description":"<p><strong>Author:</strong> Matthew Cary (Google)</p>\n<p>Kubernetes v1.23 introduced a new, alpha-level policy for\n<a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\">StatefulSets</a> that controls the lifetime of\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\">PersistentVolumeClaims</a> (PVCs) generated from the\nStatefulSet spec template for cases when they should be deleted automatically when the StatefulSet\nis deleted or pods in the StatefulSet are scaled down.</p>\n<h2 id=\"what-problem-does-this-solve\">What problem does this solve?</h2>\n<p>A StatefulSet spec can include Pod and PVC templates. When a replica is first created, the\nKubernetes control plane creates a PVC for that replica if one does not already exist. The behavior\nbefore Kubernetes v1.23 was that the control plane never cleaned up the PVCs created for\nStatefulSets - this was left up to the cluster administrator, or to some add-on automation that\nyou’d have to find, check suitability, and deploy. The common pattern for managing PVCs, either\nmanually or through tools such as Helm, is that the PVCs are tracked by the tool that manages them,\nwith explicit lifecycle. Workflows that use StatefulSets must determine on their own what PVCs are\ncreated by a StatefulSet and what their lifecycle should be.</p>\n<p>Before this new feature, when a StatefulSet-managed replica disappears, either because the\nStatefulSet is reducing its replica count, or because its StatefulSet is deleted, the PVC and its\nbacking volume remains and must be manually deleted. While this behavior is appropriate when the\ndata is critical, in many cases the persistent data in these PVCs is either temporary, or can be\nreconstructed from another source. In those cases, PVCs and their backing volumes remaining after\ntheir StatefulSet or replicas have been deleted are not necessary, incur cost, and require manual\ncleanup.</p>\n<h2 id=\"the-new-statefulset-pvc-retention-policy\">The new StatefulSet PVC retention policy</h2>\n<p>If you enable the alpha feature, a StatefulSet spec includes a PersistentVolumeClaim retention\npolicy. This is used to control if and when PVCs created from a StatefulSet’s <code>volumeClaimTemplate</code>\nare deleted. This first iteration of the retention policy contains two situations where PVCs may be\ndeleted.</p>\n<p>The first situation is when the StatefulSet resource is deleted (which implies that all replicas are\nalso deleted). This is controlled by the <code>whenDeleted</code> policy. The second situation, controlled by\n<code>whenScaled</code> is when the StatefulSet is scaled down, which removes some but not all of the replicas\nin a StatefulSet. In both cases the policy can either be <code>Retain</code>, where the corresponding PVCs are\nnot touched, or <code>Delete</code>, which means that PVCs are deleted. The deletion is done with a normal\n<a href=\"https://kubernetes.io/docs/concepts/architecture/garbage-collection/\">object deletion</a>, so that, for example, all\nretention policies for the underlying PV are respected.</p>\n<p>This policy forms a matrix with four cases. I’ll walk through and give an example for each one.</p>\n<ul>\n<li>\n<p><strong><code>whenDeleted</code> and <code>whenScaled</code> are both <code>Retain</code>.</strong> This matches the existing behavior for\nStatefulSets, where no PVCs are deleted. This is also the default retention policy. It’s\nappropriate to use when data on StatefulSet volumes may be irreplaceable and should only be\ndeleted manually.</p>\n</li>\n<li>\n<p><strong><code>whenDeleted</code> is <code>Delete</code> and <code>whenScaled</code> is <code>Retain</code>.</strong> In this case, PVCs are deleted only when\nthe entire StatefulSet is deleted. If the StatefulSet is scaled down, PVCs are not touched,\nmeaning they are available to be reattached if a scale-up occurs with any data from the previous\nreplica. This might be used for a temporary StatefulSet, such as in a CI instance or ETL\npipeline, where the data on the StatefulSet is needed only during the lifetime of the\nStatefulSet lifetime, but while the task is running the data is not easily reconstructible. Any\nretained state is needed for any replicas that scale down and then up.</p>\n</li>\n<li>\n<p><strong><code>whenDeleted</code> and <code>whenScaled</code> are both <code>Delete</code>.</strong> PVCs are deleted immediately when their\nreplica is no longer needed. Note this does not include when a Pod is deleted and a new version\nrescheduled, for example when a node is drained and Pods need to migrate elsewhere. The PVC is\ndeleted only when the replica is no longer needed as signified by a scale-down or StatefulSet\ndeletion. This use case is for when data does not need to live beyond the life of its\nreplica. Perhaps the data is easily reconstructable and the cost savings of deleting unused PVCs\nis more important than quick scale-up, or perhaps that when a new replica is created, any data\nfrom a previous replica is not usable and must be reconstructed anyway.</p>\n</li>\n<li>\n<p><strong><code>whenDeleted</code> is <code>Retain</code> and <code>whenScaled</code> is <code>Delete</code>.</strong> This is similar to the previous case,\nwhen there is little benefit to keeping PVCs for fast reuse during scale-up. An example of a\nsituation where you might use this is an Elasticsearch cluster. Typically you would scale that\nworkload up and down to match demand, whilst ensuring a minimum number of replicas (for example:\n3). When scaling down, data is migrated away from removed replicas and there is no benefit to\nretaining those PVCs. However, it can be useful to bring the entire Elasticsearch cluster down\ntemporarily for maintenance. If you need to take the Elasticsearch system offline, you can do\nthis by temporarily deleting the StatefulSet, and then bringing the Elasticsearch cluster back\nby recreating the StatefulSet. The PVCs holding the Elasticsearch data will still exist and the\nnew replicas will automatically use them.</p>\n</li>\n</ul>\n<p>Visit the\n<a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-policies\">documentation</a> to\nsee all the details.</p>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>Enable the feature and try it out! Enable the <code>StatefulSetAutoDeletePVC</code> feature gate on a cluster,\nthen create a StatefulSet using the new policy. Test it out and tell us what you think!</p>\n<p>I'm very curious to see if this owner reference mechanism works well in practice. For example, we\nrealized there is no mechanism in Kubernetes for knowing who set a reference, so it’s possible that\nthe StatefulSet controller may fight with custom controllers that set their own\nreferences. Fortunately, maintaining the existing retention behavior does not involve any new owner\nreferences, so default behavior will be compatible.</p>\n<p>Please tag any issues you report with the label <code>sig/apps</code> and assign them to Matthew Cary\n(<a href=\"https://github.com/mattcary\">@mattcary</a> at GitHub).</p>\n<p>Enjoy!</p>","PublishedAt":"2021-12-16 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/16/kubernetes-1-23-statefulset-pvc-auto-deletion/","SourceName":"Kubernetes"}},{"node":{"ID":1240,"Title":"Blog: Kubernetes 1.23: Prevent PersistentVolume leaks when deleting out of order","Description":"<p><strong>Author:</strong> Deepak Kinni (VMware)</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\">PersistentVolume</a> (or PVs for short) are\nassociated with <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reclaim-policy\">Reclaim Policy</a>.\nThe Reclaim Policy is used to determine the actions that need to be taken by the storage\nbackend on deletion of the PV.\nWhere the reclaim policy is <code>Delete</code>, the expectation is that the storage backend\nreleases the storage resource that was allocated for the PV. In essence, the reclaim\npolicy needs to honored on PV deletion.</p>\n<p>With the recent Kubernetes v1.23 release, an alpha feature lets you configure your\ncluster to behave that way and honor the configured reclaim policy.</p>\n<h2 id=\"how-did-reclaim-work-in-previous-kubernetes-releases\">How did reclaim work in previous Kubernetes releases?</h2>\n<p><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#Introduction\">PersistentVolumeClaim</a> (or PVC for short) is\na request for storage by a user. A PV and PVC are considered <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#Binding\">Bound</a>\nif there is a newly created PV or a matching PV is found. The PVs themselves are\nbacked by a volume allocated by the storage backend.</p>\n<p>Normally, if the volume is to be deleted, then the expectation is to delete the\nPVC for a bound PV-PVC pair. However, there are no restrictions to delete a PV\nprior to deleting a PVC.</p>\n<p>First, I'll demonstrate the behavior for clusters that are running an older version of Kubernetes.</p>\n<h4 id=\"retrieve-an-pvc-that-is-bound-to-a-pv\">Retrieve an PVC that is bound to a PV</h4>\n<p>Retrieve an existing PVC <code>example-vanilla-block-pvc</code></p>\n<pre tabindex=\"0\"><code>kubectl get pvc example-vanilla-block-pvc\n</code></pre><p>The following output shows the PVC and it's <code>Bound</code> PV, the PV is shown under the <code>VOLUME</code> column:</p>\n<pre tabindex=\"0\"><code>NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\nexample-vanilla-block-pvc Bound pvc-6791fdd4-5fad-438e-a7fb-16410363e3da 5Gi RWO example-vanilla-block-sc 19s\n</code></pre><h4 id=\"delete-pv\">Delete PV</h4>\n<p>When I try to delete a bound PV, the cluster blocks and the <code>kubectl</code> tool does\nnot return back control to the shell; for example:</p>\n<pre tabindex=\"0\"><code>kubectl delete pv pvc-6791fdd4-5fad-438e-a7fb-16410363e3da\n</code></pre><pre tabindex=\"0\"><code>persistentvolume &#34;pvc-6791fdd4-5fad-438e-a7fb-16410363e3da&#34; deleted\n^C\n</code></pre><p>Retrieving the PV:</p>\n<pre tabindex=\"0\"><code>kubectl get pv pvc-6791fdd4-5fad-438e-a7fb-16410363e3da\n</code></pre><p>It can be observed that the PV is in <code>Terminating</code> state</p>\n<pre tabindex=\"0\"><code>NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\npvc-6791fdd4-5fad-438e-a7fb-16410363e3da 5Gi RWO Delete Terminating default/example-vanilla-block-pvc example-vanilla-block-sc 2m23s\n</code></pre><h4 id=\"delete-pvc\">Delete PVC</h4>\n<pre tabindex=\"0\"><code>kubectl delete pvc example-vanilla-block-pvc\n</code></pre><p>The following output is seen if the PVC gets successfully deleted:</p>\n<pre tabindex=\"0\"><code>persistentvolumeclaim &#34;example-vanilla-block-pvc&#34; deleted\n</code></pre><p>The PV object from the cluster also gets deleted. When attempting to retrieve the PV\nit will be observed that the PV is no longer found:</p>\n<pre tabindex=\"0\"><code>kubectl get pv pvc-6791fdd4-5fad-438e-a7fb-16410363e3da\n</code></pre><pre tabindex=\"0\"><code>Error from server (NotFound): persistentvolumes &#34;pvc-6791fdd4-5fad-438e-a7fb-16410363e3da&#34; not found\n</code></pre><p>Although the PV is deleted the underlying storage resource is not deleted, and\nneeds to be removed manually.</p>\n<p>To sum it up, the reclaim policy associated with the Persistent Volume is currently\nignored under certain circumstance. For a <code>Bound</code> PV-PVC pair the ordering of PV-PVC\ndeletion determines whether the PV reclaim policy is honored. The reclaim policy\nis honored if the PVC is deleted first, however, if the PV is deleted prior to\ndeleting the PVC then the reclaim policy is not exercised. As a result of this behavior,\nthe associated storage asset in the external infrastructure is not removed.</p>\n<h2 id=\"pv-reclaim-policy-with-kubernetes-v1-23\">PV reclaim policy with Kubernetes v1.23</h2>\n<p>The new behavior ensures that the underlying storage object is deleted from the backend when users attempt to delete a PV manually.</p>\n<h4 id=\"how-to-enable-new-behavior\">How to enable new behavior?</h4>\n<p>To make use of the new behavior, you must have upgraded your cluster to the v1.23 release of Kubernetes.\nYou need to make sure that you are running the CSI <a href=\"https://github.com/kubernetes-csi/external-provisioner\"><code>external-provisioner</code></a> version <code>4.0.0</code>, or later.\nYou must also enable the <code>HonorPVReclaimPolicy</code> <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> for the\n<code>external-provisioner</code> and for the <code>kube-controller-manager</code>.</p>\n<p>If you're not using a CSI driver to integrate with your storage backend, the fix isn't\navailable. The Kubernetes project doesn't have a current plan to fix the bug for in-tree\nstorage drivers: the future of those in-tree drivers is deprecation and migration to CSI.</p>\n<h4 id=\"how-does-it-work\">How does it work?</h4>\n<p>The new behavior is achieved by adding a finalizer <code>external-provisioner.volume.kubernetes.io/finalizer</code> on new and existing PVs, the finalizer is only removed after the storage from backend is deleted.</p>\n<p>An example of a PV with the finalizer, notice the new finalizer in the finalizers list</p>\n<pre tabindex=\"0\"><code>kubectl get pv pvc-a7b7e3ba-f837-45ba-b243-dec7d8aaed53 -o yaml\n</code></pre><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolume<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">annotations</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">pv.kubernetes.io/provisioned-by</span>:<span style=\"color:#bbb\"> </span>csi.vsphere.vmware.com<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">creationTimestamp</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;2021-11-17T19:28:56Z&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">finalizers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- kubernetes.io/pv-protection<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- external-provisioner.volume.kubernetes.io/finalizer<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>pvc-a7b7e3ba-f837-45ba-b243-dec7d8aaed53<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resourceVersion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;194711&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">uid</span>:<span style=\"color:#bbb\"> </span>087f14f2-4157-4e95-8a70-8294b039d30e<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">capacity</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">claimRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-vanilla-block-pvc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>default<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resourceVersion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;194677&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">uid</span>:<span style=\"color:#bbb\"> </span>a7b7e3ba-f837-45ba-b243-dec7d8aaed53<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">csi</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">driver</span>:<span style=\"color:#bbb\"> </span>csi.vsphere.vmware.com<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fsType</span>:<span style=\"color:#bbb\"> </span>ext4<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeAttributes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage.kubernetes.io/csiProvisionerIdentity</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">1637110610497-8081</span>-csi.vsphere.vmware.com<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>vSphere CNS Block Volume<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeHandle</span>:<span style=\"color:#bbb\"> </span>2dacf297-803f-4ccc-afc7-3d3c3f02051e<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">persistentVolumeReclaimPolicy</span>:<span style=\"color:#bbb\"> </span>Delete<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storageClassName</span>:<span style=\"color:#bbb\"> </span>example-vanilla-block-sc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMode</span>:<span style=\"color:#bbb\"> </span>Filesystem<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">status</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">phase</span>:<span style=\"color:#bbb\"> </span>Bound<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>The presence of the finalizer prevents the PV object from being removed from the\ncluster. As stated previously, the finalizer is only removed from the PV object\nafter it is successfully deleted from the storage backend. To learn more about\nfinalizers, please refer to <a href=\"https://kubernetes.io/blog/2021/05/14/using-finalizers-to-control-deletion/\">Using Finalizers to Control Deletion</a>.</p>\n<h4 id=\"what-about-csi-migrated-volumes\">What about CSI migrated volumes?</h4>\n<p>The fix is applicable to CSI migrated volumes as well. However, when the feature\n<code>HonorPVReclaimPolicy</code> is enabled on 1.23, and CSI Migration is disabled, the finalizer\nis removed from the PV object if it exists.</p>\n<h3 id=\"some-caveats\">Some caveats</h3>\n<ol>\n<li>The fix is applicable only to CSI volumes and migrated volumes. In-tree volumes will exhibit older behavior.</li>\n<li>The fix is introduced as an alpha feature in the <a href=\"https://github.com/kubernetes-csi/external-provisioner\">external-provisioner</a> under the feature gate <code>HonorPVReclaimPolicy</code>. The feature is disabled by default, and needs to be enabled explicitly.</li>\n</ol>\n<h3 id=\"references\">References</h3>\n<ul>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/2644-honor-pv-reclaim-policy\">KEP-2644</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/issues/546\">Volume leak issue</a></li>\n</ul>\n<h3 id=\"how-do-i-get-involved\">How do I get involved?</h3>\n<p>The Kubernetes Slack channel <a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/README.md#contact\">SIG Storage communication channels</a> are great mediums to reach out to the SIG Storage and migration working group teams.</p>\n<p>Special thanks to the following people for the insightful reviews, thorough consideration and valuable contribution:</p>\n<ul>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Xing Yang (xing-yang)</li>\n<li>Matthew Wong (wongma7)</li>\n</ul>\n<p>Those interested in getting involved with the design and development of CSI or any part of the Kubernetes Storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group (SIG)</a>. We’re rapidly growing and always welcome new contributors.</p>","PublishedAt":"2021-12-15 18:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/15/kubernetes-1-23-prevent-persistentvolume-leaks-when-deleting-out-of-order/","SourceName":"Kubernetes"}},{"node":{"ID":243,"Title":"Why Company Data Strategies Are Indelibly Linked with DEI","Description":"<p>Data is the missing puzzle piece for organizations to couple DEI initiatives with actionable insights, identify areas where impact will be highest, and build metrics for greater accountability.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/why-company-data-strategies-are-indelibly-linked-with-dei/\">Why Company Data Strategies Are Indelibly Linked with DEI</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-15 14:00:20+00:00","OriginURL":"https://blog.cloudera.com/why-company-data-strategies-are-indelibly-linked-with-dei/","SourceName":"Cloudera"}},{"node":{"ID":1111,"Title":"Accessibility Testing 101","Description":"<p>This post is for Day 15 of Mercari Advent Calendar 2021, brought to you by Sahil Khokhar from the Mercari JP Web team. I would like to take this opportunity to continue my efforts towards helping everyone understand Web Accessibility. After explaining The Importance of Web Accessibility and Web Accessibility through Internationalization and Localization in [&hellip;]</p>\n","PublishedAt":"2021-12-15 09:28:25+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211215-accessibility-testing-101/","SourceName":"Mercari"}},{"node":{"ID":244,"Title":"It’s Time to Listen More to Your Employees!","Description":"<p>Some of the most successful people I know listen more than they talk. We need leaders who focus on building the organizations they run, not their own egos.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/its-time-to-listen-more-to-your-employees/\">It&#8217;s Time to Listen More to Your Employees!</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-14 18:27:59+00:00","OriginURL":"https://blog.cloudera.com/its-time-to-listen-more-to-your-employees/","SourceName":"Cloudera"}},{"node":{"ID":245,"Title":"AI and ML: No Longer the Stuff of Science Fiction","Description":"<p>Global use cases for enterprise-scale machine learning and industrialized AI</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/ai-and-ml-no-longer-the-stuff-of-science-fiction/\">AI and ML: No Longer the Stuff of Science Fiction</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-14 16:58:15+00:00","OriginURL":"https://blog.cloudera.com/ai-and-ml-no-longer-the-stuff-of-science-fiction/","SourceName":"Cloudera"}},{"node":{"ID":1211,"Title":"Go 1.18 Beta 1 is available, with generics","Description":"Go 1.18 Beta 1 is our first preview of Go 1.18. Please try it and let us know if you find problems.","PublishedAt":"2021-12-14 00:00:00+00:00","OriginURL":"https://go.dev/blog/go1.18beta1","SourceName":"The Go Blog"}},{"node":{"ID":246,"Title":"Cloudera Response to CVE-2021-44228","Description":"<p>On December 10th 2021, the Apache Software Foundation released a security advisory for Apache Log4j 2.0-2.14. This vulnerability is critical and is rated 10 out of 10 on the CVSS 3.1 scoring scale.</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/cloudera-response-to-cve-2021-44228/\">Cloudera Response to CVE-2021-44228</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2021-12-13 19:39:17+00:00","OriginURL":"https://blog.cloudera.com/cloudera-response-to-cve-2021-44228/","SourceName":"Cloudera"}},{"node":{"ID":1112,"Title":"Microservice Migration at Mercari: The Ideal and the Real","Description":"<p>Introduction Hello, this is @stanaka . Mercari has launched the “Robust Foundation for Speed” project aimed at enhancing its business platform. The first part of this project is to migrate microservices, so in this entry I will explain our ideals for microservices migration and the realities of our progress. The Ideal Modern Development Team I’ll [&hellip;]</p>\n","PublishedAt":"2021-12-13 17:41:39+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211111-reality-of-microservices-migration/","SourceName":"Mercari"}},{"node":{"ID":1113,"Title":"Why is Mercari Investing in Business Infrastructure Enhancement Now? All About the &#8220;Robust Foundation for Speed&#8221; Project","Description":"<p>Introduction Robust Foundation for Speed (RFfS) is a project that was newly launched at Mercari. It is an effort to solve complex technical problems within the current shared business infrastructure so that Mercari can continue to pursue rapid, strong growth into the future. This effort involves analyzing and improving the existing system, and doing so [&hellip;]</p>\n","PublishedAt":"2021-12-13 16:32:57+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211105-4f441db0bb/","SourceName":"Mercari"}},{"node":{"ID":1114,"Title":"🪙 The Future of NFTs on E-commerce","Description":"<p>Hello! This is Pramendra from the Advanced Technology Team. At the Advanced Technology Team, we research emerging business and technology trends. We’re excited to bring you another trend report based on our findings. Previously, we shared about Instant Delivery: Autonomous Delivery Robots. Do you know NFT market capitalization is growing tenfold in just 2 years. [&hellip;]</p>\n","PublishedAt":"2021-12-13 16:26:47+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211213-b652bc2850/","SourceName":"Mercari"}},{"node":{"ID":1115,"Title":"What Are the Biggest Challenges Facing the Mercari CTO Today? Looking Back on Both the Technology and the Organization","Description":"<p>Introduction Mercari’s engineering organization has transformed dynamically over the years to match the scale of its business operations and the different phases of its services. To remain innovative, we have incorporated state-of-the-art development styles and arranged them in our own, original way to create a system for development, all while constantly embracing and learning from [&hellip;]</p>\n","PublishedAt":"2021-12-13 16:24:49+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211104-8456a371cb/","SourceName":"Mercari"}},{"node":{"ID":466,"Title":"Andrew Chen on network effects and competing for growth in a rocketing market","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/12/Innovators_Chen-19201080_Blog-1024x576.jpg\" class=\"type:primaryImage\" /></figure>\n<p>The last time we sat down to speak with Andrew Chen, we were inside the offices of Uber, just feet away from the growth team he helped assemble at the rideshare giant. Though much has changed in the few years since then, including Chen parting with the company to become a full-time investor and consultant,</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/andrew-chen-on-network-effects-and-competing-for-growth-in-a-rocketing-market/\">Andrew Chen on network effects and competing for growth in a rocketing market</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-12-13 13:01:00+00:00","OriginURL":"https://mixpanel.com/blog/andrew-chen-on-network-effects-and-competing-for-growth-in-a-rocketing-market/","SourceName":"Mixpanel"}},{"node":{"ID":1116,"Title":"JetFire &#8211; Validation Platform for ML models on mobile devices","Description":"<p>This post is for Day 13 of Mercari Advent Calendar 2021, brought to you by @Rakesh_kumar from the Mercari Edge AI team. Machine learning has caught the attention of a lot of people in recent years and most of the companies today claim to be using ML models in their products. Traditionally the ML models [&hellip;]</p>\n","PublishedAt":"2021-12-13 07:00:06+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211209-jetfire-validation-platform-for-ml-models-on-mobile-devices/","SourceName":"Mercari"}},{"node":{"ID":1117,"Title":"Chaos engineering with chaos mesh in payment-service","Description":"<p>This post is for Day 1２ of Merpay Advent Calendar 2021, brought to you by @Po-An from the Merpay Payment Platform team. Chaos engineering and chaos mesh Since NetFlix created the chaos monkey in 2010, chaos engineering has become one tooling that could help the product foresee and check system reliability under extreme circumstances. Teams [&hellip;]</p>\n","PublishedAt":"2021-12-12 13:00:13+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211212-chaos-engineering-in-payment-service/","SourceName":"Mercari"}},{"node":{"ID":1118,"Title":"Bazel Remote Execution for iOS Builds with Apple Silicon","Description":"<p>This article is for Day 12 of Mercari Advent Calendar 2021, brought to you by Thi Doan from the Mercari Tools &amp; Infrastructure team. This article will describe how to configure your Bazel builds for iOS to take advantage of an Apple silicon remote execution build farm. Introduction Bazel is one of the build tools [&hellip;]</p>\n","PublishedAt":"2021-12-12 10:00:52+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211210-bazel-remote-execution-for-ios-builds-with-apple-silicon/","SourceName":"Mercari"}},{"node":{"ID":1119,"Title":"Effective abstraction in a modern React project","Description":"<p>Effective abstraction in a modern React project This post is for Day 11 of Mercari Advent Calendar 2021, brought to you by Gary Forster from the Mercari Web Personalization team. Here at Mercari we use React in a lot of our projects. Its simplicity and unopinionated nature as a UI library, as opposed to a [&hellip;]</p>\n","PublishedAt":"2021-12-11 10:00:17+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211211-effective-abstraction-in-a-modern-react-project/","SourceName":"Mercari"}},{"node":{"ID":1120,"Title":"How is Security Testing Different from Typical Software Testing?","Description":"<p>This post is for Day 10 of Mercari Advent Calendar 2021, brought to you by @gloria from the Mercari Product Security team. &#8212;&#8212;&#8212;&#8212; Hello, this is @gloria from the Product Security Team. Previously, I wrote about DevSecOps as a part of last year’s Advent Calendar event. Recently, I noticed that the topic of transitioning from [&hellip;]</p>\n","PublishedAt":"2021-12-10 10:00:28+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211210-how-is-security-testing-different-from-typical-software-testing/","SourceName":"Mercari"}},{"node":{"ID":1241,"Title":"Blog: Kubernetes 1.23: Kubernetes In-Tree to CSI Volume Migration Status Update","Description":"<p><strong>Author:</strong> Jiawei Wang (Google)</p>\n<p>The Kubernetes in-tree storage plugin to <a href=\"https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/\">Container Storage Interface (CSI)</a> migration infrastructure has already been <a href=\"https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/\">beta</a> since v1.17. CSI migration was introduced as alpha in Kubernetes v1.14.</p>\n<p>Since then, SIG Storage and other Kubernetes special interest groups are working to ensure feature stability and compatibility in preparation for GA.\nThis article is intended to give a status update to the feature as well as changes between Kubernetes 1.17 and 1.23. In addition, I will also cover the future roadmap for the CSI migration feature GA for each storage plugin.</p>\n<h2 id=\"quick-recap-what-is-csi-migration-and-why-migrate\">Quick recap: What is CSI Migration, and why migrate?</h2>\n<p>The Container Storage Interface (CSI) was designed to help Kubernetes replace its existing, in-tree storage driver mechanisms - especially vendor specific plugins.\nKubernetes support for the <a href=\"https://github.com/container-storage-interface/spec/blob/master/spec.md#README\">Container Storage Interface</a> has been\n<a href=\"https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/\">generally available</a> since Kubernetes v1.13.\nSupport for using CSI drivers was introduced to make it easier to add and maintain new integrations between Kubernetes and storage backend technologies. Using CSI drivers allows for for better maintainability (driver authors can define their own release cycle and support lifecycle) and reduce the opportunity for vulnerabilities (with less in-tree code, the risks of a mistake are reduced, and cluster operators can select only the storage drivers that their cluster requires).</p>\n<p>As more CSI Drivers were created and became production ready, SIG Storage group wanted all Kubernetes users to benefit from the CSI model. However, we cannot break API compatibility with the existing storage API types. The solution we came up with was CSI migration: a feature that translates in-tree APIs to equivalent CSI APIs and delegates operations to a replacement CSI driver.</p>\n<p>The CSI migration effort enables the replacement of existing in-tree storage plugins such as <code>kubernetes.io/gce-pd</code> or <code>kubernetes.io/aws-ebs</code> with a corresponding <a href=\"https://kubernetes-csi.github.io/docs/introduction.html\">CSI driver</a> from the storage backend.\nIf CSI Migration is working properly, Kubernetes end users shouldn’t notice a difference. Existing <code>StorageClass</code>, <code>PersistentVolume</code> and <code>PersistentVolumeClaim</code> objects should continue to work.\nWhen a Kubernetes cluster administrator updates a cluster to enable CSI migration, existing workloads that utilize PVCs which are backed by in-tree storage plugins will continue to function as they always have.\nHowever, behind the scenes, Kubernetes hands control of all storage management operations (previously targeting in-tree drivers) to CSI drivers.</p>\n<p>For example, suppose you are a <code>kubernetes.io/gce-pd</code> user, after CSI migration, you can still use <code>kubernetes.io/gce-pd</code> to provision new volumes, mount existing GCE-PD volumes or delete existing volumes. All existing API/Interface will still function correctly. However, the underlying function calls are all going through the <a href=\"https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver\">GCE PD CSI driver</a> instead of the in-tree Kubernetes function.</p>\n<p>This enables a smooth transition for end users. Additionally as storage plugin developers, we can reduce the burden of maintaining the in-tree storage plugins and eventually remove them from the core Kubernetes binary.</p>\n<h2 id=\"what-has-been-changed-and-what-s-new\">What has been changed, and what's new?</h2>\n<p>Building on the work done in Kubernetes v1.17 and earlier, the releases since then have\nmade a series of changes:</p>\n<h3 id=\"new-feature-gates\">New feature gates</h3>\n<p>The Kubernetes v1.21 release deprecated the <code>CSIMigration{provider}Complete</code> feature flags, and stopped honoring them. In their place came new feature flags named <code>InTreePlugin{vendor}Unregister</code>, that replace the old feature flag and retain all the functionality that <code>CSIMigration{provider}Complete</code> provided.</p>\n<p><code>CSIMigration{provider}Complete</code> was introduced before as a supplementary feature gate once CSI migration is enabled on all of the nodes. This flag unregisters the in-tree storage plugin you specify with the <code>{provider}</code> part of the flag name.</p>\n<p>When you enable that feature gate, then instead of using the in-tree driver code, your cluster directly selects and uses the relevant CSI driver. This happens without any check for whether CSI migration is enabled on the node, or whether you have in fact deployed that CSI driver.</p>\n<p>While this feature gate is a great helper, SIG Storage (and, I'm sure, lots of cluster operators) also wanted a feature gate that lets you disable an in-tree storage plugin, even without also enabling CSI migration. For example, you might want to disable the EBS storage plugin on a GCE cluster, because EBS volumes are specific to a different vendor's cloud (AWS).</p>\n<p>To make this possible, Kubernetes v1.21 introduced a new feature flag set: <code>InTreePlugin{vendor}Unregister</code>.</p>\n<p><code>InTreePlugin{vendor}Unregister</code> is a standalone feature gate that can be enabled and disabled independently from CSI Migration. When enabled, the component will not register the specific in-tree storage plugin to the supported list. If the cluster operator only enables this flag, end users will get an error from PVC saying it cannot find the plugin when the plugin is used. The cluster operator may want to enable this regardless of CSI Migration if they do not want to support the legacy in-tree APIs and only support CSI moving forward.</p>\n<h3 id=\"observability\">Observability</h3>\n<p>Kubernetes v1.21 introduced <a href=\"https://github.com/kubernetes/kubernetes/issues/98279\">metrics</a> for tracking CSI migration.\nYou can use these metrics to observe how your cluster is using storage services and whether access to that storage is using the legacy in-tree driver or its CSI-based replacement.</p>\n<table>\n<thead>\n<tr>\n<th>Components</th>\n<th>Metrics</th>\n<th>Notes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Kube-Controller-Manager</td>\n<td>storage_operation_duration_seconds</td>\n<td>A new label <code>migrated</code> is added to the metric to indicate whether this storage operation is a CSI migration operation(string value <code>true</code> for enabled and <code>false</code> for not enabled).</td>\n</tr>\n<tr>\n<td>Kubelet</td>\n<td>csi_operations_seconds</td>\n<td>The new metric exposes labels including <code>driver_name</code>, <code>method_name</code>, <code>grpc_status_code</code> and <code>migrated</code>. The meaning of these labels is identical to <code>csi_sidecar_operations_seconds</code>.</td>\n</tr>\n<tr>\n<td>CSI Sidecars(provisioner, attacher, resizer)</td>\n<td>csi_sidecar_operations_seconds</td>\n<td>A new label <code>migrated</code> is added to the metric to indicate whether this storage operation is a CSI migration operation(string value <code>true</code> for enabled and <code>false</code> for not enabled).</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"bug-fixes-and-feature-improvement\">Bug fixes and feature improvement</h3>\n<p>We have fixed numerous bugs like dangling attachment, garbage collection, incorrect topology label through the help of our beta testers.</p>\n<h3 id=\"cloud-provider-cluster-lifecycle-collaboration\">Cloud Provider &amp;&amp; Cluster Lifecycle Collaboration</h3>\n<p>SIG Storage has been working closely with SIG Cloud Provider and SIG Cluster Lifecycle on the rollout of CSI migration.</p>\n<p>If you are a user of a managed Kubernetes service, check with your provider if anything needs to be done. In many cases, the provider will manage the migration and no additional work is required.</p>\n<p>If you use a distribution of Kubernetes, check its official documentation for information about support for this feature. For the CSI Migration feature graduation to GA, SIG Storage and SIG Cluster Lifecycle are collaborating towards making the migration mechanisms available in tooling (such as kubeadm) as soon as they're available in Kubernetes itself.</p>\n<h2 id=\"timeline-and-status\">What is the timeline / status?</h2>\n<p>The current and targeted releases for each individual driver is shown in the table below:</p>\n<table>\n<thead>\n<tr>\n<th>Driver</th>\n<th>Alpha</th>\n<th>Beta (in-tree deprecated)</th>\n<th>Beta (on-by-default)</th>\n<th>GA</th>\n<th>Target &quot;in-tree plugin&quot; removal</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>AWS EBS</td>\n<td>1.14</td>\n<td>1.17</td>\n<td>1.23</td>\n<td>1.24 (Target)</td>\n<td>1.26 (Target)</td>\n</tr>\n<tr>\n<td>GCE PD</td>\n<td>1.14</td>\n<td>1.17</td>\n<td>1.23</td>\n<td>1.24 (Target)</td>\n<td>1.26 (Target)</td>\n</tr>\n<tr>\n<td>OpenStack Cinder</td>\n<td>1.14</td>\n<td>1.18</td>\n<td>1.21</td>\n<td>1.24 (Target)</td>\n<td>1.26 (Target)</td>\n</tr>\n<tr>\n<td>Azure Disk</td>\n<td>1.15</td>\n<td>1.19</td>\n<td>1.23</td>\n<td>1.24 (Target)</td>\n<td>1.26 (Target)</td>\n</tr>\n<tr>\n<td>Azure File</td>\n<td>1.15</td>\n<td>1.21</td>\n<td>1.24 (Target)</td>\n<td>1.25 (Target)</td>\n<td>1.27 (Target)</td>\n</tr>\n<tr>\n<td>vSphere</td>\n<td>1.18</td>\n<td>1.19</td>\n<td>1.24 (Target)</td>\n<td>1.25 (Target)</td>\n<td>1.27 (Target)</td>\n</tr>\n<tr>\n<td>Ceph RBD</td>\n<td>1.23</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>Portworx</td>\n<td>1.23</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>The following storage drivers will not have CSI migration support. The ScaleIO driver was already removed; the others are deprecated and will be removed from core Kubernetes.</p>\n<table>\n<thead>\n<tr>\n<th>Driver</th>\n<th>Deprecated</th>\n<th>Code Removal</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ScaleIO</td>\n<td>1.16</td>\n<td>1.22</td>\n</tr>\n<tr>\n<td>Flocker</td>\n<td>1.22</td>\n<td>1.25 (Target)</td>\n</tr>\n<tr>\n<td>Quobyte</td>\n<td>1.22</td>\n<td>1.25 (Target)</td>\n</tr>\n<tr>\n<td>StorageOS</td>\n<td>1.22</td>\n<td>1.25 (Target)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"what-s-next\">What's next?</h2>\n<p>With more CSI drivers graduating to GA, we hope to soon mark the overall CSI Migration feature as GA. We are expecting cloud provider in-tree storage plugins code removal to happen by Kubernetes v1.26 and v1.27.</p>\n<h2 id=\"what-should-i-do-as-a-user\">What should I do as a user?</h2>\n<p>Note that all new features for the Kubernetes storage system (such as volume snapshotting) will only be added to the CSI interface. Therefore, if you are starting up a new cluster, creating stateful applications for the first time, or require these new features we recommend using CSI drivers natively (instead of the in-tree volume plugin API). Follow the <a href=\"https://kubernetes-csi.github.io/docs/drivers.html\">updated user guides for CSI drivers</a> and use the new CSI APIs.</p>\n<p>However, if you choose to roll a cluster forward or continue using specifications with the legacy volume APIs, CSI Migration will ensure we continue to support those deployments with the new CSI drivers. However, if you want to leverage new features like snapshot, it will require a manual migration to re-import an existing intree PV as a CSI PV.</p>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>The Kubernetes Slack channel <a href=\"https://kubernetes.slack.com/messages/csi-migration\">#csi-migration</a> along with any of the standard <a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/README.md#contact\">SIG Storage communication channels</a> are great mediums to reach out to the SIG Storage and migration working group teams.</p>\n<p>This project, like all of Kubernetes, is the result of hard work by many contributors from diverse backgrounds working together. We offer a huge thank you to the contributors who stepped up these last quarters to help move the project forward:</p>\n<ul>\n<li>Michelle Au (msau42)</li>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Hemant Kumar (gnufied)</li>\n</ul>\n<p>Special thanks to the following people for the insightful reviews, thorough consideration and valuable contribution to the CSI migration feature:</p>\n<ul>\n<li>Andy Zhang (andyzhangz)</li>\n<li>Divyen Patel (divyenpatel)</li>\n<li>Deep Debroy (ddebroy)</li>\n<li>Humble Devassy Chirammal (humblec)</li>\n<li>Jing Xu (jingxu97)</li>\n<li>Jordan Liggitt (liggitt)</li>\n<li>Matthew Cary (mattcary)</li>\n<li>Matthew Wong (wongma7)</li>\n<li>Neha Arora (nearora-msft)</li>\n<li>Oksana Naumov (trierra)</li>\n<li>Saad Ali (saad-ali)</li>\n<li>Tim Bannister (sftim)</li>\n<li>Xing Yang (xing-yang)</li>\n</ul>\n<p>Those interested in getting involved with the design and development of CSI or any part of the Kubernetes Storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group (SIG)</a>. We’re rapidly growing and always welcome new contributors.</p>","PublishedAt":"2021-12-10 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/12/10/storage-in-tree-to-csi-migration-status-update/","SourceName":"Kubernetes"}}]}},"pageContext":{"limit":30,"skip":4020,"numPages":158,"currentPage":135}},"staticQueryHashes":["3649515864"]}