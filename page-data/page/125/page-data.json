{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/125","result":{"data":{"allPost":{"edges":[{"node":{"ID":174,"Title":"Urban Institute Enacts Real Social and Policy Change Using Data","Description":"<p>The Education Data Portal</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/urban-institute-enacts-real-social-and-policy-change-using-data/\">Urban Institute Enacts Real Social and Policy Change Using Data</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-06-01 17:50:54+00:00","OriginURL":"https://blog.cloudera.com/urban-institute-enacts-real-social-and-policy-change-using-data/","SourceName":"Cloudera"}},{"node":{"ID":1048,"Title":"How we introduced mob programming to handle tasks as a team","Description":"<p>* This article is a translation of the Japanese article written on December 4, 2021. Introduction Hello! This is @ysk24ok, from the Merpay ML Platform Team. This article is for day 4 of Merpay Advent Calendar . In this article, I talk about how we implemented mob programming to handle tasks as a team. What [&hellip;]</p>\n","PublishedAt":"2022-06-01 10:00:56+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211130-52e6d96087/","SourceName":"Mercari"}},{"node":{"ID":1202,"Title":"Share your feedback about developing with Go","Description":"Help shape the future of Go by sharing your thoughts via the Go Developer Survey","PublishedAt":"2022-06-01 00:00:00+00:00","OriginURL":"https://go.dev/blog/survey2022-q2","SourceName":"The Go Blog"}},{"node":{"ID":1213,"Title":"Blog: Annual Report Summary 2021","Description":"<p><strong>Author:</strong> Paris Pittman (Steering Committee)</p>\n<p>Last year, we published our first <a href=\"https://kubernetes.io/blog/2021/06/28/announcing-kubernetes-community-group-annual-reports/\">Annual Report Summary</a> for 2020 and it's already time for our second edition!</p>\n<p><a href=\"https://www.cncf.io/reports/kubernetes-annual-report-2021/\">2021 Annual Report Summary</a></p>\n<p>This summary reflects the work that has been done in 2021 and the initiatives on deck for the rest of 2022. Please forward to organizations and indidviduals participating in upstream activities, planning cloud native strategies, and/or those looking to help out. To find a specific community group's complete report, go to the <a href=\"https://github.com/kubernetes/community\">kubernetes/community repo</a> under the groups folder. Example: <a href=\"https://github.com/kubernetes/community/blob/master/sig-api-machinery/annual-report-2021.md\">sig-api-machinery/annual-report-2021.md</a></p>\n<p>You’ll see that this report summary is a growth area in itself. It takes us roughly 6 months to prepare and execute, which isn’t helpful or valuable to anyone as a fast moving project with short and long term needs. How can we make this better? Provide your feedback here: <a href=\"https://github.com/kubernetes/steering/issues/242\">https://github.com/kubernetes/steering/issues/242</a></p>\n<p>Reference:\n<a href=\"https://github.com/kubernetes/community/blob/master/committee-steering/governance/annual-reports.md\">Annual Report Documentation</a></p>","PublishedAt":"2022-06-01 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/06/01/annual-report-summary-2021/","SourceName":"Kubernetes"}},{"node":{"ID":1049,"Title":"Android automated testing to support one-week releases","Description":"<p>* This article is a translation of the Japanese article written on December 10, 2021. This article is for day 10 of Merpay Advent Calendar 2021. Today&#8217;s article on Android automated testing to support a one-week release is brought to you by @amane, @kenken, @anzai, and @hiroP from the Merpay Android Team. Background leading up [&hellip;]</p>\n","PublishedAt":"2022-05-31 10:00:23+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211210-merpay-android-test-automation/","SourceName":"Mercari"}},{"node":{"ID":446,"Title":"Taylor Murphy on the funny thing about data","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2022/05/Innovators_Taylor-19201080_Blog-1-1024x576.jpeg\" class=\"type:primaryImage\" /></figure>\n<p>It takes a great degree of knowledge and talent to be a good data practitioner. But it’s an entirely different set of skills that are required to write a data meme that makes people laugh. Taylor Murphy does both quite well. Though his day jobs as Head of Product &#38; Data at Meltano (spun out</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/taylor-murphy-meltano-data-jokes-open-source/\">Taylor Murphy on the funny thing about data</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-05-31 06:04:50+00:00","OriginURL":"https://mixpanel.com/blog/taylor-murphy-meltano-data-jokes-open-source/","SourceName":"Mixpanel"}},{"node":{"ID":732,"Title":"Affirm","Description":"Businesses in the US can now offer Affirm to let customers pay for a large purchase over time. Eligible businesses can start accepting Affirm in minutes.","PublishedAt":"2022-05-31 00:00:00+00:00","OriginURL":"https://stripe.com/payments/affirm","SourceName":"Stripe"}},{"node":{"ID":1050,"Title":"Suspecting the Unsuspected. Extracting and Analyzing Log Anomalies","Description":"<p>This article is part of the Security Tech Blog Series: Spring Cleaning for Security, brought to you by Simon from the Security Engineering team. We hope this article can provide you with some useful pointers to kickstart your journey in log anomaly detection, and get familiar with some of the techniques used at Mercari to [&hellip;]</p>\n","PublishedAt":"2022-05-27 16:53:07+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220527-suspecting-the-unsuspected-extracting-and-analyzing-log-anomalies/","SourceName":"Mercari"}},{"node":{"ID":1051,"Title":"Practical alerts based on user impact","Description":"<p>* This article is a translation of the Japanese article written on December 16, 2021. This article is for day 16 of Merpay Advent Calendar 2021. Hello everyone. This is foostan from the Merpay SRE Team. Most of the time you’ll see me talking about keyboards, but my actual job is on the SRE Team [&hellip;]</p>\n","PublishedAt":"2022-05-27 11:00:00+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20211215-practical_alerting_methods_based_on_customer_impact/","SourceName":"Mercari"}},{"node":{"ID":1214,"Title":"Blog: Kubernetes 1.24: Maximum Unavailable Replicas for StatefulSet","Description":"<p><strong>Author:</strong> Mayank Kumar (Salesforce)</p>\n<p>Kubernetes <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\">StatefulSets</a>, since their introduction in\n1.5 and becoming stable in 1.9, have been widely used to run stateful applications. They provide stable pod identity, persistent\nper pod storage and ordered graceful deployment, scaling and rolling updates. You can think of StatefulSet as the atomic building\nblock for running complex stateful applications. As the use of Kubernetes has grown, so has the number of scenarios requiring\nStatefulSets. Many of these scenarios, require faster rolling updates than the currently supported one-pod-at-a-time updates, in the\ncase where you're using the <code>OrderedReady</code> Pod management policy for a StatefulSet.</p>\n<p>Here are some examples:</p>\n<ul>\n<li>\n<p>I am using a StatefulSet to orchestrate a multi-instance, cache based application where the size of the cache is large. The cache\nstarts cold and requires some siginificant amount of time before the container can start. There could be more initial startup tasks\nthat are required. A RollingUpdate on this StatefulSet would take a lot of time before the application is fully updated. If the\nStatefulSet supported updating more than one pod at a time, it would result in a much faster update.</p>\n</li>\n<li>\n<p>My stateful application is composed of leaders and followers or one writer and multiple readers. I have multiple readers or\nfollowers and my application can tolerate multiple pods going down at the same time. I want to update this application more than\none pod at a time so that i get the new updates rolled out quickly, especially if the number of instances of my application are\nlarge. Note that my application still requires unique identity per pod.</p>\n</li>\n</ul>\n<p>In order to support such scenarios, Kubernetes 1.24 includes a new alpha feature to help. Before you can use the new feature you must\nenable the <code>MaxUnavailableStatefulSet</code> feature flag. Once you enable that, you can specify a new field called <code>maxUnavailable</code>, part\nof the <code>spec</code> for a StatefulSet. For example:</p>\n<pre tabindex=\"0\"><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\nname: web\nnamespace: default\nspec:\npodManagementPolicy: OrderedReady # you must set OrderedReady\nreplicas: 5\nselector:\nmatchLabels:\napp: nginx\ntemplate:\nmetadata:\nlabels:\napp: nginx\nspec:\ncontainers:\n- image: k8s.gcr.io/nginx-slim:0.8\nimagePullPolicy: IfNotPresent\nname: nginx\nupdateStrategy:\nrollingUpdate:\nmaxUnavailable: 2 # this is the new alpha field, whose default value is 1\npartition: 0\ntype: RollingUpdate\n</code></pre><p>If you enable the new feature and you don't specify a value for <code>maxUnavailable</code> in a StatefulSet, Kubernetes applies a default\n<code>maxUnavailable: 1</code>. This matches the behavior you would see if you don't enable the new feature.</p>\n<p>I'll run through a scenario based on that example manifest to demonstrate how this feature works. I will deploy a StatefulSet that\nhas 5 replicas, with <code>maxUnavailable</code> set to 2 and <code>partition</code> set to 0.</p>\n<p>I can trigger a rolling update by changing the image to <code>k8s.gcr.io/nginx-slim:0.9</code>. Once I initiate the rolling update, I can\nwatch the pods update 2 at a time as the current value of maxUnavailable is 2. The below output shows a span of time and is not\ncomplete. The maxUnavailable can be an absolute number (for example, 2) or a percentage of desired Pods (for example, 10%). The\nabsolute number is calculated from percentage by rounding down.</p>\n<pre tabindex=\"0\"><code>kubectl get pods --watch\n</code></pre><pre tabindex=\"0\"><code>NAME READY STATUS RESTARTS AGE\nweb-0 1/1 Running 0 85s\nweb-1 1/1 Running 0 2m6s\nweb-2 1/1 Running 0 106s\nweb-3 1/1 Running 0 2m47s\nweb-4 1/1 Running 0 2m27s\nweb-4 1/1 Terminating 0 5m43s ----&gt; start terminating 4\nweb-3 1/1 Terminating 0 6m3s ----&gt; start terminating 3\nweb-3 0/1 Terminating 0 6m7s\nweb-3 0/1 Pending 0 0s\nweb-3 0/1 Pending 0 0s\nweb-4 0/1 Terminating 0 5m48s\nweb-4 0/1 Terminating 0 5m48s\nweb-3 0/1 ContainerCreating 0 2s\nweb-3 1/1 Running 0 2s\nweb-4 0/1 Pending 0 0s\nweb-4 0/1 Pending 0 0s\nweb-4 0/1 ContainerCreating 0 0s\nweb-4 1/1 Running 0 1s\nweb-2 1/1 Terminating 0 5m46s ----&gt; start terminating 2 (only after both 4 and 3 are running)\nweb-1 1/1 Terminating 0 6m6s ----&gt; start terminating 1\nweb-2 0/1 Terminating 0 5m47s\nweb-1 0/1 Terminating 0 6m7s\nweb-1 0/1 Pending 0 0s\nweb-1 0/1 Pending 0 0s\nweb-1 0/1 ContainerCreating 0 1s\nweb-1 1/1 Running 0 2s\nweb-2 0/1 Pending 0 0s\nweb-2 0/1 Pending 0 0s\nweb-2 0/1 ContainerCreating 0 0s\nweb-2 1/1 Running 0 1s\nweb-0 1/1 Terminating 0 6m6s ----&gt; start terminating 0 (only after 2 and 1 are running)\nweb-0 0/1 Terminating 0 6m7s\nweb-0 0/1 Pending 0 0s\nweb-0 0/1 Pending 0 0s\nweb-0 0/1 ContainerCreating 0 0s\nweb-0 1/1 Running 0 1s\n</code></pre><p>Note that as soon as the rolling update starts, both 4 and 3 (the two highest ordinal pods) start terminating at the same time. Pods\nwith ordinal 4 and 3 may become ready at their own pace. As soon as both pods 4 and 3 are ready, pods 2 and 1 start terminating at the\nsame time. When pods 2 and 1 are both running and ready, pod 0 starts terminating.</p>\n<p>In Kubernetes, updates to StatefulSets follow a strict ordering when updating Pods. In this example, the update starts at replica 4, then\nreplica 3, then replica 2, and so on, one pod at a time. When going one pod at a time, its not possible for 3 to be running and ready\nbefore 4. When <code>maxUnavailable</code> is more than 1 (in the example scenario I set <code>maxUnavailable</code> to 2), it is possible that replica 3 becomes\nready and running before replica 4 is ready—and that is ok. If you're a developer and you set <code>maxUnavailable</code> to more than 1, you should\nknow that this outcome is possible and you must ensure that your application is able to handle such ordering issues that occur\nif any. When you set <code>maxUnavailable</code> greater than 1, the ordering is guaranteed in between each batch of pods being updated. That guarantee\nmeans that pods in update batch 2 (replicas 2 and 1) cannot start updating until the pods from batch 0 (replicas 4 and 3) are ready.</p>\n<p>Although Kubernetes refers to these as <em>replicas</em>, your stateful application may have a different view and each pod of the StatefulSet may\nbe holding completely different data than other pods. The important thing here is that updates to StatefulSets happen in batches, and you can\nnow have a batch size larger than 1 (as an alpha feature).</p>\n<p>Also note, that the above behavior is with <code>podManagementPolicy: OrderedReady</code>. If you defined a StatefulSet as <code>podManagementPolicy: Parallel</code>,\nnot only <code>maxUnavailable</code> number of replicas are terminated at the same time; <code>maxUnavailable</code> number of replicas start in <code>ContainerCreating</code>\nphase at the same time as well. This is called bursting.</p>\n<p>So, now you may have a lot of questions about:-</p>\n<ul>\n<li>What is the behavior when you set <code>podManagementPolicy: Parallel</code>?</li>\n<li>What is the behavior when <code>partition</code> to a value other than <code>0</code>?</li>\n</ul>\n<p>It might be better to try and see it for yourself. This is an alpha feature, and the Kubernetes contributors are looking for feedback on this feature. Did\nthis help you achieve your stateful scenarios Did you find a bug or do you think the behavior as implemented is not intuitive or can\nbreak applications or catch them by surprise? Please <a href=\"https://github.com/kubernetes/kubernetes/issues\">open an issue</a> to let us know.</p>\n<h2 id=\"next-steps\">Further reading and next steps</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#maximum-unavailable-pods\">Maximum unavailable Pods</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-apps/961-maxunavailable-for-statefulset\">KEP for MaxUnavailable for StatefulSet</a></li>\n<li><a href=\"https://github.com/kubernetes/kubernetes/pull/82162/files\">Implementation</a></li>\n<li><a href=\"https://github.com/kubernetes/enhancements/issues/961\">Enhancement Tracking Issue</a></li>\n</ul>","PublishedAt":"2022-05-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/27/maxunavailable-for-statefulset/","SourceName":"Kubernetes"}},{"node":{"ID":747,"Title":"USL – Uber’s Unified Signup and Login Stack","Description":"<h1><b>Introduction</b></h1>\n<p><span style=\"font-weight: 400;\">Uber has operations in over 10,000 cities worldwide and its services include ridesharing, food delivery, package delivery, couriers, freight transportation, electric bicycle and motorized scooter rental, and ferry transport.</span></p>\n<p><span style=\"font-weight: 400;\">Every year we have millions of users going through signup </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/usl-ubers-unified-signup-and-login-stack/\">USL &#8211; Uber’s Unified Signup and Login Stack</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2022-05-26 16:30:36+00:00","OriginURL":"https://eng.uber.com/usl-ubers-unified-signup-and-login-stack/","SourceName":"Uber"}},{"node":{"ID":1262,"Title":"Miro Developer Platform: A look under the hood","Description":"","PublishedAt":"2022-05-26 08:57:16+00:00","OriginURL":"https://medium.com/miro-engineering/miro-developer-platform-a-look-under-the-hood-2725cd654082?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":1215,"Title":"Blog: Contextual Logging in Kubernetes 1.24","Description":"<p><strong>Authors:</strong> Patrick Ohly (Intel)</p>\n<p>The <a href=\"https://github.com/kubernetes/community/blob/master/wg-structured-logging/README.md\">Structured Logging Working\nGroup</a>\nhas added new capabilities to the logging infrastructure in Kubernetes\n1.24. This blog post explains how developers can take advantage of those to\nmake log output more useful and how they can get involved with improving Kubernetes.</p>\n<h2 id=\"structured-logging\">Structured logging</h2>\n<p>The goal of <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/1602-structured-logging/README.md\">structured\nlogging</a>\nis to replace C-style formatting and the resulting opaque log strings with log\nentries that have a well-defined syntax for storing message and parameters\nseparately, for example as a JSON struct.</p>\n<p>When using the traditional klog text output format for structured log calls,\nstrings were originally printed with <code>\\n</code> escape sequences, except when\nembedded inside a struct. For structs, log entries could still span multiple\nlines, with no clean way to split the log stream into individual entries:</p>\n<pre tabindex=\"0\"><code>I1112 14:06:35.783529 328441 structured_logging.go:51] &#34;using InfoS&#34; longData={Name:long Data:Multiple\nlines\nwith quite a bit\nof text. internal:0}\nI1112 14:06:35.783549 328441 structured_logging.go:52] &#34;using InfoS with\\nthe message across multiple lines&#34; int=1 stringData=&#34;long: Multiple\\nlines\\nwith quite a bit\\nof text.&#34; str=&#34;another value&#34;\n</code></pre><p>Now, the <code>&lt;</code> and <code>&gt;</code> markers along with indentation are used to ensure that splitting at a\nklog header at the start of a line is reliable and the resulting output is human-readable:</p>\n<pre tabindex=\"0\"><code>I1126 10:31:50.378204 121736 structured_logging.go:59] &#34;using InfoS&#34; longData=&lt;\n{Name:long Data:Multiple\nlines\nwith quite a bit\nof text. internal:0}\n&gt;\nI1126 10:31:50.378228 121736 structured_logging.go:60] &#34;using InfoS with\\nthe message across multiple lines&#34; int=1 stringData=&lt;\nlong: Multiple\nlines\nwith quite a bit\nof text.\n&gt; str=&#34;another value&#34;\n</code></pre><p>Note that the log message itself is printed with quoting. It is meant to be a\nfixed string that identifies a log entry, so newlines should be avoided there.</p>\n<p>Before Kubernetes 1.24, some log calls in kube-scheduler still used <code>klog.Info</code>\nfor multi-line strings to avoid the unreadable output. Now all log calls have\nbeen updated to support structured logging.</p>\n<h2 id=\"contextual-logging\">Contextual logging</h2>\n<p><a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-instrumentation/3077-contextual-logging/README.md\">Contextual logging</a>\nis based on the <a href=\"https://github.com/go-logr/logr#a-minimal-logging-api-for-go\">go-logr API</a>. The key\nidea is that libraries are passed a logger instance by their caller and use\nthat for logging instead of accessing a global logger. The binary decides about\nthe logging implementation, not the libraries. The go-logr API is designed\naround structured logging and supports attaching additional information to a\nlogger.</p>\n<p>This enables additional use cases:</p>\n<ul>\n<li>\n<p>The caller can attach additional information to a logger:</p>\n<ul>\n<li><a href=\"https://pkg.go.dev/github.com/go-logr/logr#Logger.WithName\"><code>WithName</code></a> adds a prefix</li>\n<li><a href=\"https://pkg.go.dev/github.com/go-logr/logr#Logger.WithValues\"><code>WithValues</code></a> adds key/value pairs</li>\n</ul>\n<p>When passing this extended logger into a function and a function uses it\ninstead of the global logger, the additional information is\nthen included in all log entries, without having to modify the code that\ngenerates the log entries. This is useful in highly parallel applications\nwhere it can become hard to identify all log entries for a certain operation\nbecause the output from different operations gets interleaved.</p>\n</li>\n<li>\n<p>When running unit tests, log output can be associated with the current test.\nThen when a test fails, only the log output of the failed test gets shown\nby <code>go test</code>. That output can also be more verbose by default because it\nwill not get shown for successful tests. Tests can be run in parallel\nwithout interleaving their output.</p>\n</li>\n</ul>\n<p>One of the design decisions for contextual logging was to allow attaching a\nlogger as value to a <code>context.Context</code>. Since the logger encapsulates all\naspects of the intended logging for the call, it is <em>part</em> of the context and\nnot just <em>using</em> it. A practical advantage is that many APIs already have a\n<code>ctx</code> parameter or adding one has additional advantages, like being able to get\nrid of <code>context.TODO()</code> calls inside the functions.</p>\n<p>Another decision was to not break compatibility with klog v2:</p>\n<ul>\n<li>\n<p>Libraries that use the traditional klog logging calls in a binary that has\nset up contextual logging will work and log through the logging backend\nchosen by the binary. However, such log output will not include the\nadditional information and will not work well in unit tests, so libraries\nshould be modified to support contextual logging. The <a href=\"https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/migration-to-structured-logging.md\">migration guide</a>\nfor structured logging has been extended to also cover contextual logging.</p>\n</li>\n<li>\n<p>When a library supports contextual logging and retrieves a logger from its\ncontext, it will still work in a binary that does not initialize contextual\nlogging because it will get a logger that logs through klog.</p>\n</li>\n</ul>\n<p>In Kubernetes 1.24, contextual logging is a new alpha feature with\n<code>ContextualLogging</code> as feature gate. When disabled (the default), the new klog\nAPI calls for contextual logging (see below) become no-ops to avoid performance\nor functional regressions.</p>\n<p>No Kubernetes component has been converted yet. An <a href=\"https://github.com/kubernetes/kubernetes/blob/v1.24.0-beta.0/staging/src/k8s.io/component-base/logs/example/cmd/logger.go\">example program</a>\nin the Kubernetes repository demonstrates how to enable contextual logging in a\nbinary and how the output depends on the binary's parameters:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-console\" data-lang=\"console\"><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">$</span> <span style=\"color:#a2f\">cd</span> <span style=\"color:#b8860b\">$GOPATH</span>/src/k8s.io/kubernetes/staging/src/k8s.io/component-base/logs/example/cmd/\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">$</span> go run . --help\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">...\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\"> --feature-gates mapStringBool A set of key=value pairs that describe feature gates for alpha/experimental features. Options are:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\"> AllAlpha=true|false (ALPHA - default=false)\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\"> AllBeta=true|false (BETA - default=false)\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\"> ContextualLogging=true|false (ALPHA - default=false)\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\"></span><span style=\"color:#000080;font-weight:bold\">$</span> go run . --feature-gates <span style=\"color:#b8860b\">ContextualLogging</span><span style=\"color:#666\">=</span><span style=\"color:#a2f\">true</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">...\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">I0404 18:00:02.916429 451895 logger.go:94] &#34;example/myname: runtime&#34; foo=&#34;bar&#34; duration=&#34;1m0s&#34;\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#888\">I0404 18:00:02.916447 451895 logger.go:95] &#34;example: another runtime&#34; foo=&#34;bar&#34; duration=&#34;1m0s&#34;\n</span></span></span></code></pre></div><p>The <code>example</code> prefix and <code>foo=&quot;bar&quot;</code> were added by the caller of the function\nwhich logs the <code>runtime</code> message and <code>duration=&quot;1m0s&quot;</code> value.</p>\n<p>The sample code for klog includes an\n<a href=\"https://github.com/kubernetes/klog/blob/v2.60.1/ktesting/example/example_test.go\">example</a>\nfor a unit test with per-test output.</p>\n<h2 id=\"klog-enhancements\">klog enhancements</h2>\n<h3 id=\"contextual-logging-api\">Contextual logging API</h3>\n<p>The following calls manage the lookup of a logger:</p>\n<dl>\n<dt><a href=\"https://pkg.go.dev/k8s.io/klog/v2#FromContext\"><code>FromContext</code></a></dt>\n<dd>from a <code>context</code> parameter, with fallback to the global logger</dd>\n<dt><a href=\"https://pkg.go.dev/k8s.io/klog/v2#Background\"><code>Background</code></a></dt>\n<dd>the global fallback, with no intention to support contextual logging</dd>\n<dt><a href=\"https://pkg.go.dev/k8s.io/klog/v2#TODO\"><code>TODO</code></a></dt>\n<dd>the global fallback, but only as a temporary solution until the function gets extended to accept\na logger through its parameters</dd>\n<dt><a href=\"https://pkg.go.dev/k8s.io/klog/v2#SetLoggerWithOptions\"><code>SetLoggerWithOptions</code></a></dt>\n<dd>changes the fallback logger; when called with <a href=\"https://pkg.go.dev/k8s.io/klog/v2#ContextualLogger\"><code>ContextualLogger(true)</code></a>,\nthe logger is ready to be called directly, in which case logging will be done\nwithout going through klog</dd>\n</dl>\n<p>To support the feature gate mechanism in Kubernetes, klog has wrapper calls for\nthe corresponding go-logr calls and a global boolean controlling their behavior:</p>\n<ul>\n<li><a href=\"https://pkg.go.dev/k8s.io/klog/v2#LoggerWithName\"><code>LoggerWithName</code></a></li>\n<li><a href=\"https://pkg.go.dev/k8s.io/klog/v2#LoggerWithValues\"><code>LoggerWithValues</code></a></li>\n<li><a href=\"https://pkg.go.dev/k8s.io/klog/v2#NewContext\"><code>NewContext</code></a></li>\n<li><a href=\"https://pkg.go.dev/k8s.io/klog/v2#EnableContextualLogging\"><code>EnableContextualLogging</code></a></li>\n</ul>\n<p>Usage of those functions in Kubernetes code is enforced with a linter\ncheck. The klog default for contextual logging is to enable the functionality\nbecause it is considered stable in klog. It is only in Kubernetes binaries\nwhere that default gets overridden and (in some binaries) controlled via the\n<code>--feature-gate</code> parameter.</p>\n<h3 id=\"ktesting-logger\">ktesting logger</h3>\n<p>The new <a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/ktesting\">ktesting</a> package\nimplements logging through <code>testing.T</code> using klog's text output format. It has\na <a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/ktesting#NewTestContext\">single API call</a> for\ninstrumenting a test case and <a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/ktesting/init\">support for command line flags</a>.</p>\n<h3 id=\"klogr\">klogr</h3>\n<p><a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/klogr\"><code>klog/klogr</code></a> continues to be\nsupported and it's default behavior is unchanged: it formats structured log\nentries using its own, custom format and prints the result via klog.</p>\n<p>However, this usage is discouraged because that format is neither\nmachine-readable (in contrast to real JSON output as produced by zapr, the\ngo-logr implementation used by Kubernetes) nor human-friendly (in contrast to\nthe klog text format).</p>\n<p>Instead, a klogr instance should be created with\n<a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/klogr#WithFormat\"><code>WithFormat(FormatKlog)</code></a>\nwhich chooses the klog text format. A simpler construction method with the same\nresult is the new\n<a href=\"https://pkg.go.dev/k8s.io/klog/v2#NewKlogr\"><code>klog.NewKlogr</code></a>. That is the\nlogger that klog returns as fallback when nothing else is configured.</p>\n<h3 id=\"reusable-output-test\">Reusable output test</h3>\n<p>A lot of go-logr implementations have very similar unit tests where they check\nthe result of certain log calls. If a developer didn't know about certain\ncaveats like for example a <code>String</code> function that panics when called, then it\nis likely that both the handling of such caveats and the unit test are missing.</p>\n<p><a href=\"https://pkg.go.dev/k8s.io/klog/v2@v2.60.1/test\"><code>klog.test</code></a> is a reusable set\nof test cases that can be applied to a go-logr implementation.</p>\n<h3 id=\"output-flushing\">Output flushing</h3>\n<p>klog used to start a goroutine unconditionally during <code>init</code> which flushed\nbuffered data at a hard-coded interval. Now that goroutine is only started on\ndemand (i.e. when writing to files with buffering) and can be controlled with\n<a href=\"https://pkg.go.dev/k8s.io/klog/v2#StopFlushDaemon\"><code>StopFlushDaemon</code></a> and\n<a href=\"https://pkg.go.dev/k8s.io/klog/v2#StartFlushDaemon\"><code>StartFlushDaemon</code></a>.</p>\n<p>When a go-logr implementation buffers data, flushing that data can be\nintegrated into <a href=\"https://pkg.go.dev/k8s.io/klog/v2#Flush\"><code>klog.Flush</code></a> by\nregistering the logger with the\n<a href=\"https://pkg.go.dev/k8s.io/klog/v2#FlushLogger\"><code>FlushLogger</code></a> option.</p>\n<h3 id=\"various-other-changes\">Various other changes</h3>\n<p>For a description of all other enhancements see in the <a href=\"https://github.com/kubernetes/klog/releases\">release notes</a>.</p>\n<h2 id=\"logcheck\">logcheck</h2>\n<p>Originally designed as a linter for structured log calls, the\n<a href=\"https://github.com/kubernetes/klog/tree/788efcdee1e9be0bfbe5b076343d447314f2377e/hack/tools/logcheck\"><code>logcheck</code></a>\ntool has been enhanced to support also contextual logging and traditional klog\nlog calls. These enhanced checks already found bugs in Kubernetes, like calling\n<code>klog.Info</code> instead of <code>klog.Infof</code> with a format string and parameters.</p>\n<p>It can be included as a plugin in a <code>golangci-lint</code> invocation, which is how\n<a href=\"https://github.com/kubernetes/kubernetes/commit/17e3c555c5115f8c9176bae10ba45baa04d23a7b\">Kubernetes uses it now</a>,\nor get invoked stand-alone.</p>\n<p>We are in the process of <a href=\"https://github.com/kubernetes/klog/issues/312\">moving the tool</a> into a new repository because it isn't\nreally related to klog and its releases should be tracked and tagged properly.</p>\n<h2 id=\"next-steps\">Next steps</h2>\n<p>The <a href=\"https://github.com/kubernetes/community/tree/master/wg-structured-logging\">Structured Logging WG</a>\nis always looking for new contributors. The migration\naway from C-style logging is now going to target structured, contextual logging\nin one step to reduce the overall code churn and number of PRs. Changing log\ncalls is good first contribution to Kubernetes and an opportunity to get to\nknow code in various different areas.</p>","PublishedAt":"2022-05-25 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/25/contextual-logging/","SourceName":"Kubernetes"}},{"node":{"ID":175,"Title":"Tailored Support Designed for You","Description":"<p>Cloudera Technology Spotlight</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/tailored-support-designed-for-you/\">Tailored Support Designed for You</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-24 19:38:38+00:00","OriginURL":"https://blog.cloudera.com/tailored-support-designed-for-you/","SourceName":"Cloudera"}},{"node":{"ID":7,"Title":"Faster JavaScript Builds with Metro","Description":"","PublishedAt":"2022-05-24 17:39:39+00:00","OriginURL":"https://medium.com/airbnb-engineering/faster-javascript-builds-with-metro-cfc46d617a1f?source=rss----53c7c27702d5---4","SourceName":"Airbnb"}},{"node":{"ID":539,"Title":"Meet the Tinder Machine Learning Team: Carlos Gutierrez","Description":"","PublishedAt":"2022-05-24 17:08:01+00:00","OriginURL":"https://medium.com/tinder/meet-the-tinder-machine-learning-team-carlos-gutierrez-742b8e2d749f?source=rss----906928af8599---4","SourceName":"Tinder"}},{"node":{"ID":176,"Title":"Who is Ready for Climate Disclosures?","Description":"<p>Observations from an ESG Europe event</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/who-is-ready-for-climate-disclosures/\">Who is Ready for Climate Disclosures?</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-24 12:59:47+00:00","OriginURL":"https://blog.cloudera.com/who-is-ready-for-climate-disclosures/","SourceName":"Cloudera"}},{"node":{"ID":733,"Title":"Sessions 2022 and product highlights from the year","Description":"Today, we kicked off our annual user conference—Stripe Sessions. You can now watch the keynote and breakout talks on demand.","PublishedAt":"2022-05-24 00:00:00+00:00","OriginURL":"https://stripe.com/blog/stripe-sessions-2022","SourceName":"Stripe"}},{"node":{"ID":734,"Title":"Introducing Stripe Apps","Description":"Stripe Apps lets you embed custom user experiences directly in the Stripe Dashboard and orchestrate the Stripe API. Create an app to streamline operations just for your team or for the more than one million businesses using Stripe.","PublishedAt":"2022-05-24 00:00:00+00:00","OriginURL":"https://stripe.com/apps","SourceName":"Stripe"}},{"node":{"ID":8,"Title":"Dynamic Kubernetes Cluster Scaling at Airbnb","Description":"","PublishedAt":"2022-05-23 17:35:24+00:00","OriginURL":"https://medium.com/airbnb-engineering/dynamic-kubernetes-cluster-scaling-at-airbnb-d79ae3afa132?source=rss----53c7c27702d5---4","SourceName":"Airbnb"}},{"node":{"ID":1216,"Title":"Blog: Kubernetes 1.24: Avoid Collisions Assigning IP Addresses to Services","Description":"<p><strong>Author:</strong> Antonio Ojea (Red Hat)</p>\n<p>In Kubernetes, <a href=\"https://kubernetes.io/docs/concepts/services-networking/service/\">Services</a> are an abstract way to expose\nan application running on a set of Pods. Services\ncan have a cluster-scoped virtual IP address (using a Service of <code>type: ClusterIP</code>).\nClients can connect using that virtual IP address, and Kubernetes then load-balances traffic to that\nService across the different backing Pods.</p>\n<h2 id=\"how-service-clusterips-are-allocated\">How Service ClusterIPs are allocated?</h2>\n<p>A Service <code>ClusterIP</code> can be assigned:</p>\n<dl>\n<dt><em>dynamically</em></dt>\n<dd>the cluster's control plane automatically picks a free IP address from within the configured IP range for <code>type: ClusterIP</code> Services.</dd>\n<dt><em>statically</em></dt>\n<dd>you specify an IP address of your choice, from within the configured IP range for Services.</dd>\n</dl>\n<p>Across your whole cluster, every Service <code>ClusterIP</code> must be unique.\nTrying to create a Service with a specific <code>ClusterIP</code> that has already\nbeen allocated will return an error.</p>\n<h2 id=\"why-do-you-need-to-reserve-service-cluster-ips\">Why do you need to reserve Service Cluster IPs?</h2>\n<p>Sometimes you may want to have Services running in well-known IP addresses, so other components and\nusers in the cluster can use them.</p>\n<p>The best example is the DNS Service for the cluster. Some Kubernetes installers assign the 10th address from\nthe Service IP range to the DNS service. Assuming you configured your cluster with Service IP range\n10.96.0.0/16 and you want your DNS Service IP to be 10.96.0.10, you'd have to create a Service like\nthis:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Service<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">labels</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">k8s-app</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kubernetes.io/cluster-service</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;true&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kubernetes.io/name</span>:<span style=\"color:#bbb\"> </span>CoreDNS<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">namespace</span>:<span style=\"color:#bbb\"> </span>kube-system<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">clusterIP</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">10.96.0.10</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">ports</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>UDP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>dns-tcp<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">port</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">protocol</span>:<span style=\"color:#bbb\"> </span>TCP<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">targetPort</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">53</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">selector</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">k8s-app</span>:<span style=\"color:#bbb\"> </span>kube-dns<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>ClusterIP<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>but as I explained before, the IP address 10.96.0.10 has not been reserved; if other Services are created\nbefore or in parallel with dynamic allocation, there is a chance they can allocate this IP, hence,\nyou will not be able to create the DNS Service because it will fail with a conflict error.</p>\n<h2 id=\"avoid-ClusterIP-conflict\">How can you avoid Service ClusterIP conflicts?</h2>\n<p>In Kubernetes 1.24, you can enable a new feature gate <code>ServiceIPStaticSubrange</code>.\nTurning this on allows you to use a different IP\nallocation strategy for Services, reducing the risk of collision.</p>\n<p>The <code>ClusterIP</code> range will be divided, based on the formula <code>min(max(16, cidrSize / 16), 256)</code>,\ndescribed as <em>never less than 16 or more than 256 with a graduated step between them</em>.</p>\n<p>Dynamic IP assignment will use the upper band by default, once this has been exhausted it will\nuse the lower range. This will allow users to use static allocations on the lower band with a low\nrisk of collision.</p>\n<p>Examples:</p>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-24\">Service IP CIDR block: 10.96.0.0/24</h4>\n<p>Range Size: 2<sup>8</sup> - 2 = 254<br>\nBand Offset: <code>min(max(16, 256/16), 256)</code> = <code>min(16, 256)</code> = 16<br>\nStatic band start: 10.96.0.1<br>\nStatic band end: 10.96.0.16<br>\nRange end: 10.96.0.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/24\n\"Static\" : 16\n\"Dynamic\" : 238\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-20\">Service IP CIDR block: 10.96.0.0/20</h4>\n<p>Range Size: 2<sup>12</sup> - 2 = 4094<br>\nBand Offset: <code>min(max(16, 4096/16), 256)</code> = <code>min(256, 256)</code> = 256<br>\nStatic band start: 10.96.0.1<br>\nStatic band end: 10.96.1.0<br>\nRange end: 10.96.15.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/20\n\"Static\" : 256\n\"Dynamic\" : 3838\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h4 id=\"service-ip-cidr-block-10-96-0-0-16\">Service IP CIDR block: 10.96.0.0/16</h4>\n<p>Range Size: 2<sup>16</sup> - 2 = 65534<br>\nBand Offset: <code>min(max(16, 65536/16), 256)</code> = <code>min(4096, 256)</code> = 256<br>\nStatic band start: 10.96.0.1<br>\nStatic band ends: 10.96.1.0<br>\nRange end: 10.96.255.254</p>\n<figure>\n<div class=\"mermaid\">\npie showData\ntitle 10.96.0.0/16\n\"Static\" : 256\n\"Dynamic\" : 65278\n</div>\n</figure>\n<noscript>\n<div class=\"alert alert-secondary callout\" role=\"alert\">\n<em class=\"javascript-required\">JavaScript must be <a href=\"https://www.enable-javascript.com/\">enabled</a> to view this content</em>\n</div>\n</noscript>\n<h2 id=\"get-involved-with-sig-network\">Get involved with SIG Network</h2>\n<p>The current SIG-Network <a href=\"https://github.com/orgs/kubernetes/projects/10\">KEPs</a> and <a href=\"https://github.com/kubernetes/kubernetes/issues?q=is%3Aopen+is%3Aissue+label%3Asig%2Fnetwork\">issues</a> on GitHub illustrate the SIG’s areas of emphasis.</p>\n<p><a href=\"https://github.com/kubernetes/community/tree/master/sig-network\">SIG Network meetings</a> are a friendly, welcoming venue for you to connect with the community and share your ideas.\nLooking forward to hearing from you!</p>","PublishedAt":"2022-05-23 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/23/service-ip-dynamic-and-static-allocation/","SourceName":"Kubernetes"}},{"node":{"ID":516,"Title":"A Survey of Causal Inference Applications at Netflix","Description":"","PublishedAt":"2022-05-21 15:02:49+00:00","OriginURL":"https://netflixtechblog.com/a-survey-of-causal-inference-applications-at-netflix-b62d25175e6f?source=rss----2615bd06b42e---4","SourceName":"Netflix"}},{"node":{"ID":524,"Title":"Modernizing Nextdoor Search Stack — Part 2","Description":"","PublishedAt":"2022-05-20 20:36:28+00:00","OriginURL":"https://engblog.nextdoor.com/modernizing-nextdoor-search-stack-part-2-82192221ad3b?source=rss----5e54f11cdfdf---4","SourceName":"Nextdoor"}},{"node":{"ID":735,"Title":"Migrating millions of lines of code to TypeScript","Description":"On Sunday, March 6, we migrated Stripe’s largest JavaScript codebase from Flow to TypeScript. In a single pull request, we converted more than 3.7 million lines of code. The next day, hundreds of engineers came in to start writing TypeScript for their projects.","PublishedAt":"2022-05-20 00:00:00+00:00","OriginURL":"https://stripe.com/blog/migrating-to-typescript","SourceName":"Stripe"}},{"node":{"ID":1217,"Title":"Blog: Kubernetes 1.24: Introducing Non-Graceful Node Shutdown Alpha","Description":"<p><strong>Authors</strong> Xing Yang and Yassine Tijani (VMware)</p>\n<p>Kubernetes v1.24 introduces alpha support for <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/2268-non-graceful-shutdown\">Non-Graceful Node Shutdown</a>. This feature allows stateful workloads to failover to a different node after the original node is shutdown or in a non-recoverable state such as hardware failure or broken OS.</p>\n<h2 id=\"how-is-this-different-from-graceful-node-shutdown\">How is this different from Graceful Node Shutdown</h2>\n<p>You might have heard about the <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#graceful-node-shutdown\">Graceful Node Shutdown</a> capability of Kubernetes,\nand are wondering how the Non-Graceful Node Shutdown feature is different from that. Graceful Node Shutdown\nallows Kubernetes to detect when a node is shutting down cleanly, and handles that situation appropriately.\nA Node Shutdown can be &quot;graceful&quot; only if the node shutdown action can be detected by the kubelet ahead\nof the actual shutdown. However, there are cases where a node shutdown action may not be detected by\nthe kubelet. This could happen either because the shutdown command does not trigger the systemd inhibitor\nlocks mechanism that kubelet relies upon, or because of a configuration error\n(the <code>ShutdownGracePeriod</code> and <code>ShutdownGracePeriodCriticalPods</code> are not configured properly).</p>\n<p>Graceful node shutdown relies on Linux-specific support. The kubelet does not watch for upcoming\nshutdowns on Windows nodes (this may change in a future Kubernetes release).</p>\n<p>When a node is shutdown but without the kubelet detecting it, pods on that node\nalso shut down ungracefully. For stateless apps, that's often not a problem (a ReplicaSet adds a new pod once\nthe cluster detects that the affected node or pod has failed). For stateful apps, the story is more complicated.\nIf you use a StatefulSet and have a pod from that StatefulSet on a node that fails uncleanly, that affected pod\nwill be marked as terminating; the StatefulSet cannot create a replacement pod because the pod\nstill exists in the cluster.\nAs a result, the application running on the StatefulSet may be degraded or even offline. If the original, shut\ndown node comes up again, the kubelet on that original node reports in, deletes the existing pods, and\nthe control plane makes a replacement pod for that StatefulSet on a different running node.\nIf the original node has failed and does not come up, those stateful pods would be stuck in a\nterminating status on that failed node indefinitely.</p>\n<pre tabindex=\"0\"><code>$ kubectl get pod -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nweb-0 1/1 Running 0 100m 10.244.2.4 k8s-node-876-1639279816 &lt;none&gt; &lt;none&gt;\nweb-1 1/1 Terminating 0 100m 10.244.1.3 k8s-node-433-1639279804 &lt;none&gt; &lt;none&gt;\n</code></pre><h2 id=\"try-out-the-new-non-graceful-shutdown-handling\">Try out the new non-graceful shutdown handling</h2>\n<p>To use the non-graceful node shutdown handling, you must enable the <code>NodeOutOfServiceVolumeDetach</code>\n<a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature gate</a> for the <code>kube-controller-manager</code>\ncomponent.</p>\n<p>In the case of a node shutdown, you can manually taint that node as out of service. You should make certain that\nthe node is truly shutdown (not in the middle of restarting) before you add that taint. You could add that\ntaint following a shutdown that the kubelet did not detect and handle in advance; another case where you\ncan use that taint is when the node is in a non-recoverable state due to a hardware failure or a broken OS.\nThe values you set for that taint can be <code>node.kubernetes.io/out-of-service=nodeshutdown: &quot;NoExecute&quot;</code>\nor <code>node.kubernetes.io/out-of-service=nodeshutdown:&quot; NoSchedule&quot;</code>.\nProvided you have enabled the feature gate mentioned earlier, setting the out-of-service taint on a Node\nmeans that pods on the node will be deleted unless if there are matching tolerations on the pods.\nPersistent volumes attached to the shutdown node will be detached, and for StatefulSets, replacement pods will\nbe created successfully on a different running node.</p>\n<pre tabindex=\"0\"><code>$ kubectl taint nodes &lt;node-name&gt; node.kubernetes.io/out-of-service=nodeshutdown:NoExecute\n$ kubectl get pod -o wide\nNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\nweb-0 1/1 Running 0 150m 10.244.2.4 k8s-node-876-1639279816 &lt;none&gt; &lt;none&gt;\nweb-1 1/1 Running 0 10m 10.244.1.7 k8s-node-433-1639279804 &lt;none&gt; &lt;none&gt;\n</code></pre><p>Note: Before applying the out-of-service taint, you <strong>must</strong> verify that a node is already in shutdown or power off state (not in the middle of restarting), either because the user intentionally shut it down or the node is down due to hardware failures, OS issues, etc.</p>\n<p>Once all the workload pods that are linked to the out-of-service node are moved to a new running node, and the shutdown node has been recovered, you should remove\nthat taint on the affected node after the node is recovered.\nIf you know that the node will not return to service, you could instead delete the node from the cluster.</p>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>Depending on feedback and adoption, the Kubernetes team plans to push the Non-Graceful Node Shutdown implementation to Beta in either 1.25 or 1.26.</p>\n<p>This feature requires a user to manually add a taint to the node to trigger workloads failover and remove the taint after the node is recovered. In the future, we plan to find ways to automatically detect and fence nodes that are shutdown/failed and automatically failover workloads to another node.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Check out the <a href=\"https://kubernetes.io/docs/concepts/architecture/nodes/#non-graceful-node-shutdown\">documentation</a>\nfor non-graceful node shutdown.</p>\n<h2 id=\"how-to-get-involved\">How to get involved?</h2>\n<p>This feature has a long story. Yassine Tijani (<a href=\"https://github.com/yastij\">yastij</a>) started the KEP more than two years ago. Xing Yang (<a href=\"https://github.com/xing-yang\">xing-yang</a>) continued to drive the effort. There were many discussions among SIG Storage, SIG Node, and API reviewers to nail down the design details. Ashutosh Kumar (<a href=\"https://github.com/sonasingh46\">sonasingh46</a>) did most of the implementation and brought it to Alpha in Kubernetes 1.24.</p>\n<p>We want to thank the following people for their insightful reviews: Tim Hockin (<a href=\"https://github.com/thockin\">thockin</a>) for his guidance on the design, Jing Xu (<a href=\"https://github.com/jingxu97\">jingxu97</a>), Hemant Kumar (<a href=\"https://github.com/gnufied\">gnufied</a>), and Michelle Au (<a href=\"https://github.com/msau42\">msau42</a>) for reviews from SIG Storage side, and Mrunal Patel (<a href=\"https://github.com/mrunalp\">mrunalp</a>), David Porter (<a href=\"https://github.com/bobbypage\">bobbypage</a>), Derek Carr (<a href=\"https://github.com/derekwaynecarr\">derekwaynecarr</a>), and Danielle Endocrimes (<a href=\"https://github.com/endocrimes\">endocrimes</a>) for reviews from SIG Node side.</p>\n<p>There are many people who have helped review the design and implementation along the way. We want to thank everyone who has contributed to this effort including the about 30 people who have reviewed the <a href=\"https://github.com/kubernetes/enhancements/pull/1116\">KEP</a> and implementation over the last couple of years.</p>\n<p>This feature is a collaboration between SIG Storage and SIG Node. For those interested in getting involved with the design and development of any part of the Kubernetes Storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG). For those interested in getting involved with the design and development of the components that support the controlled interactions between pods and host resources, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">Kubernetes Node SIG</a>.</p>","PublishedAt":"2022-05-20 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2022/05/20/kubernetes-1-24-non-graceful-node-shutdown-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":447,"Title":"Mobile app event tracking: Telling the story of how your app works (or doesn’t work)","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2022/05/MXP-Blog-MobileAppEventTracking-1920x1080-1-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Event tracking is how you know what’s happening in your mobile apps. It’s the primary technique used to capture usage information by product analytics platforms like Mixpanel. It’s, therefore, essential for you, as a product manager, designer, or any kind of product stakeholder, to have a good understanding of how event tracking works so you</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/what-is-mobile-app-event-tracking/\">Mobile app event tracking: Telling the story of how your app works (or doesn&#8217;t work)</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2022-05-19 19:22:14+00:00","OriginURL":"https://mixpanel.com/blog/what-is-mobile-app-event-tracking/","SourceName":"Mixpanel"}},{"node":{"ID":177,"Title":"#ClouderaLife Spotlight: Margot Tien, Software Engineer","Description":"<p>A career in transition, a community in need, navigating uncharted territory to solve for both</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.cloudera.com/clouderalife-spotlight-margot-tien-software-engineer/\">#ClouderaLife Spotlight: Margot Tien, Software Engineer</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.cloudera.com\">Cloudera Blog</a>.</p>\n","PublishedAt":"2022-05-19 18:38:10+00:00","OriginURL":"https://blog.cloudera.com/clouderalife-spotlight-margot-tien-software-engineer/","SourceName":"Cloudera"}},{"node":{"ID":402,"Title":"Refactoring and Optimizing a High Traffic API at PayPal","Description":"","PublishedAt":"2022-05-19 15:44:52+00:00","OriginURL":"https://medium.com/paypal-tech/refactoring-and-optimizing-a-high-traffic-api-at-paypal-eb11c373d795?source=rss----6423323524ba---4","SourceName":"Paypal"}},{"node":{"ID":1052,"Title":"Terraform CI code execution restrictions","Description":"<p>This article is part of the Security Tech Blog Series: Spring Cleaning for Security series, brought to you by Maximilian Frank (@max-frank) from the Security Engineering team. Background At Mercari, we utilize many microservices developed across multiple different teams. Each team has ownership over not only their code, but also the infrastructure necessary to run [&hellip;]</p>\n","PublishedAt":"2022-05-19 13:28:08+00:00","OriginURL":"https://engineering.mercari.com/en/blog/entry/20220519-terraform-ci-code-execution-restrictions/","SourceName":"Mercari"}},{"node":{"ID":393,"Title":"Tooling to Find More Items, More Quickly","Description":"","PublishedAt":"2022-05-18 16:03:32+00:00","OriginURL":"https://tech.instacart.com/tooling-to-find-more-items-more-quickly-26ff6196e821?source=rss----587883b5d2ee---4","SourceName":"Instacart"}}]}},"pageContext":{"limit":30,"skip":3720,"numPages":158,"currentPage":125}},"staticQueryHashes":["3649515864"]}