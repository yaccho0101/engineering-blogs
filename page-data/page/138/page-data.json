{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/page/138","result":{"data":{"allPost":{"edges":[{"node":{"ID":62,"Title":"Elastic on Elastic: Configuring the Security app to use Cross Cluster Search","Description":"<p>The Elastic Infosec Detections and Analytics team is responsible for building, tuning, and maintaining the security detections used to protect all Elastic systems. Within Elastic we call ourselves Customer Zero and <a href=\"https://www.elastic.co/blog/elastic-on-elastic-how-infosec-deploys-infrastructure-and-stays-up-to-date-with-eck\">we strive to always use the newest versions</a> of our products.&nbsp;\n</p>\n<p>In the previous blog posts we gave an overview of our architecture and what data we send to our clusters. In this blog post we will provide instructions on how we use Cross Cluster Search (CCS) with the Security and Machine Learning (ML) applications\n</p>\n<h2>Configuring CCS<br></h2>\n<p>Getting the Security app to work with CCS only requires a few minor changes. The first step is to configure the Security app so that it knows to look for the CCS index patterns instead of local index patterns. To do this open the Kibana ‘Advanced Settings’ within the Stack Management menu, then located within the Security Solution section update the Elasticsearch indices. These should be set to match the CCS index patterns such as *:auditbeat-*, *:filebeat-*, *:logs-*, and any other index patterns you want to add to your Security app.&nbsp;\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/kxD1eOYM7-2VRGKIc0PAkZgUV3cvNg6bSSgcYv-i5HQox3VLEgQXNDSxbS9sgqNfDT_AhbvWuZcEfQA_OJxi68lEsQZIJY7w15EwoM4e2uFdnyAoBnGS3O3-cudSiz1pU4H-CPvy=s0\" width=\"602\" height=\"249\">\n</p>\n<p>Now when you return to the Security app you should see the Overview, Hosts, and Network pages displaying events from all of your remote clusters.\n</p>\n<h2>Configuring Built In Detection Rules to use CCS</h2>\n<p>Creating brand new custom Detection rules does not require any additional steps, the CCS index patterns will be available to select when you create a new detection rule. If you want to use the 500+ built in Detection rules with CCS it requires a little extra work. To do this you will need to import, duplicate, and bulk edit all of the rules to change the index patterns to use Cross Cluster Search.&nbsp;\n</p>\n<p>The first step is to load all of the pre-built Elastic rules into your Security App. Within the detections tab of the security app navigate to the ‘Manage Detections’ page and click the ‘Load Elastic prebuilt rules’ button.\n</p>\n<h2 style=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\"><img src=\"https://lh5.googleusercontent.com/UolDnHQhugxnjt3-eXvkWouN6ttWFaJsA0G_PYBCAqcL5qXKHu8-sEjvXWtR4LysIiuiAwoGqwdJzWkXzhyaKNhNfLo77bqS9J3TpjmoDkJO5dKYTjKD3io9KZ0jt4Sa5vmowWOl=s0\" width=\"266\" height=\"65\"></h2>\n<p>The Prebuilt rules can not be directly modified but they can be duplicated and then the duplicates can be modified. To do this you will need to select all of the rules and use the ‘Bulk Actions’ menu to duplicate them all. Before starting this process I recommend changing the ‘refresh settings’ to disable automatically refreshing the table. If you don’t then the table may refresh automatically while you are trying to duplicate the rules causing you to deselect some rules.\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/b6A0AsuACM2hHZ1nDmCklF09TdWKmfoQoUPC-35sKP7mDNN2I3Gnl4O-n8R5nQNL2ldEeLSNuyLpyV6GZFpXDW9P3S5vc3n79sxV9Lsu1cuNRsJPViO_mcHy4rz_W2cY9sZP2v31=s0\" width=\"216\" height=\"77\">\n</p>\n<p>To Select all rules on clusters older than 7.14 you will need to change the ‘Rows per page’ to the maximum amount. <br>\n</p>\n<h2 style=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\" rel=\"line-height:1.38;background-color:#ffffff;margin-top:0pt;margin-bottom:0pt;padding:18pt 0pt 6pt 0pt;\"><img src=\"https://lh3.googleusercontent.com/THYRjUpwmz2qiAWpp780ZtW_SrQ_3rO3bnPlj67rC4uhbGCzDzzUNJ9aewX29WsZUqa5LTihcGefyLbus8L47PuXWHoezF9Ctqg7yZBcQToWSq6SP4CpLc3bGTZa20jvp2LsdLnw=s0\" width=\"192\" height=\"464\"></h2>\n<p>When all of the rules are displayed select all rules and then in the bulk actions menu select ‘Duplicate Selected’. Duplicating all of the rules may take a couple minutes.\n</p>\n<p rel=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\"><img src=\"https://lh5.googleusercontent.com/E1ZILEFSNwUHOWUaRBlvRGBVe1WCCcfhIoU7szJgWDp0DnIy5w1-u00JL9xJPq25H6cP8ISFftr9rh_-AtdC09zrNVK46ThtvGygYrJUVhHMMUXKAaxjOJ_jeilOZnMPiL4rOgGT=s0\" width=\"348\" height=\"406\">\n</p>\n<p>When this is complete you will have two copies of every rule. Using the filter on the right side of the rule table select only the ‘Custom rules’ that you just created<br><br>\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/_P7bkklIKPRBtuwuQzFwvDEZ-zE6bNH5rxCQEsIcDWA-nDyj9sqiRYXie_ThCvsHsk8PBHFe1xvLK7afHpGnqEkfLWh-YCYZhZbQ9C585TL8OsoJzcfp6Cct4-8FY35-50TjllbJ=s0\" width=\"297\" height=\"57\">\n</p>\n<p>With only the Custom Rules displayed ‘select all’ again and select ‘Export Selected’ from the ‘bulk actions’ menu to download all of the rules as an ndjson file.&nbsp;\n</p>\n<p>Within this ndjson file you will need to find and replace all instances of the normal index patterns with the CCS index pattern. For example, to use the remote auditbeat index pattern you will need to find \"auditbeat-*\" and replace it with \"*:auditbeat-*\".&nbsp; Repeat this for the other index patterns until all of the index patterns have been changed to the new CCS pattern.<br><br>\n</p>\n<p><img src=\"https://lh5.googleusercontent.com/SjH1dydxRimjXQP5NGTeRdaQnrCWgZUCcO-g4O5qZCUhKLcKKzbv_LqIgtv55gU2TbjnJg13wta5hM26e7UTI4FoJZOI3XCtiXgfqIcN49tTPFvnpRmrHQPkq3jOrIDZFamCOAw4=s0\" width=\"375\" height=\"76\">\n</p>\n<p>I also recommend replacing the word ‘[Duplicate]’ that was appended to every rule name with the current stack version. This will help you manage your rules over time and track when each rule was installed or last updated.\n</p>\n<p>After all of the changes have been saved to the custom rules ndjson file you can import the modified rules over the existing rules. Click the ‘Import rule’ button to open the rule import interface\n</p>\n<p><img src=\"https://lh6.googleusercontent.com/LlSpXbKOK9bvQRIJcp27-vmCAm2NcJJoQFZwY8JiuQ3KqMQghZt6D2ldD10dfExemIhIsMUDtlkEN-X8cWWh94PmxIN6CnjYiDWSWe7ercmrZT6sTjuTw1OwOdokPiEAlvLjWWVK=s0\" width=\"592\" height=\"166\">\n</p>\n<p>Drag and drop the modified rule file to the pop up window and select the button to ‘Automatically overwrite saved objects with the same rule ID’. If you forget to do this it will create new rules instead of updating the existing rules and you will probably want to clean up all of the unnecessary rules.\n</p>\n<p><img src=\"https://lh4.googleusercontent.com/EIcsjUGxFJPwMCo_GYTsIl9N-yAmUGysZyP0NSW7VBc644oDRArFLtyjsuXmiM4IOPy7EDBLc08IPRaJsy9K7St3fzdZE6Ak_hklXDzTQX7oPleLyWlg2E3P_cjv3iF9A5cEl9Ak=s0\" width=\"602\" height=\"405\">\n</p>\n<p>After the rules have all been re-imported you can activate all of the rules that are applicable to your environment.<br><br>\n</p>\n<h2>Note on Elastic Query Language (EQL)</h2>\n<p><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/master/eql.html\">EQL</a> support for CCS is available as of Elastic release 7.14, but it requires that all of your remote clusters have also been upgraded to 7.14 or newer. Many of the built in Elastic detection rules use EQL so if you are using CCS with clusters older than 7.14 you will need to disable those rules.<br><br>\n</p>\n<h2>Machine Learning with CCS</h2>\n<p>To use the Machine Learning with CCS you will need to update each of the datafeeds to use the CCS index patterns. When creating your own custom Machine Learning jobs this is easy to do, you simply select the CCS index pattern when creating the new job. To use the built in Security Machine Learning jobs requires modifying the datafeeds of each job to use the CCS index patterns. Because you cannot change a datafeed’s index pattern via the UI, doing this requires access to the Kibana Devtools or API access. My method for doing this is to load the built-in Machine Learning jobs, stop all of the jobs, and then use the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-apis.html\">Machine Learning API</a> to <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-get-datafeed.html\">Get the datafeed</a>, make the change to the datafeed’s Index pattern, and then <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/ml-update-datafeed.html\">update the datafeed</a> with the changes. After this is complete all of the ML jobs and datafeeds can be restarted. If you used the built in Security ML jobs you can now enable the built in Detection rules that use Machine Learning.<br>\n</p>\n<h2>Conclusion</h2>\n<p>In this post we showed you how to configure your Security Application and Machine Learning jobs to work with Cross Cluster Search. Keep an eye out for future blog posts from the Elastic Infosec team on how we use Elastic to protect Elastic.\n</p>","PublishedAt":"2021-09-28 15:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-on-elastic-configuring-the-security-app-to-use-cross-cluster-search","SourceName":"Elastic"}},{"node":{"ID":147,"Title":"Why we built a custom Rust library for Capture","Description":"","PublishedAt":"2021-09-28 13:00:00+00:00","OriginURL":"https://dropbox.tech/application/why-we-built-a-custom-rust-library-for-capture","SourceName":"Dropbox"}},{"node":{"ID":63,"Title":"Ingest data directly from Google Pub/Sub into Elastic using Google Dataflow","Description":"<p>Today we’re excited to announce the latest development in our ongoing partnership with Google Cloud. Now developers, site reliability engineers (SREs), and security analysts can ingest data from Google Pub/Sub to the Elastic Stack with just a few clicks in the Google Cloud Console. By leveraging Google Dataflow templates, Elastic makes it easy to stream events and logs from Google Cloud services like Google Cloud Audit, VPC Flow, or firewall into the Elastic Stack. This allows customers to simplify their data pipeline architecture, eliminate operational overhead, and reduce the time required for troubleshooting. </p><p>Many developers, SREs, and security analysts who use Google Cloud to develop applications and set up their infrastructure also use the Elastic Stack to troubleshoot, monitor, and identify security anomalies. Google and Elastic have worked together to provide an easy-to-use, frictionless way to ingest logs and events from applications and infrastructure in Google Cloud services to Elastic. And all of this is possible with just a few clicks in the Google Cloud Console, without ever installing any data shippers.&nbsp; &nbsp; </p><p>In this blog post, we’ll cover how to get started with agentless data ingestion from Google Pub/Sub to the Elastic Stack using Google Dataflow. </p><h2>Skip the overhead</h2><p>Pub/Sub is a popular serverless asynchronous messaging service used to stream data from Google Operations (formerly Stackdriver), applications built using Google Cloud services, or other use cases involving streaming data integration pipelines. Ingesting Google Cloud Audit, VPC Flow, or firewall logs to third-party analytics solutions like the Elastic Stack requires these logs to be shipped to Google Operations first, then Pub/Sub.&nbsp; Once the logs are in Pub/Sub, a Google Cloud user must decide on the ingestion method to ship messages stored in Google Pub/Sub to third-party analytics solutions. </p><p>A popular option for joint Google and Elastic users is to install Filebeat, Elastic Agent, or Fluentd on a Google Compute Engine VM (virtual machine), then use one of these data shippers to send data from Pub/Sub to the Elastic Stack. Provisioning a VM and installing data shippers requires process and management overhead. The ability to skip this step and ingest data directly from Pub/Sub to Elastic is valuable to many users — especially when&nbsp; it can be done with a few clicks in the Google Cloud Console. Now this is possible through a dropdown menu in Google Dataflow. </p><h2>Streamline data ingest</h2><p>Google Dataflow is a serverless asynchronous messaging service based on Apache Beam. Dataflow can be used instead of Filebeat to ship logs directly from the Google Cloud Console. The Google and Elastic teams worked together to develop an out-of-the-box Dataflow template that pushes logs and events from Pub/Sub to Elastic. This template replaces lightweight processing such as data format transformation previously completed by Filebeat in a serverless manner — with no other changes for users who previously used the Elasticsearch ingest pipeline.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </p><p>Here is a summary of data ingestion flow. The integration works for all users, regardless of whether they are using the Elastic Stack on Elastic Cloud, Elastic Cloud in the Google Cloud Marketplace, or a self-managed environment. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt4a0252dfb0591d2f/6143c63764c8007a9bdea6f5/blog-gcp-integration-pubsub-1.png\" data-sys-asset-uid=\"blt4a0252dfb0591d2f\" alt=\"blog-gcp-integration-pubsub-1.png\"/></p><h2>Get started</h2><p>In this section, we’ll go into a step-by-step tutorial on how to get started with the Dataflow template for analyzing <a href=\"https://cloud.google.com/logging/docs/audit\" target=\"_self\">GCP Audit Logs</a> in the Elastic Stack. </p><p>Audit logs contain information that help you answer the question of \"where, how and when\" of operational changes that happen in your Google Cloud account. With our Pub/Sub template, you can stream audit logs from GCP to Elasticsearch and gather insights within seconds.&nbsp; </p><p>We’ll start with installing the Elastic GCP integration straight from the Kibana web UI, which contains prebuilt dashboards, ingest node configurations, and other assets that help you get the most of the audit logs you ingest.&nbsp; </p><p>Before configuring the Dataflow template, you will have to create a <a href=\"https://cloud.google.com/pubsub/docs/quickstart-console\" target=\"_self\">Pub/Sub topic and subscription</a> from your Google Cloud Console where you can send your logs from Google Operations Suite. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt729ea82c62f6cf41/6143c6569d27cf7da4ba0a18/blog-gcp-integration-pubsub-2.png\" data-sys-asset-uid=\"blt729ea82c62f6cf41\" alt=\"blog-gcp-integration-pubsub-2.png\"/></p><p>Next, navigate to the Google Cloud Console to configure our <a href=\"https://cloud.google.com/dataflow/\" target=\"_self\">Dataflow</a> job.&nbsp; </p><p>In the Dataflow product, click “Create job from template” and select \"Pub/Sub to Elasticsearch\" from the Dataflow template dropdown menu. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltbd14459da3fb91c0/6143c6648440e97ef58272c3/blog-gcp-integration-pubsub-3.png\" data-sys-asset-uid=\"bltbd14459da3fb91c0\" alt=\"blog-gcp-integration-pubsub-3.png\"/></p><p>Fill in required parameters, including your Cloud ID and Base64-encoded API Key for Elasticsearch. Since we are streaming audit logs, add “audit” as a log type parameter. Cloud ID can be found from Elastic Cloud UI as shown below. API Key can be created using the <a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-create-api-key.html\" target=\"_self\">Create API key API</a>. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltaa76aed1b8faf542/6143c677947b692d209b5352/blog-gcp-integration-pubsub-4.png\" data-sys-asset-uid=\"bltaa76aed1b8faf542\" alt=\"blog-gcp-integration-pubsub-4.png\"/></p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt56be59a0016ed28c/6143c686f725af79f53fc4ea/blog-gcp-integration-pubsub-5.png\" data-sys-asset-uid=\"blt56be59a0016ed28c\" alt=\"blog-gcp-integration-pubsub-5.png\"/></p><p>Click “Run Job” and wait for Dataflow to execute the template, which takes about a few minutes. As you can see, you don’t need to leave the Google Cloud Console or manage agents! </p><p>Now, navigate to Kibana to see your logs parsed and visualized in the [Logs GCP] dashboard. </p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt879b955d1a95e437/6143c69364c8007a9bdea6fd/blog-gcp-integration-pubsub-6.png\" data-sys-asset-uid=\"blt879b955d1a95e437\" alt=\"blog-gcp-integration-pubsub-6.png\"/></p><h2>Wrapping up</h2><p>Elastic is constantly making it easier and more frictionless for customers to run where they want and use what they want — and this streamlined integration with Google Cloud is the latest example of that. Elastic Cloud extends the value of the Elastic Stack, allowing customers to do more, faster, making it the best way to experience our platform. For more information on the integration, <a href=\"https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubtoelasticsearch\" target=\"_self\">visit Google’s documentation</a>. To get started using Elastic on Google Cloud, visit the <a href=\"https://console.cloud.google.com/marketplace/product/elastic-prod/elastic-cloud?utm_source=elastic&utm_medium=elastic_blog&utm_campaign=ingest_data_directly_from_google_pub_sub_into_elastic_using_google_dataflow\" target=\"_self\">Google Cloud Marketplace</a> or <a href=\"https://www.elastic.co/\" target=\"_self\">elastic.co</a>. </p>","PublishedAt":"2021-09-27 17:00:00+00:00","OriginURL":"https://www.elastic.co/blog/ingest-data-directly-from-google-pub-sub-into-elastic-using-google-dataflow","SourceName":"Elastic"}},{"node":{"ID":1254,"Title":"Blog: Spotlight on SIG Node","Description":"<p><strong>Author:</strong> Dewan Ahmed, Red Hat</p>\n<h2 id=\"introduction\">Introduction</h2>\n<p>In Kubernetes, a <em>Node</em> is a representation of a single machine in your cluster. <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node</a> owns that very important Node component and supports various subprojects such as Kubelet, Container Runtime Interface (CRI) and more to support how the pods and host resources interact. In this blog, we have summarized our conversation with <a href=\"https://twitter.com/ehashdn\">Elana Hashman (EH)</a> &amp; <a href=\"https://twitter.com/SergeyKanzhelev\">Sergey Kanzhelev (SK)</a>, who walk us through the various aspects of being a part of the SIG and share some insights about how others can get involved.</p>\n<h2 id=\"a-summary-of-our-conversation\">A summary of our conversation</h2>\n<h3 id=\"could-you-tell-us-a-little-about-what-sig-node-does\">Could you tell us a little about what SIG Node does?</h3>\n<p>SK: SIG Node is a vertical SIG responsible for the components that support the controlled interactions between the pods and host resources. We manage the lifecycle of pods that are scheduled to a node. This SIG's focus is to enable a broad set of workload types, including workloads with hardware specific or performance sensitive requirements. All while maintaining isolation boundaries between pods on a node, as well as the pod and the host. This SIG maintains quite a few components and has many external dependencies (like container runtimes or operating system features), which makes the complexity we deal with huge. We tame the complexity and aim to continuously improve node reliability.</p>\n<h3 id=\"sig-node-is-a-vertical-sig-could-you-explain-a-bit-more\">&quot;SIG Node is a vertical SIG&quot; could you explain a bit more?</h3>\n<p>EH: There are two kinds of SIGs: horizontal and vertical. Horizontal SIGs are concerned with a particular function of every component in Kubernetes: for example, SIG Security considers security aspects of every component in Kubernetes, or SIG Instrumentation looks at the logs, metrics, traces and events of every component in Kubernetes. Such SIGs don't tend to own a lot of code.</p>\n<p>Vertical SIGs, on the other hand, own a single component, and are responsible for approving and merging patches to that code base. SIG Node owns the &quot;Node&quot; vertical, pertaining to the kubelet and its lifecycle. This includes the code for the kubelet itself, as well as the node controller, the container runtime interface, and related subprojects like the node problem detector.</p>\n<h3 id=\"how-did-the-ci-subproject-start-is-this-specific-to-sig-node-and-how-does-it-help-the-sig\">How did the CI subproject start? Is this specific to SIG Node and how does it help the SIG?</h3>\n<p>SK: The subproject started as a follow up after one of the releases was blocked by numerous test failures of critical tests. These tests haven’t started falling all at once, rather continuous lack of attention led to slow degradation of tests quality. SIG Node was always prioritizing quality and reliability, and forming of the subproject was a way to highlight this priority.</p>\n<h3 id=\"as-the-3rd-largest-sig-in-terms-of-number-of-issues-and-prs-how-does-your-sig-juggle-so-much-work\">As the 3rd largest SIG in terms of number of issues and PRs, how does your SIG juggle so much work?</h3>\n<p>EH: It helps to be organized. When I increased my contributions to the SIG in January of 2021, I found myself overwhelmed by the volume of pull requests and issues and wasn't sure where to start. We were already tracking test-related issues and pull requests on the CI subproject board, but that was missing a lot of our bugfixes and feature work. So I began putting together a triage board for the rest of our pull requests, which allowed me to sort each one by status and what actions to take, and documented its use for other contributors. We closed or merged over 500 issues and pull requests tracked by our two boards in each of the past two releases. The Kubernetes devstats showed that we have significantly increased our velocity as a result.</p>\n<p>In June, we ran our first bug scrub event to work through the backlog of issues filed against SIG Node, ensuring they were properly categorized. We closed over 130 issues over the course of this 48 hour global event, but as of writing we still have 333 open issues.</p>\n<h3 id=\"why-should-new-and-existing-contributors-consider-joining-sig-node\">Why should new and existing contributors consider joining SIG Node?</h3>\n<p>SK: Being a SIG Node contributor gives you skills and recognition that are rewarding and useful. Understanding under the hood of a kubelet helps architecting better apps, tune and optimize those apps, and gives leg up in issues troubleshooting. If you are a new contributor, SIG Node gives you the foundational knowledge that is key to understanding why other Kubernetes components are designed the way they are. Existing contributors may benefit as many features will require SIG Node changes one way or another. So being a SIG Node contributor helps building features in other SIGs faster.</p>\n<p>SIG Node maintains numerous components, many of which have dependency on external projects or OS features. This makes the onboarding process quite lengthy and demanding. But if you are up for a challenge, there is always a place for you, and a group of people to support.</p>\n<h3 id=\"what-do-you-do-to-help-new-contributors-get-started\">What do you do to help new contributors get started?</h3>\n<p>EH: Getting started in SIG Node can be intimidating, since there is so much work to be done, our SIG meetings are very large, and it can be hard to find a place to start.</p>\n<p>I always encourage new contributors to work on things that they have some investment in already. In SIG Node, that might mean volunteering to help fix a bug that you have personally been affected by, or helping to triage bugs you care about by priority.</p>\n<p>To come up to speed on any open source code base, there are two strategies you can take: start by exploring a particular issue deeply, and follow that to expand the edges of your knowledge as needed, or briefly review as many issues and change requests as you possibly can to get a higher level picture of how the component works. Ultimately, you will need to do both if you want to become a Node reviewer or approver.</p>\n<p><a href=\"https://twitter.com/dims\">Davanum Srinivas</a> and I each ran a cohort of group mentoring to help teach new contributors the skills to become Node reviewers, and if there's interest we can work to find a mentor to run another session. I also encourage new contributors to attend our Node CI Subproject meeting: it's a smaller audience and we don't record the triage sessions, so it can be a less intimidating way to get started with the SIG.</p>\n<h3 id=\"are-there-any-particular-skills-you-d-like-to-recruit-for-what-skills-are-contributors-to-sig-usability-likely-to-learn\">Are there any particular skills you’d like to recruit for? What skills are contributors to SIG Usability likely to learn?</h3>\n<p>SK: SIG Node works on many workstreams in very different areas. All of these areas are on system level. For the typical code contributions you need to have a passion for building and utilizing low level APIs and writing performant and reliable components. Being a contributor you will learn how to debug and troubleshoot, profile, and monitor these components, as well as user workload that is run by these components. Often, with the limited to no access to Nodes, as they are running production workloads.</p>\n<p>The other way of contribution is to help document SIG node features. This type of contribution requires a deep understanding of features, and ability to explain them in simple terms.</p>\n<p>Finally, we are always looking for feedback on how best to run your workload. Come and explain specifics of it, and what features in SIG Node components may help to run it better.</p>\n<h3 id=\"what-are-you-getting-positive-feedback-on-and-what-s-coming-up-next-for-sig-node\">What are you getting positive feedback on, and what’s coming up next for SIG Node?</h3>\n<p>EH: Over the past year SIG Node has adopted some new processes to help manage our feature development and Kubernetes enhancement proposals, and other SIGs have looked to us for inspiration in managing large workloads. I hope that this is an area we can continue to provide leadership in and further iterate on.</p>\n<p>We have a great balance of new features and deprecations in flight right now. Deprecations of unused or difficult to maintain features help us keep technical debt and maintenance load under control, and examples include the dockershim and DynamicKubeletConfiguration deprecations. New features will unlock additional functionality in end users' clusters, and include exciting features like support for cgroups v2, swap memory, graceful node shutdowns, and device management policies.</p>\n<h3 id=\"any-closing-thoughts-resources-you-d-like-to-share\">Any closing thoughts/resources you’d like to share?</h3>\n<p>SK/EH: It takes time and effort to get to any open source community. SIG Node may overwhelm you at first with the number of participants, volume of work, and project scope. But it is totally worth it. Join our welcoming community! <a href=\"https://github.com/kubernetes/community/tree/master/sig-node\">SIG Node GitHub Repo</a> contains many useful resources including Slack, mailing list and other contact info.</p>\n<h2 id=\"wrap-up\">Wrap Up</h2>\n<p>SIG Node hosted a <a href=\"https://www.youtube.com/watch?v=z5aY4e2RENA\">KubeCon + CloudNativeCon Europe 2021 talk</a> with an intro and deep dive to their awesome SIG. Join the SIG's meetings to find out about the most recent research results, what the plans are for the forthcoming year, and how to get involved in the upstream Node team as a contributor!</p>","PublishedAt":"2021-09-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/27/sig-node-spotlight-2021/","SourceName":"Kubernetes"}},{"node":{"ID":40,"Title":"My internship on Asana’s Engineering team","Description":"<img width=\"1024\" height=\"656\" src=\"https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1024x656.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" loading=\"lazy\" style=\"display: block; margin: auto; margin-bottom: 5px;max-width: 100%;\" link_thumbnail=\"\" srcset=\"https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1024x656.png 1024w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-520x333.png 520w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-1536x984.png 1536w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero.png 1607w, https://blog.asana.com/wp-content/post-images/Blog-Asana-Intern-Hero-520x333@2x.png 1040w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><p>This post was written by Jordan Hunt during his internship before he went back to school! Hi there, I’m Jordan and I’m a rising junior at Harvey Mudd College studying computer science and mathematics. I spent this summer interning at Asana as a Product Engineer on their Pricing &#38; Packaging team. Interning at Asana has [&#8230;]</p>\n<p>The post <a rel=\"nofollow\" href=\"https://blog.asana.com/2021/09/engineering-internship/\">My internship on Asana&#8217;s Engineering&nbsp;team</a> appeared first on <a rel=\"nofollow\" href=\"https://blog.asana.com\">The Asana Blog</a>.</p>\n","PublishedAt":"2021-09-24 14:37:03+00:00","OriginURL":"https://blog.asana.com/2021/09/engineering-internship/","SourceName":"Asana"}},{"node":{"ID":474,"Title":"Feature flags and product analytics","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/09/ask-an-expert-dave-martin@2x-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>Experimentation is a huge part of getting your product right, whether it&#8217;s trying out a new feature or potential tweaks to existing elements of your app. When it comes to running these kinds of product tests, using feature flags can be a really effective and minimally disruptive way to go. We spoke to David Martin,</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/feature-flags-and-product-analytics-working-together/\">Feature flags and product analytics</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-09-24 00:12:00+00:00","OriginURL":"https://mixpanel.com/blog/feature-flags-and-product-analytics-working-together/","SourceName":"Mixpanel"}},{"node":{"ID":64,"Title":"Elastic APM iOS agent technical preview released","Description":"<p>We are proud to announce the preview release of the Elastic APM iOS agent! This release is intended to elicit feedback from the community, while providing some initial functionality within the Elastic Observability stack and is not intended for production use. Now is your chance to influence the direction of this new iOS agent and let us know what you think on our <a href=\"https://discuss.elastic.co/c/apm\">discussion forum</a>. If you find an issue, or would like to contribute yourself, visit the <a href=\"https://github.com/elastic/apm-agent-ios\">GitHub repository</a>. </p> <p><a href=\"https://www.elastic.co/solutions/apm\">Elastic APM</a> is an Application Performance Monitoring solution from Elastic and alongside the iOS agent, there are official agents available for <a href=\"https://github.com/elastic/apm-agent-java\">Java</a>, <a href=\"https://github.com/elastic/apm-agent-nodejs\">Node.js</a>, <a href=\"https://github.com/elastic/apm-agent-python\">Python</a>,<a href=\"https://github.com/elastic/apm-agent-ruby\"> Ruby</a>, <a href=\"https://github.com/elastic/apm-agent-js-base\">JavaScript/RUM</a>, <a href=\"https://github.com/elastic/apm-agent-dotnet\">.NET</a>, <a href=\"https://github.com/elastic/apm-agent-php\">PHP</a>, and <a href=\"https://github.com/elastic/apm-agent-go\">Go</a>. Elastic APM helps you to gain insight into the performance of your application, track errors, and gauge the end-user experience in the browser. </p> <p>I’ll be going into the details of the release below, but if you’re ready to jump into the documentation right away you can find it at the <a href=\"https://www.elastic.co/guide/en/apm/agent/swift/current/index.html\">Elastic APM iOS agent documentation</a>. </p> <strong><h2>Supported frameworks</h2></strong> <p>The Elastic APM iOS agent is built on the <a href=\"https://github.com/open-telemetry/opentelemetry-swift\">opentelementry-swift sdk</a>. This means that any frameworks or libraries that are instrumented with Open Telemetry will be captured by the Elastic APM iOS agent. Additionally, any custom OTel instrumentation you add to your application will be picked up by our agent. </p> <p>We are initially providing auto instrumentation of following: </p> <ul> <li aria-level=\"1\">URLSession</li> <li aria-level=\"1\">CPU & Memory usage</li> <li aria-level=\"1\">Network connectivity</li> <li aria-level=\"1\">Device & Application attributes</li> </ul> <p>Our main focus is to provide insight into your backend services from the perspective of your mobile application, automatically displaying distributed traces starting at your mobile app. </p> <strong><h2>Downloading the agent</h2></strong> <p>The agent will initially be provided through the <a href=\"https://swift.org/package-manager/\">Swift Package Manager</a>. It can be added to an iOS project through the <a href=\"https://developer.apple.com/documentation/swift_packages/adding_package_dependencies_to_your_app\">Xcode SPM dependency manager</a> or through a <code>Package.swift</code> file.&nbsp; </p> <p>Simply add the following to your Package.swift dependencies </p> <pre class=\"prettyprint\">         dependencies: [ \n        .package(name: \"apm-agent-ios\", url: \"https://github.com/elastic/apm-agent-ios\", .branch(“v0.1.0\")), \n… </pre> <p>And add “iOSAgent” to the targets you wish to instrument: </p> <pre class=\"prettyprint\">.target( \n            name: \"MyLibrary\", \n            dependencies: [ \n                .product(name: \"iOSAgent\", package: \"apm-agent-ios\") \n            ]), </pre> <strong><h2>The agent API</h2></strong> <p>The Elastic APM iOS Agent has a few project requirements: </p> <ul> <li aria-level=\"1\">It’s only compatible with Swift (sorry Objective-C engineers)&nbsp;</li> <li aria-level=\"1\">It requires Swift v5.3</li> <li aria-level=\"1\">It requires the minimum of iOS v11</li> </ul> <p>The agent API is fairly slim. We provide a configuration object that allows the agent to be set up for an on-prem or cloud solution. </p> <p>If you’re using SwiftUI to build your app, you can set up the agent as follows:&nbsp; </p> <pre class=\"prettyprint\">struct MyApp: App { \n    init() { \n        var config = AgentConfiguration() \n        config.collectorAddress = \"127.0.0.1\"  \n        config.collectorPort = 8200  \n        config.collectorTLS = false  \n        config.secretToken = \"&lt;secret token&gt;\"  \n        Agent.start(with: config) \n    } </pre> <p>&nbsp;Read up more on configuration in the “<a href=\"https://www.elastic.co/guide/en/apm/agent/swift/0.x/setup.html\">Set up the Agent</a>” doc. </p> <p>The agent also captures any data recorded through the OpenTelementry-Swift APIs, including traces and metrics. Here’s an example on how to start a simple trace: </p> <pre class=\"prettyprint\">let instrumentationLibraryName = \"SimpleExporter\" \nlet instrumentationLibraryVersion = \"semver:0.1.0\" \nvar instrumentationLibraryInfo = InstrumentationLibraryInfo(name: instrumentationLibraryName, version: instrumentationLibraryVersion) \nvar tracer = OpenTelemetrySDK.instance.tracerProvider.get(instrumentationName: instrumentationLibraryName, instrumentationVersion: instrumentationLibraryVersion) as! TracerSdk \nfunc simpleSpan() { \n    let span = tracer.spanBuilder(spanName: \"SimpleSpan\").setSpanKind(spanKind: .client).startSpan() \n    span.setAttribute(key: sampleKey, value: sampleValue) \n    Thread.sleep(forTimeInterval: 0.5) \n    span.end() \n} </pre> <p>You can find more examples on how to use the OTel API at <a href=\"https://github.com/open-telemetry/opentelemetry-swift/tree/main/Examples\">OpenTelementry-Swift examples</a>. </p> <p>If you decide to go this route, you may have to add OpenTelemetry-Swift as a dependency to your project as well.&nbsp; </p> <strong><h2>Summary and future</h2></strong> <p>We would be thrilled to receive your feedback in our <a href=\"https://discuss.elastic.co/c/apm\">discussion forum</a> or in <a href=\"https://github.com/elastic/apm-agent-ios\">our GitHub repository</a>. Please keep in mind that the current release is a preview and we may introduce breaking changes. We are excited to be launching this mobile offering and already have many ideas for what comes next, but we want the community to help guide our direction. Check out our <a href=\"https://github.com/elastic/apm-agent-ios/blob/main/CONTRIBUTING.md\">CONTRIBUTING.md</a> and let the PRs fly! </p>","PublishedAt":"2021-09-23 18:00:00+00:00","OriginURL":"https://www.elastic.co/blog/elastic-apm-ios-agent-technical-preview-released","SourceName":"Elastic"}},{"node":{"ID":769,"Title":"Real-Time Exactly-Once Ad Event Processing with Apache Flink, Kafka, and Pinot","Description":"<p><span style=\"font-weight: 400;\">Uber recently launched a new capability: Ads on UberEats. With this new ability came new challenges that needed to be solved at Uber, such as systems for ad auctions, bidding, attribution, reporting, and more. This article focuses on how we </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/real-time-exactly-once-ad-event-processing/\">Real-Time Exactly-Once Ad Event Processing with Apache Flink, Kafka, and Pinot</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-23 16:00:42+00:00","OriginURL":"https://eng.uber.com/real-time-exactly-once-ad-event-processing/","SourceName":"Uber"}},{"node":{"ID":65,"Title":"How the French Ministry of Agriculture deploys Elastic to monitor the commercial fishing industry","Description":"<p>Within the French Ministry of Agriculture and Food (the Ministry), our team of architects in the Methods, Support and Quality office (BMSQ) evaluate and supply software solutions to resolve issues encountered by project teams that affect various disciplines.\n</p><p>As data specialists, one area we’ve been involved in includes reconfiguring the traceability of activities for the commercial fishing industry. The aim is to improve the quality, speed and precision of how we collect and analyze large volumes of data connected to the industry — from declared fish hauls, harbor exit manifests, to GPS data tracking vessel locations.\n</p><p>The challenge we have is to provide up-to-date information that is verified, complete, dynamic and can be viewed in various formats depending on the target audience, and Elastic is the solution. Elastic handles ingesting all of our data and render visualizations to make it easy to share and use real-time information about commercial fishing activity. With this integrated data, we can take enforcement action, stop illegal fishing, and negotiate fishing rights with our neighboring countries.\n</p><h1 dir=\"ltr\">Why we choose Elastic over Splunk and Graylog</h1><p>The first stage of the project was to perform a proof of concept with a solution capable of storing, extracting, and presenting the data related to fishing activities in real time.\n</p><p>We benchmarked the <a href=\"https://www.elastic.co/elastic-stack/\">Elastic Stack</a> against other tools, such as Graylog and Splunk. We were ultimately won over by the Elastic Stack’s speed and ease of use, along with its power and scalability. The data presentation and visualization tools, <a href=\"https://www.elastic.co/what-is/kibana-canvas\">Canvas</a>, and <a href=\"https://www.elastic.co/kibana/\">Kibana</a>, have also played crucial roles in this project, enabling us to efficiently provide information for our end users in the context of increasingly strict protective fishing regulations and measures. In addition, our Elastic subscription, reduces our development time and allows us to focus on our real work, thanks to the support team at Elastic.\n</p><h1 dir=\"ltr\">Casting a wide regulatory fishing net with Elastic</h1><p>With GPS systems required on fishing vessels larger than 12 meters (39 feet), we have been able to track boats while at the same time indexing that monitoring data into <a href=\"https://www.elastic.co/elasticsearch/\">Elasticsearch</a>, where it is visualized in either Kibana or Canvas. This enables us to help Ministry officials on several enforcement levels:\n</p><ul>\n\t<li dir=\"ltr\" aria-level=\"1\">Locating activity zones of boats and areas of intense fishing</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Monitoring fishing quotas in FAO (Food and Agriculture Organization) zones&nbsp;</li>\n\t<li dir=\"ltr\" aria-level=\"1\">Flagging infringements of the law</li>\n</ul><em><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb97730e25592db6c/6164acc6ca79db05abb0f1ad/kibana-presentation-areas-intense-fishing.jpg\" data-sys-asset-uid=\"bltb97730e25592db6c\" alt=\"kibana-presentation-areas-intense-fishing.jpg\">\n</p>Sample Kibana presentation to locate areas of intense fishing&nbsp;&nbsp;<br></em><br><p>With Canvas, we can refine the granularity, quality, and format to ensure the fishery data is presented in the most suitable format for the audience, especially a non-technical audience.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltf4ea8efa140c8790/6164ae0656faa61e63fdd9a9/infographic-quotas-de-peche.png\" data-sys-asset-uid=\"bltf4ea8efa140c8790\" alt=\"infographic-quotas-de-peche.png\"></p><p><em>Example of the infographics generated using Canvas to monitor fishing data of cod, sardine, and tuna\n\t</em>\n</p><p>We could not render presentations like this with our legacy tools, which were conventional databases and a Java application. They were at their limits in terms of the required performance due to the number of filter fields, 300 and counting. Now, once the data has been processed in Logstash, stored and indexed in Elasticsearch, it can be filtered, cross-referenced and correlated in real time.&nbsp;\n</p><p>Elastic gives us the ability to verify the precision and compliance of statements declared by boats compared with actual recorded events.\n</p><p>We are storing our raw data for 10 years. This amounts to 135 million records in Elasticsearch. In addition, each record contains more than 300 filter fields. We receive raw ERS (Electronic Reporting System) data in XML format, as issued by the boats using onboard software or GPS, and we model this data as it flows in so we can integrate it into our Elasticsearch cluster.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt4a80668166d5428f/6164ae5edd1cf90b821de893/diagram-ers-data-xml-format-boats-gps-model.png\" data-sys-asset-uid=\"blt4a80668166d5428f\" alt=\"diagram-ers-data-xml-format-boats-gps-model.png\"></p><h1 dir=\"ltr\">How Elastic fits in the architectural layout of the French Ministry of Agriculture <br></h1><p>This sea of information allows us to pinpoint quantities and species fished, rejections of protected species, type of boat plus its flag, registration and equipment, fishing quotas per territorial area, satellite operator depending on the region of the globe, and much more.&nbsp;\n</p><p>Real-time information detailed by region is the basis for consolidated analyses and discussion to facilitate immediate remedying of any infringements of the law, rapid reaction to media controversy relating to protected marine species, and even the renegotiation of quotas each year within the European Union.\n</p><h1 dir=\"ltr\">Expanding to political, economical and environmental use cases&nbsp;</h1><p>The Ministry is continuing to closely monitor new releases of the Elastic Stack. We are anticipating the availability of a French version of Kibana, which would expand the solution’s user group. The most recent functionalities provided in versions 7.11 and 7.12 of Elastic are being tested with great interest — in particular the addition of the tracks layer in the Maps application. This feature takes an index of point locations, ordered by time, and displays them as a line, enabling us to track the route taken by boats, as shown below:\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1c263e15a3d96e4d/6164ac5daeba391136e44d0e/dashboard-test-trace.jpg\" data-sys-asset-uid=\"blt1c263e15a3d96e4d\" alt=\"dashboard-test-trace.jpg\">\n</p><p>We have been grateful for the ease of use, flexibility, and creativity of Kibana and Canvas in enabling stakeholders to remain well informed and to react rapidly to increasingly stringent protective regulations and measures. Moreover, the fishing data provided in XML format is modeled by batch, which enables requests to be processed via Elasticsearch on a continuously growing volume of data, without having to wait for all 10 years of the current stored data to be processed. Elastic also enables the indexation process to be repeated each time new data is added to existing fields.&nbsp;\n</p><p>In the short term, the Ministry’s aim is to conclude the roll-out of this solution and open it up to a growing group of users.\n</p><p>Beyond fishing data, we are going to need to store, process, and analyze increasing volumes of tracking data, particularly in regard to food — from farm to table. All of which means that Elastic could be of use for these new development projects with high political, economical and environmental stakes.\n</p><p dir=\"ltr\" style=\"line-height:1.38;margin-top:0pt;margin-bottom:0pt;\"><br>\n</p><hr><p><em><strong>Sébastien Arnaud</strong> — Exchanges & Data architect at the French Ministry of Agriculture</em>\n</p><p>Following initial training in the field of networks and IT security, he has worked on complex data exchange and transformation solutions. He likes to design and integrate innovative architectures for processing, storing and evaluating increasingly large volumes of data.\n</p>","PublishedAt":"2021-09-23 15:00:00+00:00","OriginURL":"https://www.elastic.co/blog/how-the-french-ministry-of-agriculture-deploys-elastic-to-monitor-the-commercial-fishing-industry","SourceName":"Elastic"}},{"node":{"ID":66,"Title":"Elastic 7.15: Create powerful, personalized search experiences in seconds","Description":"<p>We are pleased to announce the general availability of Elastic 7.15, a release that brings a broad set of new capabilities to the Elastic Search Platform (including Elasticsearch and Kibana) and its three built-in solutions — Elastic Enterprise Search, Elastic Observability, and Elastic Security.\n</p><p>With Elastic 7.15 comes the general availability of the Elastic App Search web crawler and tighter integrations with Google Cloud — enabling our customers and community to more quickly create powerful new web search experiences, to ingest data more quickly and securely, and to more easily put their data to work with the power of search.\n</p><p>In addition, with Elastic Observability’s new APM correlations feature, DevOps teams can accelerate root cause analysis and reduce mean time to resolution (MTTR) by automatically surfacing attributes correlated with high-latency or erroneous transactions.\n</p><p>And, as the saying goes, if you’re going to observe... why not (also) protect?\n</p><p>To this end, with Elastic 7.15, Elastic Security enhances Limitless XDR (extended detection and response) with both malicious behavior protection for (nearly) every OS and one-click host isolation for cloud-native Linux environments.\n</p><div class=\"video embed-container\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/yN5mR9f6pUny82KZNxZAyb.jpg\" data-uuid=\"yN5mR9f6pUny82KZNxZAyb\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p>Elastic 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can, of course, also <a href=\"/downloads/\">download the Elastic Stack</a> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.\n</p><h2>Elastic Enterprise Search</h2><h3>Create powerful new web search experiences in seconds with the general availability of the Elastic App Search web crawler</h3><p>With 7.15, Enterprise Search makes it faster than ever for organizations to get up and running with web search — freeing up technical teams to focus on other important projects. The Elastic App Search web crawler, now generally available, makes implementing search and ingesting website content nearly effortless. In addition to a number of web crawler improvements that make setup a snap, like automatic crawling controls, content extraction tools, and the ability to natively analyze logs and metrics in Kibana, the web crawler now enables customers to use a single platform to search all of their organization’s data — even websites.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1ce8388dee720102/613cdadbfbe3b8273005fc82/7-15-elastic-co-starting-a-crawl.gif\" data-sys-asset-uid=\"blt1ce8388dee720102\" alt=\"Generally available with Elastic 7.15, the Elastic App Search Web Crawler makes it easy to ingest website content\"><br>\n</p><figcaption>Generally available with Elastic 7.15, the Elastic App Search web crawler makes it easy to ingest website content</figcaption><p>To learn more visit the <a href=\"/blog/whats-new-elastic-enterprise-search-7-15-0\">Elastic Enterprise Search 7.15 blog</a>.\n</p><h2>Elastic Observability</h2><h3>Automate root cause analysis for faster application troubleshooting</h3><p>DevOps teams and site reliability engineers are constantly challenged by the need to sift through overwhelming amounts of data to keep modern applications performant and error-free. More often than not, this is a manual and time-consuming effort. To effectively resolve complex problems, these users need the ability to collect, unify, and analyze an increasing volume of telemetry data and quickly distill meaningful insights. Automation and machine intelligence have become essential components of the troubleshooter’s toolkit.\n</p><p>With Elastic 7.15, we’re excited to announce the general availability of Elastic Observability’s APM correlations feature. This new capability will help DevOps teams and site reliability engineers to accelerate root cause analysis by automatically surfacing attributes of the APM data set that are correlated with high-latency or erroneous transactions.<img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltebe967f6d2648245/613fa0d58540c92b07a99fdf/7-15-animation-apm-latency-correlations.gif\" data-sys-asset-uid=\"bltebe967f6d2648245\" alt=\"Elastic APM correlations, now generally available, accelerate root cause analysis to free up DevOps and SRE teams\">\n</p><figcaption>Elastic APM correlations, now generally available, accelerate root cause analysis to free up DevOps and SRE teams</figcaption><h3>Streamline monitoring of Google Cloud Platform services with frictionless log ingestion</h3><p>Elastic’s new Google Cloud Dataflow integration drives efficiency with the frictionless ingestion of log data directly from the Google Cloud Platform (GCP) console. This agentless approach provides an “easy button” for customers — eliminating the cost and hassle of administrative overhead and further extending Elastic’s ability to more easily monitor&nbsp;native GCP services.\n</p><p>To learn more visit the <a href=\"/blog/whats-new-elastic-observability-7-15-0\">Elastic Observability 7.15 blog</a>.\n</p> <strong><h2>Elastic Security</h2></strong><p>With Elastic 7.15, Elastic Security augments extended detection and response by equipping Elastic Agent to end threats at the endpoint, with new layers of prevention for every OS and host isolation for cloud-native Linux environments.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb7921b50c291a90c/613fa1703e034728ba0171ea/screenshot-security-detection-host-alert-7-15.jpg\" data-sys-asset-uid=\"bltb7921b50c291a90c\" alt=\"Elastic Security 7.15 powers extended detection and response (XDR) with malicious behavior protection for every OS and host isolation for cloud-native Linux environments\">\n</p><figcaption>Elastic Security 7.15 powers extended detection and response (XDR) with malicious behavior protection for every OS and host isolation for cloud-native Linux environments</figcaption><h3>Stop advanced threats at the endpoint with malicious behavior protection for Linux, Windows, and macOS hosts</h3><p>Malicious behavior protection, new in version 7.15, arms Elastic Agent to stop advanced threats at the endpoint. It provides a new layer of protection for Linux, Windows, and macOS hosts, powered by analytics that prevent attack techniques leveraged by known threats. This capability buttresses <a href=\"/blog/whats-new-elastic-security-7-14-0\">existing malware and ransomware prevention</a> with dynamic prevention of post-execution behavior. Prevention is achieved by pairing post-execution analytics with response actions tailored to disrupt the adversary early in the attack, such as killing a process to stop a payload from being downloaded.\n</p><h3>Contain attacks with one-click host isolation from within Kibana</h3><p>In addition to malicious behavior protection, with the release of Elastic 7.15, Elastic Security enables analysts to quickly and easily quarantine Linux hosts via a remote action from Kibana. With (just) one click, analysts can respond to malicious activity by isolating a host from a network, containing the attack and preventing lateral movements. While <a href=\"/blog/whats-new-elastic-security-7-14-0\">host isolation was introduced for Windows and macOS in version 7.14</a>, it is now available on every OS protected by Elastic Agent.\n</p><p>We’re implementing this capability on Linux systems via <a href=\"https://ebpf.io/\">extended Berkeley Packet Filter (eBPF)</a> technology, a reflection of our commitment to technologies that enable users to observe and protect modern cloud-native systems in the most frictionless way possible.\n</p><p>For more information on our continuing efforts in the realm of cloud security, check out our recent announcements on Elastic joining forces with <a href=\"/blog/elastic-and-build-security-shifting-left-together-to-secure-the-cloud\">build.security</a> and <a href=\"/blog/elastic-and-cmd-join-forces-to-help-you-take-command-of-your-cloud-workloads\">Cmd</a>.\n</p><p>To learn more about what’s new with Elastic Security in 7.15, visit the <a href=\"/blog/whats-new-elastic-security-7-15-0\">Elastic Security 7.15 blog</a>.\n</p><h2>Elastic Cloud</h2><p>Whether customers are looking to quickly find information, gain insights, or protect their technology investments (or all of the above), Elastic Cloud is the best way to experience the Elastic Search Platform. And we continue to improve that experience with new integrations that let customers ingest data into Elastic Cloud even more quickly and securely.\n</p><h3>Ingest data faster with Google Cloud Dataflow</h3><p>With Elastic 7.15, we’re pleased to announce the first-ever native Google Cloud data source integration to Elastic Cloud — Google Cloud Dataflow. This integration enables users to ship Pub/Sub, Big Query, and Cloud Storage&nbsp;data directly into their Elastic Cloud deployments without having to set up an extra intermediary data shipper, utilizing Google Cloud’s native serverless ETL service. The integration simplifies data architectures and helps users ingest data into Elastic Cloud faster.\n</p><h3>Ensure data privacy with the general availability of Google Cloud Private Service Connect</h3><p>We’re also excited to announce that support for Google Private Service Connect is now generally available. Google Private Service Connect provides private connectivity from Google Cloud virtual private clouds (VPCs) to Elastic Cloud deployments. The traffic between Google Cloud and Elastic Cloud deployments on Google Cloud travels only within the Google Cloud network, utilizing Private Service Connect endpoints and ensuring that customer data stays off the (public) internet.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blte6407921f8ae5b16/613fa6b2fbe3b82730060152/7-15-elastic-google-cloud-private-service-connect.jpg\" data-sys-asset-uid=\"blte6407921f8ae5b16\" alt=\"Google Private Service Connect provides easy and private access to Elastic Cloud deployment endpoints while keeping all traffic within the Google network\"><br>\n</p><figcaption>Google Private Service Connect provides easy and private access to Elastic Cloud deployment endpoints while keeping all traffic within the Google network</figcaption><p>To learn more about what’s new with Elastic Cloud, visit the <a href=\"/blog/whats-new-elasticsearch-kibana-cloud-7-15-0\">Elastic Platform 7.15 blog</a>.\n</p><h2>Read more in our latest release blogs</h2><ul>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-enterprise-search-7-15-0\">Elastic Enterprise Search 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-observability-7-15-0\">Elastic Observability 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elastic-security-7-15-0\">Elastic Security 7.15 released</a></li>\n\t<li aria-level=\"1\"><a href=\"/blog/whats-new-elasticsearch-kibana-cloud-7-15-0\">Elastic Platform 7.15 released</a></li>\n</ul><h2>Test our mettle</h2><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"/training/free#quick-starts\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or our <a href=\"/training/free#fundamentals\">free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\">free 14-day trial of Elastic Cloud</a>. Or <a href=\"/downloads/\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.</em>\n</p> <em><em></em></em>","PublishedAt":"2021-09-22 16:04:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-7-15-0","SourceName":"Elastic"}},{"node":{"ID":67,"Title":"What's new in Elastic Enterprise Search 7.15: Web crawler GA and personalized Workplace Search","Description":"<p>Elastic Enterprise Search 7.15 introduces general availability for App Search’s web crawler making it quick and effortless to spin up powerful, new search experiences for every use case.\n</p><div class=\"video embed-container shadow m-b-40\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/z7s4ctMrp4AgVYo9RjY4ox.jpg\" data-uuid=\"z7s4ctMrp4AgVYo9RjY4ox\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-hidden_controls=\"1\" data-muted=\"0\" muted=\"0\" alt=\"\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p>We’re also adding countless ways to personalize Workplace Search to meet the unique needs of your organization with the ability to add custom branding, schedule sync frequency, and configure automatic filter detection.\n</p><p>These updates help teams launch search faster and tailor the search experiences they create:\n</p><ul>\n\t<li>Take the headache out of data ingestion and make your website content instantly searchable with a sophisticated, easy-to-use web crawler</li>\n\t<li>Apply your organization’s branding across all your mission-critical productivity tools</li>\n\t<li>Schedule sync frequency in line with infrastructure demands</li>\n\t<li>Define custom filters specific to your business so your team can search naturally</li>\n\t<li>Create search integrations where your teams spend the most time, and deliver results from any source from Google Drive to Slack, and everything in between.</li>\n</ul>Elastic Enterprise Search 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-15-blog\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can also <strong><a href=\"https://www.elastic.co/downloads?elektra=whats-new-elastic-7-15-blog\">download the Elastic Stack</a></strong> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.<strong><h2>Set up new search experiences in no time with App Search’s web crawler</h2></strong><p>With 7.15, <a href=\"https://www.elastic.co/enterprise-search\">Elastic Enterprise Search</a> brings general availability to the <a href=\"https://www.elastic.co/web-crawler\">native web crawler</a> in App Search. One common hurdle customers face when setting up website and application search is data indexing. No more! With the web crawler, it’s simple to ingest web content and get new search experiences up and running in no time. And we’ve added features like adding automatic crawling controls and content extraction tools that streamline implementation and free up technical teams. Now you can also analyze crawler logs with Kibana visualizations and Elastic observability tools — so you can use one platform for all of your search data.\n</p><p><img class=\"shadow\" src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt1ce8388dee720102/613cdadbfbe3b8273005fc82/7-15-elastic-co-starting-a-crawl.gif\" data-sys-asset-uid=\"blt1ce8388dee720102\" alt=\"7-15-elastic-co-starting-a-crawl.gif\"><br>\n</p><p>Here’s everything new in the crawler including loads of performance and stability optimizations:\n</p><ul>\n\t<li><strong>Robots.txt support:</strong> Follows the robots exclusion standard, so it knows what pages not to crawl</li>\n\t<li><strong>Sitemap support:</strong> Uses your website’s XML blueprint to efficiently locate and crawl your most important content</li>\n\t<li><strong>Persistent crawling:</strong> Continues web crawling progress even in the instance of a failure or restart</li>\n\t<li><strong>Content extraction utilities:</strong> Lets you identify the exact content you want the web crawler to extract from each page it visits. Also covers:\n\t<ul>\n\t\t<li aria-level=\"2\">Meta tag and data-attribute rules</li>\n\t\t<li aria-level=\"2\">Include/exclude rules in the document body</li>\n\t</ul></li>\n\t<li><strong>Domain validation:</strong> Checks that a domain is valid and can be reached without indexing restrictions to prevent issues with starting a crawl</li>\n\t<li><strong>Deduplication control:</strong> Ensures that only the best version of each page appears in your search engine index</li>\n\t<li><strong>Automatic crawling controls:</strong> Allows you to define how frequently you want to perform automatic crawls</li>\n\t<li><strong>Process crawls:</strong> Allows you to remove documents on-demand from your index according to crawl rules</li>\n\t<li><strong>URL debugging API:</strong> A comprehensive way to troubleshoot problematic URLs, allowing you to understand what the web crawler encounters when it visits a given page</li>\n</ul> <strong><h2>Make your mark on Workplace Search</h2></strong><p>Personalize internal search with your very own branding assets so you can have a consistent look and feel across all of your organization’s essential applications. Make unified search your own and give it instant credibility with the team when you add your organization’s branding without having to build a custom interface. All it takes is a simple .png upload.\n</p><div class=\"video embed-container shadow m-b-40\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/qZxn6eWxQwmuZDmtMyTV4Y.jpg\" data-uuid=\"qZxn6eWxQwmuZDmtMyTV4Y\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-hidden_controls=\"1\" data-muted=\"0\" muted=\"0\" alt=\"\" style=\"width: 100%; margin: auto; display: block;\">\n</div><p><strong></strong></p><h2><strong>Your timetable, your data, your way with Workplace Search</strong></h2><p>Now you can also schedule Workplace Search sync frequency according to your organization’s needs. When you use Workplace Search’s enhanced sync configurability, you can ensure that computing resources are on par with infrastructure demands. What’s more, you can get real-time results when syncs correspond to your org’s data refresh patterns. No one will miss the team’s latest and greatest content when it’s instantly indexed. Customers on Elastic’s Platinum tier also get added convenience with the ability to schedule syncs by content source and by using the scheduling API.\n</p> <strong><h2>Get instant recognition with configurable automatic filter detection in Workplace Search</h2></strong><p>Natural language queries are at the heart of making search experiences intuitive and effective. But how do you also capture the terms and phrases essential to an organization’s communal intelligence? You need configurable filters, of course. Let your team search naturally and find information faster with filters defined for your organization. Take these examples:\n</p><ul> <strong>\n\t<li><strong>Pull requests </strong>from <strong>last week</strong></li></strong> <strong>\n\t<li><strong>Product team notes </strong>updated by <strong>me</strong></li></strong> <strong>\n\t<li>Monthly <strong>board presentations </strong>in <strong>Google Drive</strong></li></strong>\n</ul><p>Deliver relevant results to everyone on the team when you create custom filters using natural language queries that get automatically recognized. No need for anyone to pick up a complex query language just to find your latest presentation deck.\n</p> <strong><h2>Present common search experiences in Workplace Search</h2></strong><p>Workplace Search offers the convenience of a fully featured desktop and mobile search experience, but also provides all the necessary tools and endpoints for designing and developing bespoke search integrations embedded within high-traffic applications like intranets and workflow applications. Several improvements to the Search API endpoints allow for a more consistent experience across data sources. Slack and Gmail are now available for custom search experience development along with SharePoint Online, Google Drive and more than a dozen more native data integrations. No matter what information is most relevant to your team, you can design an immersive experience without constraints.\n</p> <strong><h2>Try it out</h2></strong><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"https://www.elastic.co/training/free#quick-starts\">Quick Start guides</a> (bite-sized training videos to get you started quickly, including the <a href=\"https://www.elastic.co/training/app-search-web-crawler-quick-start\">Web crawler Quick Start</a>) or our <a href=\"https://www.elastic.co/training/free#fundamentals\">free fundamentals training courses</a> (including the <a href=\"https://www.elastic.co/training/app-search-web-crawler-fundamentals\">App Search Web Crawler fundamentals course</a>). You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?elektra=whats-new-elastic-7-15-blog\">free 14-day trial of Elastic Enterprise Search</a>. Or <a href=\"https://www.elastic.co/downloads?elektra=whats-new-elastic-7-15-blog\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p>Read about these capabilities and more in the <a href=\"https://www.elastic.co/guide/en/enterprise-search/7.15/release-notes-7.15.0.html\">release notes</a>, and other Elastic Stack highlights in the <a href=\"https://www.elastic.co/blog/whats-new-elastic-7-15-0\">Elastic 7.15 announcement post</a>.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.</em>\n</p>","PublishedAt":"2021-09-22 16:03:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-enterprise-search-7-15-0","SourceName":"Elastic"}},{"node":{"ID":68,"Title":"What’s new in Elasticsearch, Kibana, and Elastic Cloud for 7.15","Description":"<p>Elastic Cloud customers can now ingest data more simply, quickly, and securely, and the latest updates to the core Elastic Stack provide users with new tools for maximizing performance and exploring their data.\n</p><p>The 7.15 release of Elastic Cloud brings new integrations with Google Cloud that allow customers to ingest Google Cloud services data directly into their Elastic Cloud deployments and take advantage of additional network security with Google Cloud Private Service Connect. Plus, the Elastic Stack brings enhancements to Elasticsearch and Kibana including improved data transfer, better resiliency, and more flexible data ingest and analysis.&nbsp;\n</p><p>Ready to roll up your sleeves and get started? We have the links you need:\n</p><ul>\n\t<li aria-level=\"1\">Try out the new features on <a href=\"https://cloud.elastic.co/registration?blade=blog&gambit=7-15-stack-and-cloud-blog\">Elastic Cloud</a>&nbsp;</li>\n\t<li aria-level=\"1\">Download the <a href=\"/downloads?elektra=stack-and-cloud-7-15-blog\">latest versions of Elasticsearch, Kibana, Elastic Cloud Enterprise, Elastic Cloud on Kubernetes</a></li>\n\t<li aria-level=\"1\">Release notes: <a href=\"/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a>, <a href=\"/guide/en/kibana/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a>, <a href=\"/guide/en/cloud/current/ec-release-notes.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud</a>, <a href=\"/guide/en/cloud-enterprise/current/ece-release-notes-2.12.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud Enterprise</a>, <a href=\"/guide/en/cloud-on-k8s/1.8/release-notes-1.8.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud on Kubernetes</a></li>\n\t<li aria-level=\"1\"><a href=\"/guide/en/elasticsearch/reference/7.15/migrating-7.15.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch breaking changes</a></li>\n</ul> <strong><h2 id=\"elastic-cloud\">What’s new in Elastic Cloud for 7.15</h2></strong> <strong><p>\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/FdFg5APpxL7jp46QG4yNiy.jpg\" data-uuid=\"FdFg5APpxL7jp46QG4yNiy\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Check out the new Google Cloud Dataflow native integration in Elastic Cloud\" style=\"width: 100%; margin: auto; display: block;\">\n</p><h3>Google Cloud Dataflow native integration</h3></strong><p>Introducing the first ever native Google Cloud data source integration for Elastic Cloud — Google Cloud Dataflow. This integration allows customers to ship Pub/Sub, Big Query, and Cloud Storage data directly into Elastic Cloud deployments without having to set up an extra intermediary data shipper, utilizing Google Cloud’s native serverless extract, transform, load (ETL) service. Customers benefit from simplified data architecture and increased speed when ingesting data into Elastic Cloud. Read our&nbsp;<a href=\"https://www.elastic.co/blog/elastic-and-google-cloud-now-offer-tighter-data-integration\">blog post on these integrations</a>&nbsp;to learn more.</p> <strong><h3>Google Cloud Private Service Connect</h3></strong><p>We’re excited to announce that support for Google Private Service Connect is now generally available. Google Private Service Connect provides private connectivity from Google Cloud virtual private cloud (VPC) to Elastic Cloud deployments. The traffic between Google Cloud and Elastic Cloud deployments on Google Cloud travels only within the Google Cloud network, utilizing Private Service Connect endpoints and ensuring that customer data stays off the Internet. Read the <a href=\"/blog/secure-your-deployments-on-elastic-cloud-with-google-cloud-private-service-connect\">blog post</a> to learn more.\n</p> <strong><h3>ARM-based (Graviton2) instances on AWS&nbsp;</h3></strong><p>Soon, customers will be able to leverage Amazon Web Services (AWS) ARM-based Graviton2 virtual machines (VMs) for Elastic Cloud deployments running on AWS. VMs running on Graviton2 hardware provide up to 40% better price performance compared to previous generation x86-based instances. Check out the&nbsp;<a href=\"https://www.elastic.co/blog/new-aws-instance-types-on-elastic-cloud\">blog post</a>&nbsp;to learn more.</p> <strong><h2 id=\"elasticsearch\">What’s new in Elasticsearch 7.15</h2></strong> <strong><h3>Improved data resiliency and reduced data transfer traffic</h3></strong><p>Since the inception of Elasticsearch, we’ve been on a mission to be the best and fastest search engine around. To further this mission, we’ve <a href=\"/elasticsearch/elasticsearch-searchable-snapshots\">lowered the costs</a> of storing and searching data, <a href=\"/blog/a-new-era-for-cluster-coordination-in-elasticsearch\">improved cluster resiliency</a> and <a href=\"/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time\">search performance</a>, <a href=\"/blog/elasticsearch-7-7-0-released\">lowered memory heap usage</a>, <a href=\"/blog/save-space-and-money-with-improved-storage-efficiency-in-elasticsearch-7-10\">improved storage efficiency</a>, and introduced <a href=\"/blog/whats-new-elasticsearch-7-14-0\">faster aggregations</a> in <a href=\"/blog/how-we-made-date-histogram-aggregations-faster-than-ever-in-elasticsearch-7-11\">multiple</a> Elasticsearch <a href=\"/blog/new-in-elasticsearch-7-13-even-faster-aggregations\">releases</a>. In this release, we not only improve data resiliency but also reduce data transfer traffic — a change designed specifically to lower our customers’ Elastic Cloud bills.&nbsp;\n</p><p>\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/Uspe6FkqGYdYJqhiRC6EVv.jpg\" data-uuid=\"Uspe6FkqGYdYJqhiRC6EVv\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Improved data resiliency and reduced data transfer traffic with Elasticsearch\" style=\"width: 100%; margin: auto; display: block;\">\n</p><p>By <a href=\"https://github.com/elastic/elasticsearch/issues/73497\">compressing specific inter-node traffic</a> and using snapshot storage to shortcut relocating <a href=\"https://github.com/elastic/elasticsearch/issues/73496\">shards between nodes</a>, we have reduced the amount of network traffic that traverses across the cluster, resulting in a reduction in Data Transfer and Storage (DTS) cost. This change will be most prominent for Elastic Cloud customers with heavy indexing or data migration between tiers.&nbsp;\n</p> <strong><h3>New APIs to help optimize and improve Elasticsearch performance</h3></strong><p>The best decisions are always data driven. Three new experimental APIs in 7.15 give you the tools to help analyze how you are using Elasticsearch usage and ultimately drive improved performance.&nbsp;\n</p><p>The <a href=\"/guide/en/elasticsearch/reference/7.15/field-usage-stats.html\">field usage API</a> helps you decide how to index a <a href=\"/guide/en/elasticsearch/reference/7.15/mapping-types.html\">field</a> based on usage statistics. For example, if a field is used frequently, it should be created with schema on write or at ingest time by using a <a href=\"/guide/en/elasticsearch/reference/7.15/explicit-mapping.html\">mapping</a>. If the field is used infrequently, consider defining it at query time with <a href=\"/guide/en/elasticsearch/reference/7.15/runtime.html\">runtime fields</a>. Changing a text field with an <code>inverted_index.term_frequencies</code> of zero and low <code>inverted_index.positions</code> to <a href=\"/guide/en/elasticsearch/reference/7.15/text.html#match-only-text-field-type\"><code>match_only_text</code></a> (added in <a href=\"/blog/whats-new-elasticsearch-7-14-0\">7.14</a>) can <a href=\"/blog/save-10-percent-disk-space-on-your-logging-datasets-with-match-only-text\">save around 10% of disk</a>.\n</p><p>With the <a href=\"/guide/en/elasticsearch/reference/7.15/indices-disk-usage.html\">index disk usage API</a> you can see how much disk space is consumed by every field in your index. Knowing what fields take up disk, you can decide which indexing option or field type is best. For example, <a href=\"/guide/en/elasticsearch/reference/7.15/keyword.html\"><code>keyword</code></a> or <a href=\"/guide/en/elasticsearch/reference/7.15/text.html#match-only-text-field-type\"><code>match_only_text </code></a> may be better than <a href=\"/guide/en/elasticsearch/reference/7.15/text.html\"><code>text</code></a> for certain fields where scoring and positional information is not important. Or, use runtime fields to create a <code>keyword</code> at query time for flexibility and saving space.\n</p><p>Finally, the <a href=\"/guide/en/elasticsearch/reference/7.15/search-vector-tile-api.html\">vector tiles API</a> provides a huge performance and scalability improvement when searching geo_points and geo_shapes drawn to a map (through use of <a href=\"https://en.wikipedia.org/wiki/Vector_tiles\">vector tiles</a>). Offloading these calculations to the local GPU significantly improves performance while also lowering costs by reducing network traffic both within the cluster and to the client.&nbsp;\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt9e30423c748276df/614a8b52f725af79f53fd555/losangeles.gif\" data-sys-asset-uid=\"blt9e30423c748276df\" alt=\"losangeles.gif\" style=\"display: block; margin: auto;\">\n</p> <strong><h3>Composite runtime fields</h3></strong><p>Elastic 7.15 continues to evolve the implementation of <a href=\"https://www.elastic.co/elasticsearch/elasticsearch-runtime-fields?elektra=stack-and-cloud-7-15-blog\">runtime fields</a> in Elasticsearch and Kibana.&nbsp;\n</p><p>In Elasticsearch, composite runtime fields enable users to streamline field creation using one Painless script to emit multiple fields, with added efficiencies for field management. Use patterns like <a href=\"/guide/en/elasticsearch/reference/7.15/runtime-examples.html#runtime-examples-grok\">grok</a> or <a href=\"/guide/en/elasticsearch/reference/7.15/runtime-examples.html#runtime-examples-dissect\">dissect</a> to emit multiple fields using one script instead of creating and maintaining multiple scripts. Using existing grok patterns also makes it faster to create new runtime fields and reduces the time and complexity of creating and maintaining regex expressions. This development makes it easier and more intuitive for users to ingest new data like custom logs. See more on runtime fields in Kibana 7.15 below.\n</p> <strong><h2 id=\"kibana\">What’s new in Kibana 7.15</h2></strong> <strong><h3>Runtime fields editor preview pane</h3></strong><p>Combined with the introduction of composite fields for Elasticsearch (above), a new preview pane in the runtime fields editor in Kibana 7.15 makes it even easier to create fields on the fly. The preview pane empowers users to test and preview new fields before creating them — for example, by evaluating a new script against documents to check accuracy in Index Patterns, Discover, or Lens. In addition, pinning specific fields in the preview pane simplifies script creation. This enhancement also includes better error handling for the editor, all to help streamline the field creation process and allow users to create runtime fields more quickly. More developments for runtime fields are on the horizon as we continue to make previously ingested data easier to parse from Kibana.\n</p><div class=\"video embed-container\" style=\"height: 319.725px;\">\n\t<img class=\"vidyard-player-embed\" src=\"https://play.vidyard.com/2t7rLk7ZRn1QJhmVcYxsBp.jpg\" data-uuid=\"2t7rLk7ZRn1QJhmVcYxsBp\" data-v=\"4\" data-type=\"inline\" data-autoplay=\"1\" data-loop=\"1\" data-disable_analytics=\"1\" data-hidden_controls=\"1\" data-muted=\"1\" disable_analytics=\"1\" alt=\"Use the Kibana runtime fields editor preview pane to evaluate sample documents before creating a new field.\" style=\"width: 100%; margin: auto; display: block;\">\n</div><h2 id=\"stack-and-cloud-features\">Other updates across the Elastic Stack and Elastic Cloud</h2><h4>Elastic Cloud\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Leverage more cost-effective hardware options on GCP:</strong> Google Compute Engine’s (GCE) N2 VMs for Elastic Cloud deployments running on Google Cloud offer up to 20% better CPU performance compared to the previous generation N1 machine types. Learn more in the <a href=\"/blog/introducing-new-google-cloud-instance-types-on-elastic-cloud\">blog post</a>.</li>\n</ul><h4>Elasticsearch\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Build complex flows with API keys:</strong> Search and pagination for API keys allow you to build complex management flows for keys, based on your own metadata.</li>\n</ul><h4>Kibana\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Sync across time and (dashboard) space with your cursor:</strong> A new hover feature in Kibana charts that highlights corresponding data across multiple charts makes it easier for users to home in on specific time periods to observe and explore trends. In addition to time series, this will also highlight the same non-time data on multiple dashboard panels.</li>\n\t<li aria-level=\"1\"><strong>Customize charts with legend-ary updates:</strong> Legends inside charts (great for busy dashboards) and multi-line series names in legends make it easier for teams to follow the data story on a dashboard.</li>\n\t<li aria-level=\"1\"><strong>Get a head start on Maps exploration:</strong> Metadata for points and shapes is now auto-generated in Elastic Maps when a user creates an index and explores with edit tools. The user and timestamp data is saved for further exploration and management. Also, a new layer action allows users to view only the specific layer they are interested in.</li>\n\t<li aria-level=\"1\">Learn more in the <a href=\"/guide/en/kibana/7.15/whats-new.html?elektra=stack-and-cloud-7-15-blog\">Kibana docs</a>.</li>\n</ul><h4>Machine learning</h4><ul>\n\t<li aria-level=\"1\"><strong>Monitor machine learning jobs easily:</strong> Operational alerts for machine learning jobs simplify the process of managing machine learning jobs and models, and alerts in Kibana make it easier to track and follow up on errors.&nbsp;</li>\n\t<li aria-level=\"1\"><strong>Adjust and reset models without the fuss:</strong> The reset jobs API makes working with models much easier across Kibana, from the Logs app to Elastic Security.</li>\n\t<li aria-level=\"1\"><strong>Reuse and scale machine learning jobs:</strong> Jobs can now be imported and exported, allowing users to reuse jobs created in lab environments or in multiple-cluster environments. Sharing jobs across deployments makes jobs more consistent and easier to scale.</li>\n\t<li aria-level=\"1\"><strong>Investigate transaction latency:</strong> Elastic APM correlations, powered by machine learning, streamline root cause analysis. The Elasticsearch significant terms aggregation was enhanced with a p_value scoring heuristic, and Kibana’s new transaction investigation page for APM aids analysts in a holistic exploration of transaction data. To learn more, read the <a href=\"/blog/whats-new-elastic-observability-7-15-0\">Observability 7.15 blog</a>.</li>\n\t<li aria-level=\"1\">Learn more in the <a href=\"/guide/en/kibana/7.15/whats-new.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a> and <a href=\"/guide/en/elasticsearch/reference/7.15/release-highlights.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a> docs.</li>\n</ul><h4>Integrations\n</h4><ul>\n\t<li aria-level=\"1\"><strong>Run Elastic Package Registry (EPR) as a Docker image:</strong> now you can run your own EPR to provide information on external data sources to air-gapped environments. By using the EPR Docker image, you can integrate, collect and visualize data using Elastic Agents. For more information, <a href=\"/guide/en/integrations-developer/current/air-gapped.html?elektra=stack-and-cloud-7-15-blog\">please refer to this Elastic guide.</a></li>\n</ul> <strong><h2>Try it out</h2></strong><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/registration?blade=blog&gambit=stack-and-cloud-7-15-blog\">Elastic Cloud console</a>. If you’re new to Elastic Cloud, take a look at our <a href=\"/training/free#quick-starts?elektra=stack-and-cloud-7-15-blog\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or our <a href=\"https://www.elastic.co/training/free#fundamentals?elektra=stack-and-cloud-7-15-blog\">free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?blade=blog&gambit=stack-and-cloud-7-15-blog\">free 14-day trial of Elastic Cloud</a>. Or <a href=\"/downloads?elektra=stack-and-cloud-7-15-blog\">download</a> the self-managed version of the Elastic Stack for free.\n</p><p>Read about these capabilities and more in the 7.15 release notes (<a href=\"/guide/en/elasticsearch/reference/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Elasticsearch</a>, <a href=\"/guide/en/kibana/7.15/release-notes-7.15.0.html?elektra=stack-and-cloud-7-15-blog\">Kibana</a>, <a href=\"/guide/en/cloud/current/ec-release-notes.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud</a>, <a href=\"/guide/en/cloud-enterprise/current/ece-release-notes-2.12.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud Enterprise</a>, <a href=\"/guide/en/cloud-on-k8s/1.8/release-notes-1.8.0.html?elektra=stack-and-cloud-7-15-blog\">Elastic Cloud on Kubernetes</a>), and other Elastic 7.15 highlights in the <a href=\"/blog/whats-new-elastic-7-15-0\">Elastic 7.15 announcement post</a>.\n</p><p><i>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.\n\t</i>\n</p>","PublishedAt":"2021-09-22 16:02:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elasticsearch-kibana-cloud-7-15-0","SourceName":"Elastic"}},{"node":{"ID":69,"Title":"Elastic Observability 7.15: Automated correlations, frictionless log ingestion from Google Cloud","Description":"<p>Elastic Observability 7.15 introduces the general availability of automated correlations, unified views across application service logs and dependencies, and agentless log ingestion from Google Cloud Platform (GCP), accelerating troubleshooting of root causes of application issues and making it even easier to ingest telemetry from cloud services.&nbsp;\n</p><p>These new features allow customers to:\n</p><ul>\n\t<li>Automatically surface attributes of the APM data set that are correlated with high-latency or erroneous transactions</li>\n\t<li>Effortlessly troubleshoot application issues by viewing all associated application or service logs from within the APM user interface&nbsp;</li>\n\t<li>Seamlessly ingest log data into Elastic from within the Google Cloud console and extend monitoring to native Google Cloud services</li>\n</ul><p>Elastic Observability 7.15 is <a href=\"https://cloud.elastic.co/registration?elektra=whats-new-elastic-7-13-blog\" target=\"_blank\">available now on Elastic Cloud</a> — the only hosted Elasticsearch offering to include all of the new features in this latest release. You can also <a href=\"https://www.elastic.co/downloads/\" target=\"_blank\">download the Elastic Stack</a> and our cloud orchestration products, Elastic Cloud Enterprise and Elastic Cloud for Kubernetes, for a self-managed experience.\n</p><h2>Automated root cause analysis with APM correlations is now GA\n</h2><p>DevOps and SRE teams are constantly challenged with an overwhelming amount of data and dependencies to sift through to keep modern applications performant and error-free. As such, automation and machine learning have become essential components of the troubleshooter’s toolkit. <a href=\"https://www.elastic.co/guide/en/kibana/7.15/correlations.html\" target=\"_blank\">Elastic APM correlations</a> accelerate root cause analysis by automatically surfacing attributes of the APM data set (such as infrastructure components, versions, locations, and custom metadata) that are correlated with high-latency or erroneous transactions and have the most significant impact on overall service performance. Visualize the latency distribution of any attribute compared to overall latency and use these attributes to filter and isolate the root causes of performance problems.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt27dff0e7a27e4f81/61423a368440e97ef5826acf/animation-apm-latency-correlations.gif\" data-sys-asset-uid=\"blt27dff0e7a27e4f81\" alt=\"animation-apm-latency-correlations.gif\">\n</p><h2>Unified observability for APM troubleshooting across logs, third-party dependencies, and backend services\n</h2><p>Elastic is the only observability solution built on a search platform that natively ingests high dimensionality and cardinality telemetry data of any type or source, adds context, and correlates it for fast, relevant analysis. Over the last twelve months we have reworked almost the entire user experience within the APM user interface&nbsp;and&nbsp;will continue to deliver visualization and workflow improvements for unified visibility and analysis across the entire application ecosystem.&nbsp;\n</p><p>Two new troubleshooting views have been added in 7.15.&nbsp;Logs are now&nbsp;available on any level, at the top level for the service, as well as at&nbsp;the level of&nbsp;specific transactions&nbsp;and&nbsp;container or pod instances. We're now also able to&nbsp;show external dependencies, such as&nbsp;backends, caches, and databases, including how they are&nbsp;performing, their upstream dependencies, and how they have&nbsp;changed over time.\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltf180dffa4d9ce8db/61423a4c564bf37c154f77c9/screenshot-apm-service-logs.png\" data-sys-asset-uid=\"bltf180dffa4d9ce8db\" alt=\"screenshot-apm-service-logs.png\" \"=\"\">\n</p><figcaption>Get an integrated roll-up view of application logs across application services running on ephemeral infrastructure to quickly find errors and other causes of application issues.</figcaption><p><em><br></em>\n</p><p><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltec7d31bd64c02a0d/61423a679d27cf7da4ba02a9/screenshot-dependencies-redis.png\" data-sys-asset-uid=\"bltec7d31bd64c02a0d\" alt=\"screenshot-dependencies-redis.png\"><br>\n</p><figcaption>Identify issues with third-party and backend service dependencies, and leverage detailed drilldowns for comparing historical performance and impact on&nbsp;upstream services.</figcaption><p><span style=\"background-color: initial;\"></span><span style=\"background-color: initial;\">We’ve also enhanced the existing transaction latency distribution chart and trace selection with more granular buckets and the flexibility to drag-select all application traces that fall within a desired range of latencies.</span>\n</p><h2>Agentless ingestion of logs from Google Cloud Platform (GCP) for frictionless observability&nbsp;&nbsp;\n</h2><p>Elastic’s new GCP Dataflow integration drives efficiency with frictionless ingestion of log data directly from the Google Cloud console. The agentless approach provides an “easy button” option for customers who want to avoid the cost and hassle of managing and maintaining agents, and further extends monitoring to native GCP services.&nbsp;\n</p><p style=\"text-align: center;\"><img src=\"https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/bltb459bb911fdbaf61/6148be340332d478b9d30bd0/blog-gcp-integration-pubsub-1.png\" data-sys-asset-uid=\"bltb459bb911fdbaf61\" alt=\"blog-gcp-integration-pubsub-1.png\" \"=\"\"><br>\n\n</p><figcaption>The Google and Elastic teams worked together to develop an out-of-the-box Dataflow template that a user can select to push logs and events from Pub/Sub to Elastic.</figcaption><h2>Additional data sources: JVM metrics support for JRuby, Azure Spring Cloud logs integration, and Osquery metrics in host details panel</h2><p>With the 7.15 release, we have&nbsp;also enhanced our application and cloud data collection for JRuby and Azure. Now you can get visibility into system and JVM metrics for JRuby applications and continuously monitor and quickly debug issues encountered in Spring boot applications running on Azure (beta).&nbsp;\n</p><p>Osquery provides a flexible and powerful way to collect any data from a target host it's installed on.&nbsp;The Osquery integration&nbsp;with the&nbsp;Elastic Agent,&nbsp;introduced in 7.13,&nbsp;opened&nbsp;up a spectrum of capabilities to support troubleshooting of security and observability use cases. Previously,&nbsp;Osquery could&nbsp;be used via Kibana to perform live and scheduled queries, with the query results stored in a dedicated data stream. With 7.15, Osquery is now directly integrated into the enhanced host details panel and delivers&nbsp;ad hoc querying capabilities on the target host.\n</p><h2>Self-managed version of Elastic Package Registry (EPR) now available for air-gapped deployments</h2><p>If you host your Elastic Stack in an air-gapped environment and want to take advantage of the recently GA <a href=\"https://www.elastic.co/blog/elastic-agent-and-fleet-make-it-easier-to-integrate-your-systems-with-elastic\" target=\"_blank\">Elastic Agent and Fleet</a>, we have good news for you. Elastic Package Registry (EPR) is now available as a Docker image that can be run and hosted in any infrastructure setting of your choice.&nbsp;In environments where&nbsp;network traffic restrictions are mandatory&nbsp;deploying your own instance of EPR enables&nbsp;Kibana to download package metadata and content in order to&nbsp;access&nbsp;all available integrations and deliver the relevant out-of-box components and documentation. Currently, the EPR Docker image is a beta&nbsp;standalone server that will continue to grow and evolve. For more information, check out the Elastic guide for <a href=\"https://www.elastic.co/guide/en/integrations-developer/current/air-gapped.html\" target=\"_blank\">running EPR in air-gapped environments</a>.&nbsp;\n</p><h2>Try it out\n</h2><p>Existing Elastic Cloud customers can access many of these features directly from the <a href=\"https://cloud.elastic.co/\" target=\"_blank\">Elastic Cloud console</a>, or, if you'd prefer, you can <a href=\"https://www.elastic.co/downloads/\" target=\"_blank\">download</a> the latest version.\n</p><p>If you’re new to Elastic Cloud, take a look at our <a href=\"https://www.elastic.co/training/free#quick-starts\" target=\"_blank\">Quick Start guides</a> (bite-sized training videos to get you started quickly) or <a href=\"https://www.elastic.co/training/free#fundamentals\" target=\"_blank\">our free fundamentals training courses</a>. You can always get started for free with a <a href=\"http://cloud.elastic.co/registration?blade=blog&gambit=whats-new-enterprise-search-7-12\" target=\"_blank\">free 14-day trial of Elastic Cloud</a>.&nbsp;\n</p><p>Read about these capabilities and more in the <a href=\"https://www.elastic.co/guide/en/observability/7.15/whats-new.html\" target=\"_blank\">Elastic Observability 7.15 release notes</a>, and other Elastic Stack highlights in the <a href=\"https://www.elastic.co/blog/whats-new-elastic-7-15-0\" target=\"_blank\">Elastic 7.15 announcement post</a>.\n</p><p><em>The release and timing of any features or functionality described in this post remain at Elastic's sole discretion. Any features or functionality not currently available may not be delivered on time or at all.&nbsp;</em>\n</p>","PublishedAt":"2021-09-22 16:01:00+00:00","OriginURL":"https://www.elastic.co/blog/whats-new-elastic-observability-7-15-0","SourceName":"Elastic"}},{"node":{"ID":785,"Title":"Service Architecture at SoundCloud — Part 3: Domain Gateways","Description":"This article is the last part in a series of posts aiming to cast some light onto how service architecture has evolved at SoundCloud over…","PublishedAt":"2021-09-17 00:00:00+00:00","OriginURL":"https://developers.soundcloud.com/blog/service-architecture-3","SourceName":"Soundcloud"}},{"node":{"ID":770,"Title":"YAML Generator for Funnel YAML Files: Streamlining the Mobile Data Workflow Process","Description":"<p><span style=\"font-weight: 400;\">At Uber, real-time mobile analytics events—generated by button taps, page views, and more—form the backbone of the mobile data workflow process.</span></p>\n<p><span style=\"font-weight: 400;\">To process these events, our Mobile Data Platform Team designed and developed the Fontana library, which converts the nearly-one-million-QPS </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/streamlining-mobile-data-workflow-process/\">YAML Generator for Funnel YAML Files: Streamlining the Mobile Data Workflow Process</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-16 16:00:32+00:00","OriginURL":"https://eng.uber.com/streamlining-mobile-data-workflow-process/","SourceName":"Uber"}},{"node":{"ID":129,"Title":"Solving Cumulative Layout Shifts At Scale","Description":"","PublishedAt":"2021-09-16 10:50:08+00:00","OriginURL":"https://medium.com/engineering-housing/solving-cumulative-layout-shifts-at-scale-e91f0d3b3be4?source=rss----3a69e32e2594---4","SourceName":"Housing.com"}},{"node":{"ID":1271,"Title":"Paying technical debt in the front-end","Description":"","PublishedAt":"2021-09-16 08:30:14+00:00","OriginURL":"https://medium.com/miro-engineering/paying-technical-debt-in-the-front-end-8666ef0c32d1?source=rss----555f7fd62a50---4","SourceName":"Miro Engineering"}},{"node":{"ID":475,"Title":"Product analytics for health tech","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/09/MetricsThatMatter_Design@2x-1024x576.png\" class=\"type:primaryImage\" /></figure>\n<p>Health tech represents a new way to address everything from personal mental health to the inefficiencies of the healthcare system.&#160; But, without the right level of insight, health tech companies may be overcome by the challenges of growing a niche solution—namely, retaining an engaged user base for a delicate use case.&#160; Our guiding question: How</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/metrics-that-matter-product-analytics-for-the-up-and-coming-health-tech-sector/\">Product analytics for health tech</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-09-14 18:22:00+00:00","OriginURL":"https://mixpanel.com/blog/metrics-that-matter-product-analytics-for-the-up-and-coming-health-tech-sector/","SourceName":"Mixpanel"}},{"node":{"ID":1255,"Title":"Blog: Introducing Single Pod Access Mode for PersistentVolumes","Description":"<p><strong>Author:</strong> Chris Henzie (Google)</p>\n<p>Last month's release of Kubernetes v1.22 introduced a new ReadWriteOncePod access mode for <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes\">PersistentVolumes</a> and <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaims</a>.\nWith this alpha feature, Kubernetes allows you to restrict volume access to a single pod in the cluster.</p>\n<h2 id=\"what-are-access-modes-and-why-are-they-important\">What are access modes and why are they important?</h2>\n<p>When using storage, there are different ways to model how that storage is consumed.</p>\n<p>For example, a storage system like a network file share can have many users all reading and writing data simultaneously.\nIn other cases maybe everyone is allowed to read data but not write it.\nFor highly sensitive data, maybe only one user is allowed to read and write data but nobody else.</p>\n<p>In the world of Kubernetes, <a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes\">access modes</a> are the way you can define how durable storage is consumed.\nThese access modes are a part of the spec for PersistentVolumes (PVs) and PersistentVolumeClaims (PVCs).</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>shared-cache<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteMany<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Allow many nodes to access shared-cache simultaneously.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Before v1.22, Kubernetes offered three access modes for PVs and PVCs:</p>\n<ul>\n<li>ReadWriteOnce – the volume can be mounted as read-write by a single node</li>\n<li>ReadOnlyMany – the volume can be mounted read-only by many nodes</li>\n<li>ReadWriteMany – the volume can be mounted as read-write by many nodes</li>\n</ul>\n<p>These access modes are enforced by Kubernetes components like the <code>kube-controller-manager</code> and <code>kubelet</code> to ensure only certain pods are allowed to access a given PersistentVolume.</p>\n<h2 id=\"what-is-this-new-access-mode-and-how-does-it-work\">What is this new access mode and how does it work?</h2>\n<p>Kubernetes v1.22 introduced a fourth access mode for PVs and PVCs, that you can use for CSI volumes:</p>\n<ul>\n<li>ReadWriteOncePod – the volume can be mounted as read-write by a single pod</li>\n</ul>\n<p>If you create a pod with a PVC that uses the ReadWriteOncePod access mode, Kubernetes ensures that pod is the only pod across your whole cluster that can read that PVC or write to it.</p>\n<p>If you create another pod that references the same PVC with this access mode, the pod will fail to start because the PVC is already in use by another pod.\nFor example:</p>\n<pre tabindex=\"0\"><code>Events:\nType Reason Age From Message\n---- ------ ---- ---- -------\nWarning FailedScheduling 1s default-scheduler 0/1 nodes are available: 1 node has pod using PersistentVolumeClaim with the same name and ReadWriteOncePod access mode.\n</code></pre><h3 id=\"how-is-this-different-than-the-readwriteonce-access-mode\">How is this different than the ReadWriteOnce access mode?</h3>\n<p>The ReadWriteOnce access mode restricts volume access to a single <em>node</em>, which means it is possible for multiple pods on the same node to read from and write to the same volume.\nThis could potentially be a major problem for some applications, especially if they require at most one writer for data safety guarantees.</p>\n<p>With ReadWriteOncePod these issues go away.\nSet the access mode on your PVC, and Kubernetes guarantees that only a single pod has access.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>The ReadWriteOncePod access mode is in alpha for Kubernetes v1.22 and is only supported for CSI volumes.\nAs a first step you need to enable the ReadWriteOncePod <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates\">feature gate</a> for <code>kube-apiserver</code>, <code>kube-scheduler</code>, and <code>kubelet</code>.\nYou can enable the feature by setting command line arguments:</p>\n<pre tabindex=\"0\"><code>--feature-gates=&#34;...,ReadWriteOncePod=true&#34;\n</code></pre><p>You also need to update the following CSI sidecars to these versions or greater:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/releases/tag/v3.0.0\">csi-provisioner:v3.0.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-attacher/releases/tag/v3.3.0\">csi-attacher:v3.3.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-resizer/releases/tag/v1.3.0\">csi-resizer:v1.3.0+</a></li>\n</ul>\n<h3 id=\"creating-a-persistentvolumeclaim\">Creating a PersistentVolumeClaim</h3>\n<p>In order to use the ReadWriteOncePod access mode for your PVs and PVCs, you will need to create a new PVC with the access mode:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>single-writer-only<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOncePod<span style=\"color:#bbb\"> </span><span style=\"color:#080;font-style:italic\"># Allow only a single pod to access single-writer-only.</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>1Gi<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>If your storage plugin supports <a href=\"https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/\">dynamic provisioning</a>, new PersistentVolumes will be created with the ReadWriteOncePod access mode applied.</p>\n<h4 id=\"migrating-existing-persistentvolumes\">Migrating existing PersistentVolumes</h4>\n<p>If you have existing PersistentVolumes, they can be migrated to use ReadWriteOncePod.</p>\n<p>In this example, we already have a &quot;cat-pictures-pvc&quot; PersistentVolumeClaim that is bound to a &quot;cat-pictures-pv&quot; PersistentVolume, and a &quot;cat-pictures-writer&quot; Deployment that uses this PersistentVolumeClaim.</p>\n<p>As a first step, you need to edit your PersistentVolume's <code>spec.persistentVolumeReclaimPolicy</code> and set it to <code>Retain</code>.\nThis ensures your PersistentVolume will not be deleted when we delete the corresponding PersistentVolumeClaim:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Retain&#34;}}&#39;</span>\n</span></span></code></pre></div><p>Next you need to stop any workloads that are using the PersistentVolumeClaim bound to the PersistentVolume you want to migrate, and then delete the PersistentVolumeClaim.</p>\n<p>Once that is done, you need to clear your PersistentVolume's <code>spec.claimRef.uid</code> to ensure PersistentVolumeClaims can bind to it upon recreation:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl scale --replicas<span style=\"color:#666\">=</span><span style=\"color:#666\">0</span> deployment cat-pictures-writer\n</span></span><span style=\"display:flex;\"><span>kubectl delete pvc cat-pictures-pvc\n</span></span><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;claimRef&#34;:{&#34;uid&#34;:&#34;&#34;}}}&#39;</span>\n</span></span></code></pre></div><p>After that you need to replace the PersistentVolume's access modes with ReadWriteOncePod:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;accessModes&#34;:[&#34;ReadWriteOncePod&#34;]}}&#39;</span>\n</span></span></code></pre></div><div class=\"alert alert-info note callout\" role=\"alert\">\n<strong>Note:</strong> The ReadWriteOncePod access mode cannot be combined with other access modes.\nMake sure ReadWriteOncePod is the only access mode on the PersistentVolume when updating, otherwise the request will fail.\n</div>\n<p>Next you need to modify your PersistentVolumeClaim to set ReadWriteOncePod as the only access mode.\nYou should also set your PersistentVolumeClaim's <code>spec.volumeName</code> to the name of your PersistentVolume.</p>\n<p>Once this is done, you can recreate your PersistentVolumeClaim and start up your workloads:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># IMPORTANT: Make sure to edit your PVC in cat-pictures-pvc.yaml before applying. You need to:</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># - Set ReadWriteOncePod as the only access mode</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#080;font-style:italic\"># - Set spec.volumeName to &#34;cat-pictures-pv&#34;</span>\n</span></span><span style=\"display:flex;\"><span>\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f cat-pictures-pvc.yaml\n</span></span><span style=\"display:flex;\"><span>kubectl apply -f cat-pictures-writer-deployment.yaml\n</span></span></code></pre></div><p>Lastly you may edit your PersistentVolume's <code>spec.persistentVolumeReclaimPolicy</code> and set to it back to <code>Delete</code> if you previously changed it.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-shell\" data-lang=\"shell\"><span style=\"display:flex;\"><span>kubectl patch pv cat-pictures-pv -p <span style=\"color:#b44\">&#39;{&#34;spec&#34;:{&#34;persistentVolumeReclaimPolicy&#34;:&#34;Delete&#34;}}&#39;</span>\n</span></span></code></pre></div><p>You can read <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/\">Configure a Pod to Use a PersistentVolume for Storage</a> for more details on working with PersistentVolumes and PersistentVolumeClaims.</p>\n<h2 id=\"what-volume-plugins-support-this\">What volume plugins support this?</h2>\n<p>The only volume plugins that support this are CSI drivers.\nSIG Storage does not plan to support this for in-tree plugins because they are being deprecated as part of <a href=\"https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/#what-is-the-timeline-status\">CSI migration</a>.\nSupport may be considered for beta for users that prefer to use the legacy in-tree volume APIs with CSI migration enabled.</p>\n<h2 id=\"as-a-storage-vendor-how-do-i-add-support-for-this-access-mode-to-my-csi-driver\">As a storage vendor, how do I add support for this access mode to my CSI driver?</h2>\n<p>The ReadWriteOncePod access mode will work out of the box without any required updates to CSI drivers, but <a href=\"#update-your-csi-sidecars\">does require updates to CSI sidecars</a>.\nWith that being said, if you would like to stay up to date with the latest changes to the CSI specification (v1.5.0+), read on.</p>\n<p>Two new access modes were introduced to the CSI specification in order to disambiguate the legacy <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L418-L420\"><code>SINGLE_NODE_WRITER</code></a> access mode.\nThey are <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L437-L447\"><code>SINGLE_NODE_SINGLE_WRITER</code> and <code>SINGLE_NODE_MULTI_WRITER</code></a>.\nIn order to communicate to sidecars (like the <a href=\"https://github.com/kubernetes-csi/external-provisioner\">external-provisioner</a>) that your driver understands and accepts these two new CSI access modes, your driver will also need to advertise the <code>SINGLE_NODE_MULTI_WRITER</code> capability for the <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L1073-L1081\">controller service</a> and <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/csi.proto#L1515-L1524\">node service</a>.</p>\n<p>If you'd like to read up on the motivation for these access modes and capability bits, you can also read the <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/2485-read-write-once-pod-pv-access-mode/README.md#csi-specification-changes-volume-capabilities\">CSI Specification Changes, Volume Capabilities</a> section of KEP-2485 (ReadWriteOncePod PersistentVolume Access Mode).</p>\n<h3 id=\"update-your-csi-driver-to-use-the-new-interface\">Update your CSI driver to use the new interface</h3>\n<p>As a first step you will need to update your driver's <code>container-storage-interface</code> dependency to v1.5.0+, which contains support for these new access modes and capabilities.</p>\n<h3 id=\"accept-new-csi-access-modes\">Accept new CSI access modes</h3>\n<p>If your CSI driver contains logic for validating CSI access modes for requests , it may need updating.\nIf it currently accepts <code>SINGLE_NODE_WRITER</code>, it should be updated to also accept <code>SINGLE_NODE_SINGLE_WRITER</code> and <code>SINGLE_NODE_MULTI_WRITER</code>.</p>\n<p>Using the <a href=\"https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/blob/v1.2.2/pkg/gce-pd-csi-driver/utils.go#L116-L130\">GCP PD CSI driver validation logic</a> as an example, here is how it can be extended:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-diff\" data-lang=\"diff\"><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">diff --git a/pkg/gce-pd-csi-driver/utils.go b/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">index 281242c..b6c5229 100644\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\"></span><span style=\"color:#a00000\">--- a/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#a00000\"></span><span style=\"color:#00a000\">+++ b/pkg/gce-pd-csi-driver/utils.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span><span style=\"color:#800080;font-weight:bold\">@@ -123,6 +123,8 @@ func validateAccessMode(am *csi.VolumeCapability_AccessMode) error {\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> case csi.VolumeCapability_AccessMode_SINGLE_NODE_READER_ONLY:\n</span></span><span style=\"display:flex;\"><span> case csi.VolumeCapability_AccessMode_MULTI_NODE_READER_ONLY:\n</span></span><span style=\"display:flex;\"><span> case csi.VolumeCapability_AccessMode_MULTI_NODE_MULTI_WRITER:\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ case csi.VolumeCapability_AccessMode_SINGLE_NODE_SINGLE_WRITER:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ case csi.VolumeCapability_AccessMode_SINGLE_NODE_MULTI_WRITER:\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> default:\n</span></span><span style=\"display:flex;\"><span> return fmt.Errorf(&#34;%v access mode is not supported for for PD&#34;, am.GetMode())\n</span></span><span style=\"display:flex;\"><span> }\n</span></span></code></pre></div><h3 id=\"advertise-new-csi-controller-and-node-service-capabilities\">Advertise new CSI controller and node service capabilities</h3>\n<p>Your CSI driver will also need to return the new <code>SINGLE_NODE_MULTI_WRITER</code> capability as part of the <code>ControllerGetCapabilities</code> and <code>NodeGetCapabilities</code> RPCs.</p>\n<p>Using the <a href=\"https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver/blob/v1.2.2/pkg/gce-pd-csi-driver/gce-pd-driver.go#L54-L77\">GCP PD CSI driver capability advertisement logic</a> as an example, here is how it can be extended:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-diff\" data-lang=\"diff\"><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">diff --git a/pkg/gce-pd-csi-driver/gce-pd-driver.go b/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\">index 45903f3..0d7ea26 100644\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#000080;font-weight:bold\"></span><span style=\"color:#a00000\">--- a/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#a00000\"></span><span style=\"color:#00a000\">+++ b/pkg/gce-pd-csi-driver/gce-pd-driver.go\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span><span style=\"color:#800080;font-weight:bold\">@@ -56,6 +56,8 @@ func (gceDriver *GCEDriver) SetupGCEDriver(name, vendorVersion string, extraVolu\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> csi.VolumeCapability_AccessMode_SINGLE_NODE_WRITER,\n</span></span><span style=\"display:flex;\"><span> csi.VolumeCapability_AccessMode_MULTI_NODE_READER_ONLY,\n</span></span><span style=\"display:flex;\"><span> csi.VolumeCapability_AccessMode_MULTI_NODE_MULTI_WRITER,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.VolumeCapability_AccessMode_SINGLE_NODE_SINGLE_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.VolumeCapability_AccessMode_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddVolumeCapabilityAccessModes(vcam)\n</span></span><span style=\"display:flex;\"><span> csc := []csi.ControllerServiceCapability_RPC_Type{\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\">@@ -67,12 +69,14 @@ func (gceDriver *GCEDriver) SetupGCEDriver(name, vendorVersion string, extraVolu\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#800080;font-weight:bold\"></span> csi.ControllerServiceCapability_RPC_EXPAND_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.ControllerServiceCapability_RPC_LIST_VOLUMES,\n</span></span><span style=\"display:flex;\"><span> csi.ControllerServiceCapability_RPC_LIST_VOLUMES_PUBLISHED_NODES,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.ControllerServiceCapability_RPC_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddControllerServiceCapabilities(csc)\n</span></span><span style=\"display:flex;\"><span> ns := []csi.NodeServiceCapability_RPC_Type{\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_STAGE_UNSTAGE_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_EXPAND_VOLUME,\n</span></span><span style=\"display:flex;\"><span> csi.NodeServiceCapability_RPC_GET_VOLUME_STATS,\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\">+ csi.NodeServiceCapability_RPC_SINGLE_NODE_MULTI_WRITER,\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#00a000\"></span> }\n</span></span><span style=\"display:flex;\"><span> gceDriver.AddNodeServiceCapabilities(ns)\n</span></span></code></pre></div><h3 id=\"implement-nodepublishvolume-behavior\">Implement <code>NodePublishVolume</code> behavior</h3>\n<p>The CSI spec outlines expected behavior for the <code>NodePublishVolume</code> RPC when called more than once for the same volume but with different arguments (like the target path).\nPlease refer to <a href=\"https://github.com/container-storage-interface/spec/blob/v1.5.0/spec.md#nodepublishvolume\">the second table in the NodePublishVolume section of the CSI spec</a> for more details on expected behavior when implementing in your driver.</p>\n<h3 id=\"update-your-csi-sidecars\">Update your CSI sidecars</h3>\n<p>When deploying your CSI drivers, you must update the following CSI sidecars to versions that depend on CSI spec v1.5.0+ and the Kubernetes v1.22 API.\nThe minimum required versions are:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes-csi/external-provisioner/releases/tag/v3.0.0\">csi-provisioner:v3.0.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-attacher/releases/tag/v3.3.0\">csi-attacher:v3.3.0+</a></li>\n<li><a href=\"https://github.com/kubernetes-csi/external-resizer/releases/tag/v1.3.0\">csi-resizer:v1.3.0+</a></li>\n</ul>\n<h2 id=\"what-s-next\">What’s next?</h2>\n<p>As part of the beta graduation for this feature, SIG Storage plans to update the Kubernetes scheduler to support pod preemption in relation to ReadWriteOncePod storage.\nThis means if two pods request a PersistentVolumeClaim with ReadWriteOncePod, the pod with highest priority will gain access to the PersistentVolumeClaim and any pod with lower priority will be preempted from the node and be unable to access the PersistentVolumeClaim.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>Please see <a href=\"https://github.com/kubernetes/enhancements/blob/master/keps/sig-storage/2485-read-write-once-pod-pv-access-mode/README.md\">KEP-2485</a> for more details on the ReadWriteOncePod access mode and motivations for CSI spec changes.</p>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>The <a href=\"https://kubernetes.slack.com/messages/csi\">Kubernetes #csi Slack channel</a> and any of the <a href=\"https://github.com/kubernetes/community/blob/master/sig-storage/README.md#contact\">standard SIG Storage communication channels</a> are great mediums to reach out to the SIG Storage and the CSI teams.</p>\n<p>Special thanks to the following people for their insightful reviews and design considerations:</p>\n<ul>\n<li>Abdullah Gharaibeh (ahg-g)</li>\n<li>Aldo Culquicondor (alculquicondor)</li>\n<li>Ben Swartzlander (bswartz)</li>\n<li>Deep Debroy (ddebroy)</li>\n<li>Hemant Kumar (gnufied)</li>\n<li>Humble Devassy Chirammal (humblec)</li>\n<li>James DeFelice (jdef)</li>\n<li>Jan Šafránek (jsafrane)</li>\n<li>Jing Xu (jingxu97)</li>\n<li>Jordan Liggitt (liggitt)</li>\n<li>Michelle Au (msau42)</li>\n<li>Saad Ali (saad-ali)</li>\n<li>Tim Hockin (thockin)</li>\n<li>Xing Yang (xing-yang)</li>\n</ul>\n<p>If you’re interested in getting involved with the design and development of CSI or any part of the Kubernetes storage system, join the <a href=\"https://github.com/kubernetes/community/tree/master/sig-storage\">Kubernetes Storage Special Interest Group</a> (SIG).\nWe’re rapidly growing and always welcome new contributors.</p>","PublishedAt":"2021-09-13 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/13/read-write-once-pod-access-mode-alpha/","SourceName":"Kubernetes"}},{"node":{"ID":771,"Title":"Jellyfish: Cost-Effective Data Tiering for Uber’s Largest Storage System","Description":"<h1><span style=\"font-weight: 400;\">Problem</span></h1>\n<p><span style=\"font-weight: 400;\">Uber deploys a few storage technologies to store business data based on their application model. One such technology is called </span><a href=\"https://eng.uber.com/schemaless-part-one-mysql-datastore/\"><span style=\"font-weight: 400;\">Schemaless</span></a><span style=\"font-weight: 400;\">, which enables the modeling of related entries in one single row of multiple columns, as well as </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/jellyfish-cost-effective-data-tiering/\">Jellyfish: Cost-Effective Data Tiering for Uber’s Largest Storage System</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-09 16:00:19+00:00","OriginURL":"https://eng.uber.com/jellyfish-cost-effective-data-tiering/","SourceName":"Uber"}},{"node":{"ID":398,"Title":"Red Means Stop. Green Means Go: A Look into Quality Assessment in Instacart’s Knowledge Graph","Description":"","PublishedAt":"2021-09-08 19:35:43+00:00","OriginURL":"https://tech.instacart.com/red-means-stop-green-means-go-a-look-into-quality-assessment-in-instacarts-knowledge-graph-9ceeb3f1be24?source=rss----587883b5d2ee---4","SourceName":"Instacart"}},{"node":{"ID":85,"Title":"3 Guidelines to Reduce Implementation Flaws","Description":"","PublishedAt":"2021-09-03 17:06:05+00:00","OriginURL":"https://medium.com/groupon-eng/3-guidelines-to-reduce-implementation-flaws-958511e2a82f?source=rss----5c13a88f9872---4","SourceName":"Groupon"}},{"node":{"ID":1256,"Title":"Blog: Alpha in Kubernetes v1.22: API Server Tracing","Description":"<p><strong>Authors:</strong> David Ashpole (Google)</p>\n<p>In distributed systems, it can be hard to figure out where problems are. You grep through one component's logs just to discover that the source of your problem is in another component. You search there only to discover that you need to enable debug logs to figure out what really went wrong... And it goes on. The more complex the path your request takes, the harder it is to answer questions about where it went. I've personally spent many hours doing this dance with a variety of Kubernetes components. Distributed tracing is a tool which is designed to help in these situations, and the Kubernetes API Server is, perhaps, the most important Kubernetes component to be able to debug. At Kubernetes' Sig Instrumentation, our mission is to make it easier to understand what's going on in your cluster, and we are happy to announce that distributed tracing in the Kubernetes API Server reached alpha in 1.22.</p>\n<h2 id=\"what-is-tracing\">What is Tracing?</h2>\n<p>Distributed tracing links together a bunch of super-detailed information from multiple different sources, and structures that telemetry into a single tree for that request. Unlike logging, which limits the quantity of data ingested by using log levels, tracing collects all of the details and uses sampling to collect only a small percentage of requests. This means that once you have a trace which demonstrates an issue, you should have all the information you need to root-cause the problem--no grepping for object UID required! My favorite aspect, though, is how useful the visualizations of traces are. Even if you don't understand the inner workings of the API Server, or don't have a clue what an etcd &quot;Transaction&quot; is, I'd wager you (yes, you!) could tell me roughly what the order of events was, and which components were involved in the request. If some step takes a long time, it is easy to tell where the problem is.</p>\n<h2 id=\"why-opentelemetry\">Why OpenTelemetry?</h2>\n<p>It's important that Kubernetes works well for everyone, regardless of who manages your infrastructure, or which vendors you choose to integrate with. That is particularly true for Kubernetes' integrations with telemetry solutions. OpenTelemetry, being a CNCF project, shares these core values, and is creating exactly what we need in Kubernetes: A set of open standards for Tracing client library APIs and a standard trace format. By using OpenTelemetry, we can ensure users have the freedom to choose their backend, and ensure vendors have a level playing field. The timing couldn't be better: the OpenTelemetry golang API and SDK are very close to their 1.0 release, and will soon offer backwards-compatibility for these open standards.</p>\n<h2 id=\"why-instrument-the-api-server\">Why instrument the API Server?</h2>\n<p>The Kubernetes API Server is a great candidate for tracing for a few reasons:</p>\n<ul>\n<li>It follows the standard &quot;RPC&quot; model (serve a request by making requests to downstream components), which makes it easy to instrument.</li>\n<li>Users are latency-sensitive: If a request takes more than 10 seconds to complete, many clients will time-out.</li>\n<li>It has a complex service topology: A single request could require consulting a dozen webhooks, or involve multiple requests to etcd.</li>\n</ul>\n<h2 id=\"trying-out-apiserver-tracing-with-a-webhook\">Trying out APIServer Tracing with a webhook</h2>\n<h3 id=\"enabling-api-server-tracing\">Enabling API Server Tracing</h3>\n<ol>\n<li>\n<p>Enable the APIServerTracing <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">feature-gate</a>.</p>\n</li>\n<li>\n<p>Set our configuration for tracing by pointing the <code>--tracing-config-file</code> flag on the kube-apiserver at our config file, which contains:</p>\n</li>\n</ol>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>apiserver.config.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>TracingConfiguration<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#080;font-style:italic\"># 1% sampling rate</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">samplingRatePerMillion</span>:<span style=\"color:#bbb\"> </span><span style=\"color:#666\">10000</span><span style=\"color:#bbb\">\n</span></span></span></code></pre></div><h3 id=\"enabling-etcd-tracing\">Enabling Etcd Tracing</h3>\n<p>Add <code>--experimental-enable-distributed-tracing</code>, <code>--experimental-distributed-tracing-address=0.0.0.0:4317</code>, <code>--experimental-distributed-tracing-service-name=etcd</code> flags to etcd to enable tracing. Note that this traces every request, so it will probably generate a lot of traces if you enable it. Required etcd version is <a href=\"https://etcd.io/docs/v3.5/op-guide/monitoring/#distributed-tracing\">v3.5+</a>.</p>\n<h3 id=\"example-trace-list-nodes\">Example Trace: List Nodes</h3>\n<p>I could've used any trace backend, but decided to use Jaeger, since it is one of the most popular open-source tracing projects. I deployed <a href=\"https://hub.docker.com/r/jaegertracing/all-in-one\">the Jaeger All-in-one container</a> in my cluster, deployed <a href=\"https://github.com/open-telemetry/opentelemetry-collector\">the OpenTelemetry collector</a> on my control-plane node (<a href=\"https://github.com/dashpole/dashpole_demos/tree/master/otel/controlplane\">example</a>), and captured traces like this one:</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-09-03-api-server-tracing/example-trace-1.png\" alt=\"Jaeger screenshot showing API server and etcd trace\" title=\"Jaeger screenshot showing API server and etcd trace\"></p>\n<p>The teal lines are from the API Server, and includes it serving a request to <code>/api/v1/nodes</code>, and issuing a grpc <code>Range</code> RPC to ETCD. The yellow-ish line is from ETCD handling the <code>Range</code> RPC.</p>\n<h3 id=\"example-trace-create-pod-with-mutating-webhook\">Example Trace: Create Pod with Mutating Webhook</h3>\n<p>I instrumented the <a href=\"https://github.com/kubernetes-sigs/controller-runtime/tree/master/examples/builtins\">example webhook</a> with OpenTelemetry (I had to <a href=\"https://github.com/dashpole/controller-runtime/commit/85fdda7ba03dd2c22ef62c1a3dbdf5aa651f90da\">patch</a> controller-runtime, but it makes a neat demo), and routed traces to Jaeger as well. I collected traces like this one:</p>\n<p><img src=\"https://kubernetes.io/images/blog/2021-09-03-api-server-tracing/example-trace-2.png\" alt=\"Jaeger screenshot showing API server, admission webhook, and etcd trace\" title=\"Jaeger screenshot showing API server, admission webhook, and etcd trace\"></p>\n<p>Compared with the previous trace, there are two new spans: A teal span from the API Server making a request to the admission webhook, and a brown span from the admission webhook serving the request. Even if you didn't instrument your webhook, you would still get the span from the API Server making the request to the webhook.</p>\n<h2 id=\"get-involved\">Get involved!</h2>\n<p>As this is our first attempt at adding distributed tracing to a Kubernetes component, there is probably a lot we can improve! If my struggles resonated with you, or if you just want to try out the latest Kubernetes has to offer, please give the feature a try and open issues with any problem you encountered and ways you think the feature could be improved.</p>\n<p>This is just the very beginning of what we can do with distributed tracing in Kubernetes. If there are other components you think would benefit from distributed tracing, or want to help bring API Server Tracing to GA, join sig-instrumentation at our <a href=\"https://github.com/kubernetes/community/tree/master/sig-instrumentation#instrumentation-special-interest-group\">regular meetings</a> and get involved!</p>","PublishedAt":"2021-09-03 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/09/03/api-server-tracing/","SourceName":"Kubernetes"}},{"node":{"ID":772,"Title":"Streaming Real-Time Analytics with Redis, AWS Fargate, and Dash Framework","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Uber’s GSS (Global Scaled Solutions) team runs scaled programs for diverse products and businesses, including but not limited to Eats, Rides, and Freight. The team transforms Uber’s ideas into agile, global solutions by designing and implementing scalable solutions. One </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/streaming-real-time-analytics/\">Streaming Real-Time Analytics with Redis, AWS Fargate, and Dash Framework</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-09-02 16:00:50+00:00","OriginURL":"https://eng.uber.com/streaming-real-time-analytics/","SourceName":"Uber"}},{"node":{"ID":773,"Title":"Enabling Seamless Kafka Async Queuing with Consumer Proxy","Description":"<p><span style=\"font-weight: 400;\">Uber has one of the largest deployments of Apache Kafka in the world, processing trillions of messages and multiple petabytes of data per day. As Figure 1 shows, today we position Apache Kafka as a cornerstone of our technology stack. </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/kafka-async-queuing-with-consumer-proxy/\">Enabling Seamless Kafka Async Queuing with Consumer Proxy</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-31 16:00:32+00:00","OriginURL":"https://eng.uber.com/kafka-async-queuing-with-consumer-proxy/","SourceName":"Uber"}},{"node":{"ID":476,"Title":"Instamojo on data stack philosophy","Description":"<figure><img src=\"https://mixpanel.com/wp-content/uploads/2021/08/Ask-An-Expert@2x-1024x577.png\" class=\"type:primaryImage\" /></figure>\n<p>As the Head of Analytics at Instamojo, an e-commerce enabler that provides e-commerce solutions to over 1.5 million micro- to medium-sized businesses in India, Ankur Sharma is in charge of all things data—data engineering, strategy, and core data analytics. In this interview, he spoke to us about what’s in Instamojo’s data stack and the philosophy</p>\n<p>The post <a rel=\"nofollow\" href=\"https://mixpanel.com/blog/ask-an-expert-ankur-sharma-instamojo-data-stack/\">Instamojo on data stack philosophy</a> appeared first on <a rel=\"nofollow\" href=\"https://mixpanel.com\">Mixpanel</a>.</p>\n","PublishedAt":"2021-08-31 10:15:38+00:00","OriginURL":"https://mixpanel.com/blog/ask-an-expert-ankur-sharma-instamojo-data-stack/","SourceName":"Mixpanel"}},{"node":{"ID":1257,"Title":"Blog: Kubernetes 1.22: A New Design for Volume Populators","Description":"<p><strong>Authors:</strong>\nBen Swartzlander (NetApp)</p>\n<p>Kubernetes v1.22, released earlier this month, introduced a redesigned approach for volume\npopulators. Originally implemented\nin v1.18, the API suffered from backwards compatibility issues. Kubernetes v1.22 includes a new API\nfield called <code>dataSourceRef</code> that fixes these problems.</p>\n<h2 id=\"data-sources\">Data sources</h2>\n<p>Earlier Kubernetes releases already added a <code>dataSource</code> field into the\n<a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims\">PersistentVolumeClaim</a> API,\nused for cloning volumes and creating volumes from snapshots. You could use the <code>dataSource</code> field when\ncreating a new PVC, referencing either an existing PVC or a VolumeSnapshot in the same namespace.\nThat also modified the normal provisioning process so that instead of yielding an empty volume, the\nnew PVC contained the same data as either the cloned PVC or the cloned VolumeSnapshot.</p>\n<p>Volume populators embrace the same design idea, but extend it to any type of object, as long\nas there exists a <a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\">custom resource</a>\nto define the data source, and a populator controller to implement the logic. Initially,\nthe <code>dataSource</code> field was directly extended to allow arbitrary objects, if the <code>AnyVolumeDataSource</code>\nfeature gate was enabled on a cluster. That change unfortunately caused backwards compatibility\nproblems, and so the new <code>dataSourceRef</code> field was born.</p>\n<p>In v1.22 if the <code>AnyVolumeDataSource</code> feature gate is enabled, the <code>dataSourceRef</code> field is\nadded, which behaves similarly to the <code>dataSource</code> field except that it allows arbitrary\nobjects to be specified. The API server ensures that the two fields always have the same\ncontents, and neither of them are mutable. The differences is that at creation time\n<code>dataSource</code> allows only PVCs or VolumeSnapshots, and ignores all other values, while\n<code>dataSourceRef</code> allows most types of objects, and in the few cases it doesn't allow an\nobject (core objects other than PVCs) a validation error occurs.</p>\n<p>When this API change graduates to stable, we would deprecate using <code>dataSource</code> and recommend\nusing <code>dataSourceRef</code> field for all use cases.\nIn the v1.22 release, <code>dataSourceRef</code> is available (as an alpha feature) specifically for cases\nwhere you want to use for custom volume populators.</p>\n<h2 id=\"using-populators\">Using populators</h2>\n<p>Every volume populator must have one or more CRDs that it supports. Administrators may\ninstall the CRD and the populator controller and then PVCs with a <code>dataSourceRef</code> specifies\na CR of the type that the populator supports will be handled by the populator controller\ninstead of the CSI driver directly.</p>\n<p>Underneath the covers, the CSI driver is still invoked to create an empty volume, which\nthe populator controller fills with the appropriate data. The PVC doesn't bind to the PV\nuntil it's fully populated, so it's safe to define a whole application manifest including\npod and PVC specs and the pods won't begin running until everything is ready, just as if\nthe PVC was a clone of another PVC or VolumeSnapshot.</p>\n<h2 id=\"how-it-works\">How it works</h2>\n<p>PVCs with data sources are still noticed by the external-provisioner sidecar for the\nrelated storage class (assuming a CSI provisioner is used), but because the sidecar\ndoesn't understand the data source kind, it doesn't do anything. The populator controller\nis also watching for PVCs with data sources of a kind that it understands and when it\nsees one, it creates a temporary PVC of the same size, volume mode, storage class,\nand even on the same topology (if topology is used) as the original PVC. The populator\ncontroller creates a worker pod that attaches to the volume and writes the necessary\ndata to it, then detaches from the volume and the populator controller rebinds the PV\nfrom the temporary PVC to the orignal PVC.</p>\n<h2 id=\"trying-it-out\">Trying it out</h2>\n<p>The following things are required to use volume populators:</p>\n<ul>\n<li>Enable the <code>AnyVolumeDataSource</code> feature gate</li>\n<li>Install a CRD for the specific data source / populator</li>\n<li>Install the populator controller itself</li>\n</ul>\n<p>Populator controllers may use the <a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a>\nlibrary to do most of the Kubernetes API level work. Individual populators only need to\nprovide logic for actually writing data into the volume based on a particular CR\ninstance. This library provides a sample populator implementation.</p>\n<p>These optional components improve user experience:</p>\n<ul>\n<li>Install the VolumePopulator CRD</li>\n<li>Create a VolumePopulator custom respource for each specific data source</li>\n<li>Install the <a href=\"https://github.com/kubernetes-csi/volume-data-source-validator\">volume data source validator</a>\ncontroller (alpha)</li>\n</ul>\n<p>The purpose of these components is to generate warning events on PVCs with data sources\nfor which there is no populator.</p>\n<h2 id=\"putting-it-all-together\">Putting it all together</h2>\n<p>To see how this works, you can install the sample &quot;hello&quot; populator and try it\nout.</p>\n<p>First install the volume-data-source-validator controller.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/client/config/crd/populator.storage.k8s.io_volumepopulators.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/deploy/kubernetes/rbac-data-source-validator.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/volume-data-source-validator/master/deploy/kubernetes/setup-data-source-validator.yaml\n</code></pre><p>Next install the example populator.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/master/example/hello-populator/crd.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/lib-volume-populator/master/example/hello-populator/deploy.yaml\n</code></pre><p>Create an instance of the <code>Hello</code> CR, with some text.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>hello.k8s.io/v1alpha1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileName</span>:<span style=\"color:#bbb\"> </span>example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">fileContents</span>:<span style=\"color:#bbb\"> </span>Hello, world!<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Create a PVC that refers to that CR as its data source.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>PersistentVolumeClaim<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">accessModes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- ReadWriteOnce<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">resources</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">requests</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">storage</span>:<span style=\"color:#bbb\"> </span>10Mi<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">dataSourceRef</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">apiGroup</span>:<span style=\"color:#bbb\"> </span>hello.k8s.io<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-hello<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMode</span>:<span style=\"color:#bbb\"> </span>Filesystem<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Next, run a job that reads the file in the PVC.</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>batch/v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-job<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">template</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>example-container<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>busybox:latest<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">command</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- cat<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- /mnt/example.txt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumeMounts</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">mountPath</span>:<span style=\"color:#bbb\"> </span>/mnt<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">restartPolicy</span>:<span style=\"color:#bbb\"> </span>Never<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">volumes</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>vol<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">persistentVolumeClaim</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">claimName</span>:<span style=\"color:#bbb\"> </span>example-pvc<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Wait for the job to complete (including all of its dependencies).</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl wait --for=condition=Complete job/example-job\n</code></pre><p>And last examine the log from the job.</p>\n<pre tabindex=\"0\"><code class=\"language-terminal\" data-lang=\"terminal\">kubectl logs job/example-job\nHello, world!\n</code></pre><p>Note that the volume already contained a text file with the string contents from\nthe CR. This is only the simplest example. Actual populators can set up the volume\nto contain arbitrary contents.</p>\n<h2 id=\"how-to-write-your-own-volume-populator\">How to write your own volume populator</h2>\n<p>Developers interested in writing new poplators are encouraged to use the\n<a href=\"https://github.com/kubernetes-csi/lib-volume-populator\">lib-volume-populator</a> library\nand to only supply a small controller wrapper around the library, and a pod image\ncapable of attaching to volumes and writing the appropriate data to the volume.</p>\n<p>Individual populators can be extremely generic such that they work with every type\nof PVC, or they can do vendor specific things to rapidly fill a volume with data\nif the volume was provisioned by a specific CSI driver from the same vendor, for\nexample, by communicating directly with the storage for that volume.</p>\n<h2 id=\"the-future\">The future</h2>\n<p>As this feature is still in alpha, we expect to update the out of tree controllers\nwith more tests and documentation. The community plans to eventually re-implement\nthe populator library as a sidecar, for ease of operations.</p>\n<p>We hope to see some official community-supported populators for some widely-shared\nuse cases. Also, we expect that volume populators will be used by backup vendors\nas a way to &quot;restore&quot; backups to volumes, and possibly a standardized API to do\nthis will evolve.</p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<p>The enhancement proposal,\n<a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-storage/1495-volume-populators\">Volume Populators</a>, includes lots of detail about the history and technical implementation\nof this feature.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-populators-and-data-sources\">Volume populators and data sources</a>, within the documentation topic about persistent volumes,\nexplains how to use this feature in your cluster.</p>\n<p>Please get involved by joining the Kubernetes storage SIG to help us enhance this\nfeature. There are a lot of good ideas already and we'd be thrilled to have more!</p>","PublishedAt":"2021-08-30 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/30/volume-populators-redesigned/","SourceName":"Kubernetes"}},{"node":{"ID":1258,"Title":"Blog: Minimum Ready Seconds for StatefulSets","Description":"<p><strong>Authors:</strong> Ravi Gudimetla (Red Hat), Maciej Szulik (Red Hat)</p>\n<p>This blog describes the notion of Availability for <code>StatefulSet</code> workloads, and a new alpha feature in Kubernetes 1.22 which adds <code>minReadySeconds</code> configuration for <code>StatefulSets</code>.</p>\n<h2 id=\"what-problems-does-this-solve\">What problems does this solve?</h2>\n<p>Prior to Kubernetes 1.22 release, once a <code>StatefulSet</code> <code>Pod</code> is in the <code>Ready</code> state it is considered <code>Available</code> to receive traffic. For some of the <code>StatefulSet</code> workloads, it may not be the case. For example, a workload like Prometheus with multiple instances of Alertmanager, it should be considered <code>Available</code> only when Alertmanager's state transfer is complete, not when the <code>Pod</code> is in <code>Ready</code> state. Since <code>minReadySeconds</code> adds buffer, the state transfer may be complete before the <code>Pod</code> becomes <code>Available</code>. While this is not a fool proof way of identifying if the state transfer is complete or not, it gives a way to the end user to express their intention of waiting for sometime before the <code>Pod</code> is considered <code>Available</code> and it is ready to serve requests.</p>\n<p>Another case, where <code>minReadySeconds</code> helps is when using <code>LoadBalancer</code> <code>Services</code> with cloud providers. Since <code>minReadySeconds</code> adds latency after a <code>Pod</code> is <code>Ready</code>, it provides buffer time to prevent killing pods in rotation before new pods show up. Imagine a load balancer in unhappy path taking 10-15s to propagate. If you have 2 replicas then, you'd kill the second replica only after the first one is up but in reality, first replica cannot be seen because it is not yet ready to serve requests.</p>\n<p>So, in general, the notion of <code>Availability</code> in <code>StatefulSets</code> is pretty useful and this feature helps in solving the above problems. This is a feature that already exists for <code>Deployments</code> and <code>DaemonSets</code> and we now have them for <code>StatefulSets</code> too to give users consistent workload experience.</p>\n<h2 id=\"how-does-it-work\">How does it work?</h2>\n<p>The statefulSet controller watches for both <code>StatefulSets</code> and the <code>Pods</code> associated with them. When the feature gate associated with this feature is enabled, the statefulSet controller identifies how long a particular <code>Pod</code> associated with a <code>StatefulSet</code> has been in the <code>Running</code> state.</p>\n<p>If this value is greater than or equal to the time specified by the end user in <code>.spec.minReadySeconds</code> field, the statefulSet controller updates a field called <code>availableReplicas</code> in the <code>StatefulSet</code>'s status subresource to include this <code>Pod</code>. The <code>status.availableReplicas</code> in <code>StatefulSet</code>'s status is an integer field which tracks the number of pods that are <code>Available</code>.</p>\n<h2 id=\"how-do-i-use-it\">How do I use it?</h2>\n<p>You are required to prepare the following things in order to try out the feature:</p>\n<ul>\n<li>Download and install a kubectl greater than v1.22.0 version</li>\n<li>Switch on the feature gate with the command line flag <code>--feature-gates=StatefulSetMinReadySeconds=true</code> on <code>kube-apiserver</code> and <code>kube-controller-manager</code></li>\n</ul>\n<p>After successfully starting <code>kube-apiserver</code> and <code>kube-controller-manager</code>, you will see <code>AvailableReplicas</code> in the status and <code>minReadySeconds</code> of spec (with a default value of 0).</p>\n<p>Specify a value for <code>minReadySeconds</code> for any StatefulSet and you can check if <code>Pods</code> are available or not by checking <code>AvailableReplicas</code> field using:\n<code>kubectl get statefulset/&lt;name_of_the_statefulset&gt; -o yaml</code></p>\n<h2 id=\"how-can-i-learn-more\">How can I learn more?</h2>\n<ul>\n<li>Read the KEP: <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-apps/2599-minreadyseconds-for-statefulsets#readme\">minReadySeconds for StatefulSets</a></li>\n<li>Read the documentation: <a href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#minimum-ready-seconds\">Minimum ready seconds</a> for StatefulSet</li>\n<li>Review the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/\">API definition</a> for StatefulSet</li>\n</ul>\n<h2 id=\"how-do-i-get-involved\">How do I get involved?</h2>\n<p>Please reach out to us in the <a href=\"https://kubernetes.slack.com/archives/C18NZM5K9\">#sig-apps</a> channel on Slack (visit <a href=\"https://slack.k8s.io/\">https://slack.k8s.io/</a> for an invitation if you need one), or on the SIG Apps mailing list: <a href=\"mailto:kubernetes-sig-apps@googlegroups.com\">kubernetes-sig-apps@googlegroups.com</a></p>","PublishedAt":"2021-08-27 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/27/minreadyseconds-statefulsets/","SourceName":"Kubernetes"}},{"node":{"ID":774,"Title":"How Data Shapes the Uber Rider App","Description":"<h1><span style=\"font-weight: 400;\">Introduction</span></h1>\n<p><span style=\"font-weight: 400;\">Data is crucial for our products. Data analytics help us provide a frictionless experience to the people that use our services. It also enables our engineers, product managers, data analysts, and data scientists to make informed decisions. The impact </span>&#8230;</p>\n<p>The post <a rel=\"nofollow\" href=\"https://eng.uber.com/how-data-shapes-the-uber-rider-app/\">How Data Shapes the Uber Rider App</a> appeared first on <a rel=\"nofollow\" href=\"https://eng.uber.com\">Uber Engineering Blog</a>.</p>\n","PublishedAt":"2021-08-26 16:00:20+00:00","OriginURL":"https://eng.uber.com/how-data-shapes-the-uber-rider-app/","SourceName":"Uber"}},{"node":{"ID":1259,"Title":"Blog: Enable seccomp for all workloads with a new v1.22 alpha feature","Description":"<p><strong>Author:</strong> Sascha Grunert, Red Hat</p>\n<p>This blog post is about a new Kubernetes feature introduced in v1.22, which adds\nan additional security layer on top of the existing seccomp support. Seccomp is\na security mechanism for Linux processes to filter system calls (syscalls) based\non a set of defined rules. Applying seccomp profiles to containerized workloads\nis one of the key tasks when it comes to enhancing the security of the\napplication deployment. Developers, site reliability engineers and\ninfrastructure administrators have to work hand in hand to create, distribute\nand maintain the profiles over the applications life-cycle.</p>\n<p>You can use the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\"><code>securityContext</code></a> field of Pods and their\ncontainers can be used to adjust security related configurations of the\nworkload. Kubernetes introduced dedicated <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\">seccomp related API\nfields</a> in this <code>SecurityContext</code> with the <a href=\"https://kubernetes.io/blog/2020/08/26/kubernetes-release-1.19-accentuate-the-paw-sitive/#graduated-to-stable\">graduation of seccomp to\nGeneral Availability (GA)</a> in v1.19.0. This enhancement allowed an easier\nway to specify if the whole pod or a specific container should run as:</p>\n<ul>\n<li><code>Unconfined</code>: seccomp will not be enabled</li>\n<li><code>RuntimeDefault</code>: the container runtimes default profile will be used</li>\n<li><code>Localhost</code>: a node local profile will be applied, which is being referenced\nby a relative path to the seccomp profile root (<code>&lt;kubelet-root-dir&gt;/seccomp</code>)\nof the kubelet</li>\n</ul>\n<p>With the graduation of seccomp, nothing has changed from an overall security\nperspective, because <code>Unconfined</code> is still the default. This is totally fine if\nyou consider this from the upgrade path and backwards compatibility perspective of\nKubernetes releases. But it also means that it is more likely that a workload\nruns without seccomp at all, which should be fixed in the long term.</p>\n<h2 id=\"seccompdefault-to-the-rescue\"><code>SeccompDefault</code> to the rescue</h2>\n<p>Kubernetes v1.22.0 introduces a new kubelet <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates\">feature gate</a>\n<code>SeccompDefault</code>, which has been added in <code>alpha</code> state as every other new\nfeature. This means that it is disabled by default and can be enabled manually\nfor every single Kubernetes node.</p>\n<p>What does the feature do? Well, it just changes the default seccomp profile from\n<code>Unconfined</code> to <code>RuntimeDefault</code>. If not specified differently in the pod\nmanifest, then the feature will add a higher set of security constraints by\nusing the default profile of the container runtime. These profiles may differ\nbetween runtimes like <a href=\"https://github.com/cri-o/cri-o/blob/fe30d62/vendor/github.com/containers/common/pkg/seccomp/default_linux.go#L45\">CRI-O</a> or <a href=\"https://github.com/containerd/containerd/blob/e1445df/contrib/seccomp/seccomp_default.go#L51\">containerd</a>. They also differ for\nits used hardware architectures. But generally speaking, those default profiles\nallow a common amount of syscalls while blocking the more dangerous ones, which\nare unlikely or unsafe to be used in a containerized application.</p>\n<h3 id=\"enabling-the-feature\">Enabling the feature</h3>\n<p>Two kubelet configuration changes have to be made to enable the feature:</p>\n<ol>\n<li><strong>Enable the feature</strong> gate by setting the <code>SeccompDefault=true</code> via the command\nline (<code>--feature-gates</code>) or the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file\">kubelet configuration</a> file.</li>\n<li><strong>Turn on the feature</strong> by enabling the feature by adding the\n<code>--seccomp-default</code> command line flag or via the <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file\">kubelet\nconfiguration</a> file (<code>seccompDefault: true</code>).</li>\n</ol>\n<p>The kubelet will error on startup if only one of the above steps have been done.</p>\n<h3 id=\"trying-it-out\">Trying it out</h3>\n<p>If the feature is enabled on a node, then you can create a new workload like\nthis:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>nginx:1.21<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>Now it is possible to inspect the used seccomp profile by using\n<a href=\"https://github.com/kubernetes-sigs/cri-tools\"><code>crictl</code></a> while investigating the containers <a href=\"https://github.com/opencontainers/runtime-spec/blob/0c021c1/config-linux.md#seccomp\">runtime\nspecification</a>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span><span style=\"color:#b8860b\">CONTAINER_ID</span><span style=\"color:#666\">=</span><span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container<span style=\"color:#a2f;font-weight:bold\">)</span>\n</span></span><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#b8860b\">$CONTAINER_ID</span> | jq .info.runtimeSpec.linux.seccomp\n</span></span></code></pre></div><div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;defaultAction&#34;: </span><span style=\"color:#b44\">&#34;SCMP_ACT_ERRNO&#34;</span>,<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;architectures&#34;: </span>[<span style=\"color:#b44\">&#34;SCMP_ARCH_X86_64&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;SCMP_ARCH_X86&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;SCMP_ARCH_X32&#34;</span>],<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;syscalls&#34;: </span>[<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>{<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;names&#34;: </span>[<span style=\"color:#b44\">&#34;_llseek&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;_newselect&#34;</span>,<span style=\"color:#bbb\"> </span><span style=\"color:#b44\">&#34;accept&#34;</span>,<span style=\"color:#bbb\"> </span>…, &#34;write&#34;, &#34;writev&#34;],<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">&#34;action&#34;: </span><span style=\"color:#b44\">&#34;SCMP_ACT_ALLOW&#34;</span><span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>},<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>…<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>]<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span>}<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>You can see that the lower level container runtime (<a href=\"https://github.com/cri-o/cri-o\">CRI-O</a> and\n<a href=\"https://github.com/opencontainers/runc\">runc</a> in our case), successfully applied the default seccomp profile.\nThis profile denies all syscalls per default, while allowing commonly used ones\nlike <a href=\"https://man7.org/linux/man-pages/man2/accept.2.html\"><code>accept</code></a> or <a href=\"https://man7.org/linux/man-pages/man2/write.2.html\"><code>write</code></a>.</p>\n<p>Please note that the feature will not influence any Kubernetes API for now.\nTherefore, it is not possible to retrieve the used seccomp profile via <code>kubectl</code>\n<code>get</code> or <code>describe</code> if the <a href=\"https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-1\"><code>SeccompProfile</code></a> field is unset within the\n<code>SecurityContext</code>.</p>\n<p>The feature also works when using multiple containers within a pod, for example\nif you create a pod like this:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-yaml\" data-lang=\"yaml\"><span style=\"display:flex;\"><span><span style=\"color:#008000;font-weight:bold\">apiVersion</span>:<span style=\"color:#bbb\"> </span>v1<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">kind</span>:<span style=\"color:#bbb\"> </span>Pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">metadata</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-pod<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"></span><span style=\"color:#008000;font-weight:bold\">spec</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">containers</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container-nginx<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>nginx:1.21<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">securityContext</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">seccompProfile</span>:<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">type</span>:<span style=\"color:#bbb\"> </span>Unconfined<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span>- <span style=\"color:#008000;font-weight:bold\">name</span>:<span style=\"color:#bbb\"> </span>test-container-redis<span style=\"color:#bbb\">\n</span></span></span><span style=\"display:flex;\"><span><span style=\"color:#bbb\"> </span><span style=\"color:#008000;font-weight:bold\">image</span>:<span style=\"color:#bbb\"> </span>redis:6.2<span style=\"color:#bbb\">\n</span></span></span></code></pre></div><p>then you should see that the <code>test-container-nginx</code> runs without a seccomp profile:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container-nginx<span style=\"color:#a2f;font-weight:bold\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp == null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><p>Whereas the container <code>test-container-redis</code> runs with <code>RuntimeDefault</code>:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspect <span style=\"color:#a2f;font-weight:bold\">$(</span>sudo crictl ps -q --name<span style=\"color:#666\">=</span>test-container-redis<span style=\"color:#a2f;font-weight:bold\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp != null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><p>The same applies to the pod itself, which also runs with the default profile:</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"><code class=\"language-bash\" data-lang=\"bash\"><span style=\"display:flex;\"><span>sudo crictl inspectp <span style=\"color:#666\">(</span>sudo crictl pods -q --name test-pod<span style=\"color:#666\">)</span> |\n</span></span><span style=\"display:flex;\"><span> jq <span style=\"color:#b44\">&#39;.info.runtimeSpec.linux.seccomp != null&#39;</span>\n</span></span><span style=\"display:flex;\"><span><span style=\"color:#a2f\">true</span>\n</span></span></code></pre></div><h3 id=\"upgrade-strategy\">Upgrade strategy</h3>\n<p>It is recommended to enable the feature in multiple steps, whereas different\nrisks and mitigations exist for each one.</p>\n<h4 id=\"feature-gate-enabling\">Feature gate enabling</h4>\n<p>Enabling the feature gate at the kubelet level will not turn on the feature, but\nwill make it possible by using the <code>SeccompDefault</code> kubelet configuration or the\n<code>--seccomp-default</code> CLI flag. This can be done by an administrator for the whole\ncluster or only a set of nodes.</p>\n<h4 id=\"testing-the-application\">Testing the Application</h4>\n<p>If you're trying this within a dedicated test environment, you have to ensure\nthat the application code does not trigger syscalls blocked by the\n<code>RuntimeDefault</code> profile before enabling the feature on a node. This can be done\nby:</p>\n<ul>\n<li>\n<p><em>Recommended</em>: Analyzing the code (manually or by running the application with\n<a href=\"https://man7.org/linux/man-pages/man1/strace.1.html\">strace</a>) for any executed syscalls which may be blocked by the\ndefault profiles. If that's the case, then you can override the default by\nexplicitly setting the pod or container to run as <code>Unconfined</code>. Alternatively,\nyou can create a custom seccomp profile (see optional step below).\nprofile based on the default by adding the additional syscalls to the\n<code>&quot;action&quot;: &quot;SCMP_ACT_ALLOW&quot;</code> section.</p>\n</li>\n<li>\n<p><em>Recommended</em>: Manually set the profile to the target workload and use a\nrolling upgrade to deploy into production. Rollback the deployment if the\napplication does not work as intended.</p>\n</li>\n<li>\n<p><em>Optional</em>: Run the application against an end-to-end test suite to trigger\nall relevant code paths with <code>RuntimeDefault</code> enabled. If a test fails, use\nthe same mitigation as mentioned above.</p>\n</li>\n<li>\n<p><em>Optional</em>: Create a custom seccomp profile based on the default and change\nits default action from <code>SCMP_ACT_ERRNO</code> to <code>SCMP_ACT_LOG</code>. This means that\nthe seccomp filter for unknown syscalls will have no effect on the application\nat all, but the system logs will now indicate which syscalls may be blocked.\nThis requires at least a Kernel version 4.14 as well as a recent <a href=\"https://github.com/opencontainers/runc\">runc</a>\nrelease. Monitor the application hosts audit logs (defaults to\n<code>/var/log/audit/audit.log</code>) or syslog entries (defaults to <code>/var/log/syslog</code>)\nfor syscalls via <code>type=SECCOMP</code> (for audit) or <code>type=1326</code> (for syslog).\nCompare the syscall ID with those <a href=\"https://github.com/torvalds/linux/blob/7bb7f2a/arch/x86/entry/syscalls/syscall_64.tbl\">listed in the Linux Kernel\nsources</a> and add them to the custom profile. Be aware that custom\naudit policies may lead into missing syscalls, depending on the configuration\nof auditd.</p>\n</li>\n<li>\n<p><em>Optional</em>: Use cluster additions like the <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator\">Security Profiles Operator</a>\nfor profiling the application via its <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/c90ef3a/installation-usage.md#record-profiles-from-workloads-with-profilerecordings\">log enrichment</a> capabilities or\nrecording a profile by using its <a href=\"https://github.com/kubernetes-sigs/security-profiles-operator/blob/c90ef3a/installation-usage.md#using-the-log-enricher\">recording feature</a>. This makes the\nabove mentioned manual log investigation obsolete.</p>\n</li>\n</ul>\n<h4 id=\"deploying-the-modified-application\">Deploying the modified application</h4>\n<p>Based on the outcome of the application tests, it may be required to change the\napplication deployment by either specifying <code>Unconfined</code> or a custom seccomp\nprofile. This is not the case if the application works as intended with\n<code>RuntimeDefault</code>.</p>\n<h4 id=\"enable-the-kubelet-configuration\">Enable the kubelet configuration</h4>\n<p>If everything went well, then the feature is ready to be enabled by the kubelet\nconfiguration or its corresponding CLI flag. This should be done on a per-node\nbasis to reduce the overall risk of missing a syscall during the investigations\nwhen running the application tests. If it's possible to monitor audit logs\nwithin the cluster, then it's recommended to do this for eventually missed\nseccomp events. If the application works as intended then the feature can be\nenabled for further nodes within the cluster.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Thank you for reading this blog post! I hope you enjoyed to see how the usage of\nseccomp profiles has been evolved in Kubernetes over the past releases as much\nas I do. On your own cluster, change the default seccomp profile to\n<code>RuntimeDefault</code> (using this new feature) and see the security benefits, and, of\ncourse, feel free to reach out any time for feedback or questions.</p>\n<hr>\n<p><em>Editor's note: If you have any questions or feedback about this blog post, feel\nfree to reach out via the <a href=\"https://kubernetes.slack.com/messages/sig-node\">Kubernetes slack in #sig-node</a>.</em></p>","PublishedAt":"2021-08-25 00:00:00+00:00","OriginURL":"https://kubernetes.io/blog/2021/08/25/seccomp-default/","SourceName":"Kubernetes"}}]}},"pageContext":{"limit":30,"skip":4110,"numPages":158,"currentPage":138}},"staticQueryHashes":["3649515864"]}